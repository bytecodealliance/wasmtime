test compile precise-output
set enable_nan_canonicalization=true
target riscv64 has_v

function %f0(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
	v2 = fadd v0, v1
	return v2
}

; VCode:
;   addi sp,sp,-16
;   sd ra,8(sp)
;   sd fp,0(sp)
;   mv fp,sp
; block0:
;   vle8.v v9,16(fp) #avl=16, #vtype=(e8, m1, ta, ma)
;   vle8.v v11,32(fp) #avl=16, #vtype=(e8, m1, ta, ma)
;   vfadd.vv v13,v9,v11 #avl=4, #vtype=(e32, m1, ta, ma)
;   lui a1,523264
;   fmv.w.x fa2,a1
;   vfmv.v.f v14,fa2 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmfne.vv v10,v13,v13 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmfne.vv v12,v13,v13 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmor.mm v0,v10,v12 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmerge.vvm v8,v13,v14,v0.t #avl=4, #vtype=(e32, m1, ta, ma)
;   vse8.v v8,0(a0) #avl=16, #vtype=(e8, m1, ta, ma)
;   ld ra,8(sp)
;   ld fp,0(sp)
;   addi sp,sp,16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   addi sp, sp, -0x10
;   sd ra, 8(sp)
;   sd s0, 0(sp)
;   mv s0, sp
; block1: ; offset 0x10
;   .byte 0x57, 0x70, 0x08, 0xcc
;   addi t6, s0, 0x10
;   .byte 0x87, 0x84, 0x0f, 0x02
;   addi t6, s0, 0x20
;   .byte 0x87, 0x85, 0x0f, 0x02
;   .byte 0x57, 0x70, 0x02, 0xcd
;   .byte 0xd7, 0x96, 0x95, 0x02
;   lui a1, 0x7fc00
;   fmv.w.x fa2, a1
;   .byte 0x57, 0x57, 0x06, 0x5e
;   .byte 0x57, 0x95, 0xd6, 0x72
;   .byte 0x57, 0x96, 0xd6, 0x72
;   .byte 0x57, 0x20, 0xa6, 0x6a
;   .byte 0x57, 0x04, 0xd7, 0x5c
;   .byte 0x57, 0x70, 0x08, 0xcc
;   .byte 0x27, 0x04, 0x05, 0x02
;   ld ra, 8(sp)
;   ld s0, 0(sp)
;   addi sp, sp, 0x10
;   ret

function %f1(f64, f64) -> f64 {
block0(v0: f64, v1: f64):
	v2 = fadd v0, v1
	return v2
}

; VCode:
; block0:
;   fadd.d fa1,fa0,fa1,rne
;   lui a5,4095
;   slli a1,a5,39
;   fmv.d.x fa3,a1
;   vmv.v.x v8,zero #avl=2, #vtype=(e64, m1, ta, ma)
;   vfmv.s.f v10,fa3 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmv.v.i v0,1 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmerge.vvm v14,v8,v10,v0.t #avl=2, #vtype=(e64, m1, ta, ma)
;   vmv.v.x v8,zero #avl=2, #vtype=(e64, m1, ta, ma)
;   vfmv.s.f v10,fa1 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmv.v.i v0,1 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmerge.vvm v15,v8,v10,v0.t #avl=2, #vtype=(e64, m1, ta, ma)
;   vmfne.vv v8,v15,v15 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmfne.vv v10,v15,v15 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmor.mm v0,v8,v10 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmerge.vvm v8,v15,v14,v0.t #avl=2, #vtype=(e64, m1, ta, ma)
;   vfmv.f.s fa0,v8 #avl=2, #vtype=(e64, m1, ta, ma)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   fadd.d fa1, fa0, fa1, rne
;   lui a5, 0xfff
;   slli a1, a5, 0x27
;   fmv.d.x fa3, a1
;   .byte 0x57, 0x70, 0x81, 0xcd
;   .byte 0x57, 0x44, 0x00, 0x5e
;   .byte 0x57, 0xd5, 0x06, 0x42
;   .byte 0x57, 0xb0, 0x00, 0x5e
;   .byte 0x57, 0x07, 0x85, 0x5c
;   .byte 0x57, 0x44, 0x00, 0x5e
;   .byte 0x57, 0xd5, 0x05, 0x42
;   .byte 0x57, 0xb0, 0x00, 0x5e
;   .byte 0xd7, 0x07, 0x85, 0x5c
;   .byte 0x57, 0x94, 0xf7, 0x72
;   .byte 0x57, 0x95, 0xf7, 0x72
;   .byte 0x57, 0x20, 0x85, 0x6a
;   .byte 0x57, 0x04, 0xf7, 0x5c
;   .byte 0x57, 0x15, 0x80, 0x42
;   ret

function %f1(f32, f32) -> f32 {
block0(v0: f32, v1: f32):
	v2 = fadd v0, v1
	return v2
}

; VCode:
; block0:
;   fadd.s fa0,fa0,fa1,rne
;   lui a5,523264
;   fmv.w.x fa1,a5
;   vmv.v.x v15,zero #avl=4, #vtype=(e32, m1, ta, ma)
;   vfmv.s.f v9,fa1 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmv.v.i v0,1 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmerge.vvm v13,v15,v9,v0.t #avl=4, #vtype=(e32, m1, ta, ma)
;   vmv.v.x v15,zero #avl=4, #vtype=(e32, m1, ta, ma)
;   vfmv.s.f v9,fa0 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmv.v.i v0,1 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmerge.vvm v14,v15,v9,v0.t #avl=4, #vtype=(e32, m1, ta, ma)
;   vmfne.vv v15,v14,v14 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmfne.vv v9,v14,v14 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmor.mm v0,v15,v9 #avl=4, #vtype=(e32, m1, ta, ma)
;   vmerge.vvm v15,v14,v13,v0.t #avl=4, #vtype=(e32, m1, ta, ma)
;   vfmv.f.s fa0,v15 #avl=4, #vtype=(e32, m1, ta, ma)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   fadd.s fa0, fa0, fa1, rne
;   lui a5, 0x7fc00
;   fmv.w.x fa1, a5
;   .byte 0x57, 0x70, 0x02, 0xcd
;   .byte 0xd7, 0x47, 0x00, 0x5e
;   .byte 0xd7, 0xd4, 0x05, 0x42
;   .byte 0x57, 0x70, 0x81, 0xcd
;   .byte 0x57, 0xb0, 0x00, 0x5e
;   .byte 0x57, 0x70, 0x02, 0xcd
;   .byte 0xd7, 0x86, 0xf4, 0x5c
;   .byte 0xd7, 0x47, 0x00, 0x5e
;   .byte 0xd7, 0x54, 0x05, 0x42
;   .byte 0x57, 0x70, 0x81, 0xcd
;   .byte 0x57, 0xb0, 0x00, 0x5e
;   .byte 0x57, 0x70, 0x02, 0xcd
;   .byte 0x57, 0x87, 0xf4, 0x5c
;   .byte 0xd7, 0x17, 0xe7, 0x72
;   .byte 0xd7, 0x14, 0xe7, 0x72
;   .byte 0x57, 0xa0, 0xf4, 0x6a
;   .byte 0xd7, 0x87, 0xe6, 0x5c
;   .byte 0x57, 0x15, 0xf0, 0x42
;   ret

