test compile precise-output
set unwind_info=false
target riscv64 has_zca has_zcb has_zbb has_zba

function %c_mul(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = imul.i64 v0, v1
  return v2
}

; VCode:
; block0:
;   mul a0,a0,a1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x4d, 0x9d
;   c.jr ra



function %c_not(i64) -> i64 {
block0(v0: i64):
  v1 = bnot.i64 v0
  return v1
}

; VCode:
; block0:
;   not a0,a0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x75, 0x9d
;   c.jr ra

function %c_zextb(i8) -> i64 {
block0(v0: i8):
    v1 = uextend.i64 v0
    return v1
}

; VCode:
; block0:
;   andi a0,a0,255
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x61, 0x9d
;   c.jr ra

function %c_zexth(i16) -> i64 {
block0(v0: i16):
    v1 = uextend.i64 v0
    return v1
}

; VCode:
; block0:
;   zext.h a0,a0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x69, 0x9d
;   c.jr ra

function %c_zextw(i32) -> i64 {
block0(v0: i32):
    v1 = uextend.i64 v0
    return v1
}

; VCode:
; block0:
;   zext.w a0,a0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x71, 0x9d
;   c.jr ra

function %c_sextb(i8) -> i64 {
block0(v0: i8):
    v1 = sextend.i64 v0
    return v1
}

; VCode:
; block0:
;   sext.b a0,a0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x65, 0x9d
;   c.jr ra

function %c_sexth(i16) -> i64 {
block0(v0: i16):
    v1 = sextend.i64 v0
    return v1
}

; VCode:
; block0:
;   sext.h a0,a0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x6d, 0x9d
;   c.jr ra


function %c_lbu(i64) -> i16, i64 {
block0(v0: i64):
  v1 = uload8.i16 v0+0
  v2 = uload8.i64 v0+3
  return v1, v2
}

; VCode:
; block0:
;   lbu a3,0(a0)
;   mv a4,a3
;   lbu a1,3(a0)
;   mv a0,a4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x14, 0x81 ; trap: heap_oob
;   c.mv a4, a3
;   .byte 0x6c, 0x81 ; trap: heap_oob
;   c.mv a0, a4
;   c.jr ra

function %c_lhu(i64) -> i32, i64 {
block0(v0: i64):
  v1 = uload16.i32 v0+0
  v2 = uload16.i64 v0+2
  return v1, v2
}

; VCode:
; block0:
;   lhu a3,0(a0)
;   mv a4,a3
;   lhu a1,2(a0)
;   mv a0,a4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x14, 0x85 ; trap: heap_oob
;   c.mv a4, a3
;   .byte 0x2c, 0x85 ; trap: heap_oob
;   c.mv a0, a4
;   c.jr ra

function %c_lh(i64) -> i16, i16 {
block0(v0: i64):
  v1 = load.i16 v0+0
  v2 = load.i16 v0+2
  return v1, v2
}

; VCode:
; block0:
;   lh a3,0(a0)
;   mv a4,a3
;   lh a1,2(a0)
;   mv a0,a4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x54, 0x85 ; trap: heap_oob
;   c.mv a4, a3
;   .byte 0x6c, 0x85 ; trap: heap_oob
;   c.mv a0, a4
;   c.jr ra

function %c_sb(i64, i8) {
block0(v0: i64, v1: i8):
  store.i8 v1, v0+0
  store.i8 v1, v0+1
  store.i8 v1, v0+2
  store.i8 v1, v0+3
  store.i8 v1, v0+4
  return
}

; VCode:
; block0:
;   sb a1,0(a0)
;   sb a1,1(a0)
;   sb a1,2(a0)
;   sb a1,3(a0)
;   sb a1,4(a0)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x0c, 0x89 ; trap: heap_oob
;   .byte 0x4c, 0x89 ; trap: heap_oob
;   .byte 0x2c, 0x89 ; trap: heap_oob
;   .byte 0x6c, 0x89 ; trap: heap_oob
;   sb a1, 4(a0) ; trap: heap_oob
;   c.jr ra

function %c_sh(i64, i16) {
block0(v0: i64, v1: i16):
  store.i16 v1, v0+0
  store.i16 v1, v0+2
  store.i16 v1, v0+3
  return
}

; VCode:
; block0:
;   sh a1,0(a0)
;   sh a1,2(a0)
;   sh a1,3(a0)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x0c, 0x8d ; trap: heap_oob
;   .byte 0x2c, 0x8d ; trap: heap_oob
;   sh a1, 3(a0) ; trap: heap_oob
;   c.jr ra

function %no_compress_store_zero(i64) {
    ss1 = explicit_slot 1
    ss2 = explicit_slot 2
    ss4 = explicit_slot 4
    ss8 = explicit_slot 8
block0(v0: i64):
  v1 = iconst.i8 0
  store.i8 notrap v1, v0
  stack_store.i8 v1, ss1

  v2 = iconst.i16 0
  store.i16 notrap v2, v0
  stack_store.i16 v2, ss2

  v3 = iconst.i32 0
  store.i32 notrap v3, v0
  stack_store.i32 v3, ss4

  v4 = iconst.i64 0
  store.i64 notrap v4, v0
  stack_store.i64 v4, ss8

  v5 = f32const 0.0
  store.f32 notrap v5, v0
  stack_store.f32 v5, ss4

  v6 = f64const 0.0
  store.f64 notrap v6, v0
  stack_store.f64 v6, ss8

  return
}

; VCode:
;   addi sp,sp,-16
;   sd ra,8(sp)
;   sd fp,0(sp)
;   mv fp,sp
;   addi sp,sp,-32
; block0:
;   sb zero,0(a0)
;   sb zero,0(slot)
;   sh zero,0(a0)
;   sh zero,8(slot)
;   sw zero,0(a0)
;   sw zero,16(slot)
;   sd zero,0(a0)
;   sd zero,24(slot)
;   fmv.w.x fa5,zero
;   fsw fa5,0(a0)
;   fsw fa5,16(slot)
;   fmv.d.x fa1,zero
;   fsd fa1,0(a0)
;   fsd fa1,24(slot)
;   addi sp,sp,32
;   ld ra,8(sp)
;   ld fp,0(sp)
;   addi sp,sp,16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   c.addi16sp sp, -0x10
;   c.sdsp ra, 8(sp)
;   c.sdsp s0, 0(sp)
;   c.mv s0, sp
;   c.addi16sp sp, -0x20
; block1: ; offset 0xa
;   sb zero, 0(a0)
;   sb zero, 0(sp)
;   sh zero, 0(a0)
;   sh zero, 8(sp)
;   sw zero, 0(a0)
;   c.swsp zero, 0x10(sp)
;   sd zero, 0(a0)
;   c.sdsp zero, 0x18(sp)
;   fmv.w.x fa5, zero
;   fsw fa5, 0(a0)
;   fsw fa5, 0x10(sp)
;   fmv.d.x fa1, zero
;   fsd fa1, 0(a0)
;   fsd fa1, 0x18(sp)
;   c.addi16sp sp, 0x20
;   c.ldsp ra, 8(sp)
;   c.ldsp s0, 0(sp)
;   c.addi16sp sp, 0x10
;   c.jr ra

