test compile precise-output
set opt_level=speed
target riscv64

function %mul_uextend_i64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = imul v2, v3
    return v4
}

; VCode:
; block0:
;   li a5,0
;   li a2,0
;   mulhu a3,a0,a1
;   mul a2,a0,a2
;   add a3,a2,a3
;   mul a5,a5,a1
;   mv a2,a1
;   add a1,a5,a3
;   mul a3,a0,a2
;   add a0,a3,zero
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mv a5, zero
;   mv a2, zero
;   mulhu a3, a0, a1
;   mul a2, a0, a2
;   add a3, a2, a3
;   mul a5, a5, a1
;   mv a2, a1
;   add a1, a5, a3
;   mul a3, a0, a2
;   add a0, a3, zero
;   ret

function %mul_sextend_i64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = sextend.i128 v0
    v3 = sextend.i128 v1
    v4 = imul v2, v3
    return v4
}

; VCode:
; block0:
;   srai a5,a0,63
;   srai a2,a1,63
;   mulhu a3,a0,a1
;   mul a2,a0,a2
;   add a3,a2,a3
;   mul a5,a5,a1
;   mv a2,a1
;   add a1,a5,a3
;   mul a3,a0,a2
;   add a0,a3,zero
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   srai a5, a0, 0x3f
;   srai a2, a1, 0x3f
;   mulhu a3, a0, a1
;   mul a2, a0, a2
;   add a3, a2, a3
;   mul a5, a5, a1
;   mv a2, a1
;   add a1, a5, a3
;   mul a3, a0, a2
;   add a0, a3, zero
;   ret

function %smul_high_i64_pattern(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = sextend.i128 v0
    v3 = sextend.i128 v1
    v4 = imul v2, v3
    v5 = sshr_imm v4, 64
    v6 = ireduce.i64 v5
    return v6
}

; VCode:
; block0:
;   mulh a0,a0,a1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mulh a0, a0, a1
;   ret

function %smul_high_i64_isplit(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = sextend.i128 v0
    v3 = sextend.i128 v1
    v4 = imul v2, v3
    v5, v6 = isplit v4
    return v6
}

; VCode:
; block0:
;   srai a5,a0,63
;   srai a2,a1,63
;   mulhu a3,a0,a1
;   mul a2,a0,a2
;   mv a4,a0
;   add a3,a2,a3
;   mul a5,a5,a1
;   add a0,a5,a3
;   mv a2,a4
;   mul a3,a2,a1
;   add a5,a3,zero
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   srai a5, a0, 0x3f
;   srai a2, a1, 0x3f
;   mulhu a3, a0, a1
;   mul a2, a0, a2
;   mv a4, a0
;   add a3, a2, a3
;   mul a5, a5, a1
;   add a0, a5, a3
;   mv a2, a4
;   mul a3, a2, a1
;   add a5, a3, zero
;   ret

function %umul_high_i64_pattern(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = imul v2, v3
    v5 = ushr_imm v4, 64
    v6 = ireduce.i64 v5
    return v6
}

; VCode:
; block0:
;   mulhu a0,a0,a1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mulhu a0, a0, a1
;   ret

function %umul_high_i64_isplit(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = imul v2, v3
    v5, v6 = isplit v4
    return v6
}

; VCode:
; block0:
;   li a5,0
;   li a2,0
;   mulhu a3,a0,a1
;   mul a2,a0,a2
;   mv a4,a0
;   add a3,a2,a3
;   mul a5,a5,a1
;   add a0,a5,a3
;   mv a2,a4
;   mul a3,a2,a1
;   add a5,a3,zero
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mv a5, zero
;   mv a2, zero
;   mulhu a3, a0, a1
;   mul a2, a0, a2
;   mv a4, a0
;   add a3, a2, a3
;   mul a5, a5, a1
;   add a0, a5, a3
;   mv a2, a4
;   mul a3, a2, a1
;   add a5, a3, zero
;   ret

