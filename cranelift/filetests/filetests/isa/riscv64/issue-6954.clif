test compile precise-output
target riscv64gc has_v has_zbkb has_zba has_zbb has_zbc has_zbs


function %a(i16 sext, f32, f64x2, i32 sext, i8 sext, i64x2, i8, f32x4, i16x8, i8 sext, i8 sext) -> f64x2, i16x8, i8, f64x2, i16x8, i16x8, i16x8, i16x8 {
    ss0 = explicit_slot 126
    ss1 = explicit_slot 126
    ss2 = explicit_slot 126

block0(v0: i16, v1: f32, v2: f64x2, v3: i32, v4: i8, v5: i64x2, v6: i8, v7: f32x4, v8: i16x8, v9: i8, v10: i8):
    v11 = iconst.i8 0
    v12 = iconst.i16 0
    v13 = iconst.i32 0
    v14 = iconst.i64 0
    v15 = uextend.i128 v14
    stack_store v15, ss0
    stack_store v15, ss0+16
    stack_store v15, ss0+32
    stack_store v15, ss0+48
    stack_store v15, ss0+64
    stack_store v15, ss0+80
    stack_store v15, ss0+96
    stack_store v14, ss0+112
    stack_store v13, ss0+120
    stack_store v12, ss0+124
    stack_store v15, ss1
    stack_store v15, ss1+16
    stack_store v15, ss1+32
    stack_store v15, ss1+48
    stack_store v15, ss1+64
    stack_store v15, ss1+80
    stack_store v15, ss1+96
    stack_store v14, ss1+112
    stack_store v13, ss1+120
    stack_store v12, ss1+124
    stack_store v15, ss2
    stack_store v15, ss2+16
    stack_store v15, ss2+32
    stack_store v15, ss2+48
    stack_store v15, ss2+64
    stack_store v15, ss2+80
    stack_store v15, ss2+96
    stack_store v14, ss2+112
    stack_store v13, ss2+120
    stack_store v12, ss2+124
    v16 = select v3, v8, v8
    v17 = select v3, v16, v16
    v18 = select v3, v17, v17
    v77 = sqrt v2
    v78 = fcmp ne v77, v77
    v79 = f64const +NaN
    v80 = splat.f64x2 v79
    v81 = bitcast.f64x2 v78
    v19 = bitselect v81, v80, v77
    v82 = sqrt v19
    v83 = fcmp ne v82, v82
    v84 = f64const +NaN
    v85 = splat.f64x2 v84
    v86 = bitcast.f64x2 v83
    v20 = bitselect v86, v85, v82
    v21 = select v3, v18, v18
    v22 = umin v0, v0
    v23 = select v3, v21, v21
    v24 = select v3, v23, v23
    v25 = select v3, v24, v24
    v26 = select v3, v25, v25
    v27 = select v3, v26, v26
    v28 = select v3, v27, v27
    v29 = select v3, v28, v28
    v30 = iadd v3, v3
    v31 = select v30, v29, v29
    v32 = umin v22, v22
    v33 = select v30, v31, v31
    v34 = select v30, v33, v33
    v35 = select v30, v34, v34
    v36 = select v30, v35, v35
    v37 = smax v5, v5
    v38 = ishl v32, v32
    v39 = select v30, v36, v36
    v40 = stack_addr.i64 ss0+3
    v41 = iadd_imm v40, 0
    v42 = atomic_rmw.i8 and v41, v10
    v43 = select v30, v39, v39
    v44 = select v30, v43, v43
    v45 = select v30, v44, v44
    v46 = isub v38, v38
    v47 = select v30, v45, v45
    v48 = select v30, v47, v47
    v49 = select v30, v48, v48
    v50 = select v30, v49, v49
    stack_store v37, ss0+33
    v51 = select v30, v50, v50
    v52 = select v30, v51, v51
    v53 = select v30, v52, v52
    v54 = select v30, v53, v53
    v55 = select v30, v54, v54
    v56 = select v30, v55, v55
    v57 = select v30, v56, v56
    v58 = select v30, v57, v57
    v59 = select v30, v58, v58
    v60 = select v30, v59, v59
    v61 = select v30, v60, v60
    v62 = select v30, v61, v61
    v63 = select v30, v62, v62
    v64 = select v30, v63, v63
    v65 = select v30, v64, v64
    v66 = select v30, v65, v65
    v67 = select v30, v66, v66
    v68 = select v30, v67, v67
    v69 = select v30, v68, v68
    v70 = select v30, v69, v69
    v71 = select v30, v70, v70
    v72 = select v30, v71, v71
    v73 = select v30, v72, v72
    v74 = select v30, v73, v73
    v75 = select v30, v74, v74
    v76 = select v30, v75, v75
    return v20, v76, v42, v20, v76, v76, v76, v76
}

; VCode:
;   addi sp,sp,-16
;   sd ra,8(sp)
;   sd fp,0(sp)
;   mv fp,sp
;   addi sp,sp,-384
; block0:
;   mv a7,a0
;   vle8.v v10,-64(incoming_arg) #avl=16, #vtype=(e8, m1, ta, ma)
;   vle8.v v13,-48(incoming_arg) #avl=16, #vtype=(e8, m1, ta, ma)
;   vle8.v v15,-16(incoming_arg) #avl=16, #vtype=(e8, m1, ta, ma)
;   li a1,0
;   li a3,0
;   sd a1,0(slot)
;   sd a3,8(slot)
;   sd a1,16(slot)
;   sd a3,24(slot)
;   sd a1,32(slot)
;   sd a3,40(slot)
;   sd a1,48(slot)
;   sd a3,56(slot)
;   sd a1,64(slot)
;   sd a3,72(slot)
;   sd a1,80(slot)
;   sd a3,88(slot)
;   sd a1,96(slot)
;   sd a3,104(slot)
;   sd zero,112(slot)
;   sw zero,120(slot)
;   sh zero,124(slot)
;   sd a1,128(slot)
;   sd a3,136(slot)
;   sd a1,144(slot)
;   sd a3,152(slot)
;   sd a1,160(slot)
;   sd a3,168(slot)
;   sd a1,176(slot)
;   sd a3,184(slot)
;   sd a1,192(slot)
;   sd a3,200(slot)
;   sd a1,208(slot)
;   sd a3,216(slot)
;   sd a1,224(slot)
;   sd a3,232(slot)
;   sd zero,240(slot)
;   sw zero,248(slot)
;   sh zero,252(slot)
;   sd a1,256(slot)
;   sd a3,264(slot)
;   sd a1,272(slot)
;   sd a3,280(slot)
;   sd a1,288(slot)
;   sd a3,296(slot)
;   sd a1,304(slot)
;   sd a3,312(slot)
;   sd a1,320(slot)
;   sd a3,328(slot)
;   sd a1,336(slot)
;   sd a3,344(slot)
;   sd a1,352(slot)
;   sd a3,360(slot)
;   sd zero,368(slot)
;   sw zero,376(slot)
;   sh zero,380(slot)
;   sext.w a3,a2
;   select v12,v15,v15##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v12,v12,v12##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v14,v12,v12##condition=(a3 ne zero)
;   vfsqrt.v v11,v10 #avl=2, #vtype=(e64, m1, ta, ma)
;   lui a1,4095
;   slli a3,a1,39
;   fmv.d.x fa5,a3
;   vfmv.v.f v12,fa5 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmfne.vv v0,v11,v11 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmerge.vvm v15,v11,v12,v0.t #avl=2, #vtype=(e64, m1, ta, ma)
;   vfsqrt.v v11,v15 #avl=2, #vtype=(e64, m1, ta, ma)
;   lui a1,4095
;   slli a3,a1,39
;   fmv.d.x fa5,a3
;   vfmv.v.f v15,fa5 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmfne.vv v0,v11,v11 #avl=2, #vtype=(e64, m1, ta, ma)
;   vmerge.vvm v12,v11,v15,v0.t #avl=2, #vtype=(e64, m1, ta, ma)
;   sext.w a3,a2
;   select v14,v14,v14##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v14,v14,v14##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v14,v14,v14##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v14,v14,v14##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v14,v14,v14##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v14,v14,v14##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v14,v14,v14##condition=(a3 ne zero)
;   sext.w a3,a2
;   select v14,v14,v14##condition=(a3 ne zero)
;   addw a3,a2,a2
;   select v11,v14,v14##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v14,v11,v11##condition=(a3 ne zero)
;   vmax.vv v11,v13,v13 #avl=2, #vtype=(e64, m1, ta, ma)
;   select v13,v14,v14##condition=(a3 ne zero)
;   load_addr a4,3(slot)
;   addi a4,a4,0
;   andi a1,a4,3
;   slli a5,a1,3
;   andi a1,a4,-4
;   atomic_rmw.i8 and a0,a6,(a1)##t0=a4 offset=a5
;   select v10,v13,v13##condition=(a3 ne zero)
;   select v10,v10,v10##condition=(a3 ne zero)
;   select v10,v10,v10##condition=(a3 ne zero)
;   select v10,v10,v10##condition=(a3 ne zero)
;   select v10,v10,v10##condition=(a3 ne zero)
;   select v10,v10,v10##condition=(a3 ne zero)
;   select v10,v10,v10##condition=(a3 ne zero)
;   vse64.v v11,33(slot) #avl=2, #vtype=(e64, m1, ta, ma)
;   select v11,v10,v10##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   select v11,v11,v11##condition=(a3 ne zero)
;   mv a1,a7
;   vse8.v v12,0(a1) #avl=16, #vtype=(e8, m1, ta, ma)
;   vse8.v v11,16(a1) #avl=16, #vtype=(e8, m1, ta, ma)
;   vse8.v v12,32(a1) #avl=16, #vtype=(e8, m1, ta, ma)
;   vse8.v v11,48(a1) #avl=16, #vtype=(e8, m1, ta, ma)
;   vse8.v v11,64(a1) #avl=16, #vtype=(e8, m1, ta, ma)
;   vse8.v v11,80(a1) #avl=16, #vtype=(e8, m1, ta, ma)
;   vse8.v v11,96(a1) #avl=16, #vtype=(e8, m1, ta, ma)
;   addi sp,sp,384
;   ld ra,8(sp)
;   ld fp,0(sp)
;   addi sp,sp,16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   addi sp, sp, -0x10
;   sd ra, 8(sp)
;   sd s0, 0(sp)
;   mv s0, sp
;   addi sp, sp, -0x180
; block1: ; offset 0x14
;   mv a7, a0
;   .byte 0x57, 0x70, 0x08, 0xcc
;   addi t6, sp, 0x190
;   .byte 0x07, 0x85, 0x0f, 0x02
;   addi t6, sp, 0x1a0
;   .byte 0x87, 0x86, 0x0f, 0x02
;   addi t6, sp, 0x1c0
;   .byte 0x87, 0x87, 0x0f, 0x02
;   mv a1, zero
;   mv a3, zero
;   sd a1, 0(sp)
;   sd a3, 8(sp)
;   sd a1, 0x10(sp)
;   sd a3, 0x18(sp)
;   sd a1, 0x20(sp)
;   sd a3, 0x28(sp)
;   sd a1, 0x30(sp)
;   sd a3, 0x38(sp)
;   sd a1, 0x40(sp)
;   sd a3, 0x48(sp)
;   sd a1, 0x50(sp)
;   sd a3, 0x58(sp)
;   sd a1, 0x60(sp)
;   sd a3, 0x68(sp)
;   sd zero, 0x70(sp)
;   sw zero, 0x78(sp)
;   sh zero, 0x7c(sp)
;   sd a1, 0x80(sp)
;   sd a3, 0x88(sp)
;   sd a1, 0x90(sp)
;   sd a3, 0x98(sp)
;   sd a1, 0xa0(sp)
;   sd a3, 0xa8(sp)
;   sd a1, 0xb0(sp)
;   sd a3, 0xb8(sp)
;   sd a1, 0xc0(sp)
;   sd a3, 0xc8(sp)
;   sd a1, 0xd0(sp)
;   sd a3, 0xd8(sp)
;   sd a1, 0xe0(sp)
;   sd a3, 0xe8(sp)
;   sd zero, 0xf0(sp)
;   sw zero, 0xf8(sp)
;   sh zero, 0xfc(sp)
;   sd a1, 0x100(sp)
;   sd a3, 0x108(sp)
;   sd a1, 0x110(sp)
;   sd a3, 0x118(sp)
;   sd a1, 0x120(sp)
;   sd a3, 0x128(sp)
;   sd a1, 0x130(sp)
;   sd a3, 0x138(sp)
;   sd a1, 0x140(sp)
;   sd a3, 0x148(sp)
;   sd a1, 0x150(sp)
;   sd a3, 0x158(sp)
;   sd a1, 0x160(sp)
;   sd a3, 0x168(sp)
;   sd zero, 0x170(sp)
;   sw zero, 0x178(sp)
;   sh zero, 0x17c(sp)
;   sext.w a3, a2
;   .byte 0x57, 0x36, 0xf0, 0x9e
;   bnez a3, 8
;   .byte 0x57, 0x36, 0xf0, 0x9e
;   sext.w a3, a2
;   sext.w a3, a2
;   .byte 0x57, 0x37, 0xc0, 0x9e
;   bnez a3, 8
;   .byte 0x57, 0x37, 0xc0, 0x9e
;   .byte 0x57, 0x70, 0x81, 0xcd
;   .byte 0xd7, 0x15, 0xa0, 0x4e
;   lui a1, 0xfff
;   slli a3, a1, 0x27
;   fmv.d.x fa5, a3
;   .byte 0x57, 0xd6, 0x07, 0x5e
;   .byte 0x57, 0x90, 0xb5, 0x72
;   .byte 0xd7, 0x07, 0xb6, 0x5c
;   .byte 0xd7, 0x15, 0xf0, 0x4e
;   lui a1, 0xfff
;   slli a3, a1, 0x27
;   fmv.d.x fa5, a3
;   .byte 0xd7, 0xd7, 0x07, 0x5e
;   .byte 0x57, 0x90, 0xb5, 0x72
;   .byte 0x57, 0x86, 0xb7, 0x5c
;   sext.w a3, a2
;   sext.w a3, a2
;   sext.w a3, a2
;   sext.w a3, a2
;   sext.w a3, a2
;   sext.w a3, a2
;   sext.w a3, a2
;   sext.w a3, a2
;   addw a3, a2, a2
;   .byte 0xd7, 0x35, 0xe0, 0x9e
;   bnez a3, 8
;   .byte 0xd7, 0x35, 0xe0, 0x9e
;   .byte 0x57, 0x37, 0xb0, 0x9e
;   bnez a3, 8
;   .byte 0x57, 0x37, 0xb0, 0x9e
;   .byte 0xd7, 0x85, 0xd6, 0x1e
;   .byte 0xd7, 0x36, 0xe0, 0x9e
;   bnez a3, 8
;   .byte 0xd7, 0x36, 0xe0, 0x9e
;   addi a4, sp, 3
;   mv a4, a4
;   andi a1, a4, 3
;   slli a5, a1, 3
;   andi a1, a4, -4
;   lr.w.aqrl a0, (a1) ; trap: heap_oob
;   srl a0, a0, a5
;   andi a0, a0, 0xff
;   and a4, a0, a6
;   lr.w.aqrl t5, (a1) ; trap: heap_oob
;   addi t6, zero, 0xff
;   sll t6, t6, a5
;   not t6, t6
;   and t5, t5, t6
;   andi t6, a4, 0xff
;   sll t6, t6, a5
;   or t5, t5, t6
;   sc.w.aqrl a4, t5, (a1) ; trap: heap_oob
;   bnez a4, -0x34
;   .byte 0x57, 0x35, 0xd0, 0x9e
;   bnez a3, 8
;   .byte 0x57, 0x35, 0xd0, 0x9e
;   addi t6, sp, 0x21
;   .byte 0xa7, 0xf5, 0x0f, 0x02
;   .byte 0xd7, 0x35, 0xa0, 0x9e
;   bnez a3, 8
;   .byte 0xd7, 0x35, 0xa0, 0x9e
;   mv a1, a7
;   .byte 0x57, 0x70, 0x08, 0xcc
;   .byte 0x27, 0x86, 0x05, 0x02
;   addi t6, a1, 0x10
;   .byte 0xa7, 0x85, 0x0f, 0x02
;   addi t6, a1, 0x20
;   .byte 0x27, 0x86, 0x0f, 0x02
;   addi t6, a1, 0x30
;   .byte 0xa7, 0x85, 0x0f, 0x02
;   addi t6, a1, 0x40
;   .byte 0xa7, 0x85, 0x0f, 0x02
;   addi t6, a1, 0x50
;   .byte 0xa7, 0x85, 0x0f, 0x02
;   addi t6, a1, 0x60
;   .byte 0xa7, 0x85, 0x0f, 0x02
;   addi sp, sp, 0x180
;   ld ra, 8(sp)
;   ld s0, 0(sp)
;   addi sp, sp, 0x10
;   ret

