test compile precise-output
target s390x

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; IADD
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

function %iadd_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = iadd.i64 v0, v1
  return v2
}

; block0:
;   agr %r2, %r3
;   br %r14

function %iadd_i64_ext32(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
  v2 = sextend.i64 v1
  v3 = iadd.i64 v0, v2
  return v3
}

; block0:
;   agfr %r2, %r3
;   br %r14

function %iadd_i64_imm16(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 1
  v2 = iadd.i64 v0, v1
  return v2
}

; block0:
;   aghi %r2, 1
;   br %r14

function %iadd_i64_imm32(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 32768
  v2 = iadd.i64 v0, v1
  return v2
}

; block0:
;   agfi %r2, 32768
;   br %r14

function %iadd_i64_mem(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3 = iadd.i64 v0, v2
  return v3
}

; block0:
;   ag %r2, 0(%r3)
;   br %r14

function %iadd_i64_mem_ext16(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload16.i64 v1
  v3 = iadd.i64 v0, v2
  return v3
}

; block0:
;   agh %r2, 0(%r3)
;   br %r14

function %iadd_i64_mem_ext32(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload32.i64 v1
  v3 = iadd.i64 v0, v2
  return v3
}

; block0:
;   agf %r2, 0(%r3)
;   br %r14

function %iadd_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = iadd.i32 v0, v1
  return v2
}

; block0:
;   ar %r2, %r3
;   br %r14

function %iadd_i32_imm16(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 1
  v2 = iadd.i32 v0, v1
  return v2
}

; block0:
;   ahi %r2, 1
;   br %r14

function %iadd_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 32768
  v2 = iadd.i32 v0, v1
  return v2
}

; block0:
;   afi %r2, 32768
;   br %r14

function %iadd_i32_mem(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3 = iadd.i32 v0, v2
  return v3
}

; block0:
;   a %r2, 0(%r3)
;   br %r14

function %iadd_i32_memoff(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3 = iadd.i32 v0, v2
  return v3
}

; block0:
;   ay %r2, 4096(%r3)
;   br %r14

function %iadd_i32_mem_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1
  v3 = iadd.i32 v0, v2
  return v3
}

; block0:
;   ah %r2, 0(%r3)
;   br %r14

function %iadd_i32_memoff_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1+4096
  v3 = iadd.i32 v0, v2
  return v3
}

; block0:
;   ahy %r2, 4096(%r3)
;   br %r14

function %iadd_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = iadd.i16 v0, v1
  return v2
}

; block0:
;   ar %r2, %r3
;   br %r14

function %iadd_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 1
  v2 = iadd.i16 v0, v1
  return v2
}

; block0:
;   ahi %r2, 1
;   br %r14

function %iadd_i16_mem(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
  v2 = load.i16 v1
  v3 = iadd.i16 v0, v2
  return v3
}

; block0:
;   ah %r2, 0(%r3)
;   br %r14

function %iadd_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = iadd.i8 v0, v1
  return v2
}

; block0:
;   ar %r2, %r3
;   br %r14

function %iadd_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 1
  v2 = iadd.i8 v0, v1
  return v2
}

; block0:
;   ahi %r2, 1
;   br %r14

function %iadd_i8_mem(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
  v2 = load.i8 v1
  v3 = iadd.i8 v0, v2
  return v3
}

; block0:
;   llc %r4, 0(%r3)
;   ar %r2, %r4
;   br %r14

function %iadd_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2, v3 = iadd_ifcout.i64 v0, v1
  return v2
}

; block0:
;   algr %r2, %r3
;   br %r14

function %iadd_i64_ext32(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
  v2 = uextend.i64 v1
  v3, v4 = iadd_ifcout.i64 v0, v2
  return v3
}

; block0:
;   algfr %r2, %r3
;   br %r14

function %iadd_i64_imm32(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 32768
  v2, v3 = iadd_ifcout.i64 v0, v1
  return v2
}

; block0:
;   algfi %r2, 32768
;   br %r14

function %iadd_i64_mem(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3, v4 = iadd_ifcout.i64 v0, v2
  return v3
}

; block0:
;   lg %r4, 0(%r3)
;   algr %r2, %r4
;   br %r14

function %iadd_i64_mem_ext32(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = uload32.i64 v1
  v3, v4 = iadd_ifcout.i64 v0, v2
  return v3
}

; block0:
;   llgf %r4, 0(%r3)
;   algr %r2, %r4
;   br %r14

function %iadd_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2, v3 = iadd_ifcout.i32 v0, v1
  return v2
}

; block0:
;   alr %r2, %r3
;   br %r14

function %iadd_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 32768
  v2, v3 = iadd_ifcout.i32 v0, v1
  return v2
}

; block0:
;   alfi %r2, 32768
;   br %r14

function %iadd_i32_mem(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3, v4 = iadd_ifcout.i32 v0, v2
  return v3
}

; block0:
;   l %r4, 0(%r3)
;   alr %r2, %r4
;   br %r14

function %iadd_i32_memoff(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3, v4 = iadd_ifcout.i32 v0, v2
  return v3
}

; block0:
;   ly %r4, 4096(%r3)
;   alr %r2, %r4
;   br %r14

function %isub_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = isub.i64 v0, v1
  return v2
}

; block0:
;   sgr %r2, %r3
;   br %r14

function %isub_i64_ext32(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
  v2 = sextend.i64 v1
  v3 = isub.i64 v0, v2
  return v3
}

; block0:
;   sgfr %r2, %r3
;   br %r14

function %isub_i64_imm16(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 1
  v2 = isub.i64 v0, v1
  return v2
}

; block0:
;   aghi %r2, -1
;   br %r14

function %isub_i64_imm32(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 32769
  v2 = isub.i64 v0, v1
  return v2
}

; block0:
;   agfi %r2, -32769
;   br %r14

function %isub_i64_mem(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3 = isub.i64 v0, v2
  return v3
}

; block0:
;   sg %r2, 0(%r3)
;   br %r14

function %isub_i64_mem_ext16(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload16.i64 v1
  v3 = isub.i64 v0, v2
  return v3
}

; block0:
;   sgh %r2, 0(%r3)
;   br %r14

function %isub_i64_mem_ext32(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload32.i64 v1
  v3 = isub.i64 v0, v2
  return v3
}

; block0:
;   sgf %r2, 0(%r3)
;   br %r14

function %isub_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = isub.i32 v0, v1
  return v2
}

; block0:
;   sr %r2, %r3
;   br %r14

function %isub_i32_imm16(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 1
  v2 = isub.i32 v0, v1
  return v2
}

; block0:
;   ahi %r2, -1
;   br %r14

function %isub_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 32769
  v2 = isub.i32 v0, v1
  return v2
}

; block0:
;   afi %r2, -32769
;   br %r14

function %isub_i32_mem(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3 = isub.i32 v0, v2
  return v3
}

; block0:
;   s %r2, 0(%r3)
;   br %r14

function %isub_i32_memoff(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3 = isub.i32 v0, v2
  return v3
}

; block0:
;   sy %r2, 4096(%r3)
;   br %r14

function %isub_i32_mem_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1
  v3 = isub.i32 v0, v2
  return v3
}

; block0:
;   sh %r2, 0(%r3)
;   br %r14

function %isub_i32_memoff_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1+4096
  v3 = isub.i32 v0, v2
  return v3
}

; block0:
;   shy %r2, 4096(%r3)
;   br %r14

function %isub_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = isub.i16 v0, v1
  return v2
}

; block0:
;   sr %r2, %r3
;   br %r14

function %isub_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 1
  v2 = isub.i16 v0, v1
  return v2
}

; block0:
;   ahi %r2, -1
;   br %r14

function %isub_i16_mem(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
  v2 = load.i16 v1
  v3 = isub.i16 v0, v2
  return v3
}

; block0:
;   sh %r2, 0(%r3)
;   br %r14

function %isub_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = isub.i8 v0, v1
  return v2
}

; block0:
;   sr %r2, %r3
;   br %r14

function %isub_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 1
  v2 = isub.i8 v0, v1
  return v2
}

; block0:
;   ahi %r2, -1
;   br %r14

function %isub_i8_mem(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
  v2 = load.i8 v1
  v3 = isub.i8 v0, v2
  return v3
}

; block0:
;   llc %r4, 0(%r3)
;   sr %r2, %r4
;   br %r14

function %iabs_i64(i64) -> i64 {
block0(v0: i64):
  v1 = iabs.i64 v0
  return v1
}

; block0:
;   lpgr %r2, %r2
;   br %r14

function %iabs_i64_ext32(i32) -> i64 {
block0(v0: i32):
  v1 = sextend.i64 v0
  v2 = iabs.i64 v1
  return v2
}

; block0:
;   lpgfr %r2, %r2
;   br %r14

function %iabs_i32(i32) -> i32 {
block0(v0: i32):
  v1 = iabs.i32 v0
  return v1
}

; block0:
;   lpr %r2, %r2
;   br %r14

function %iabs_i16(i16) -> i16 {
block0(v0: i16):
  v1 = iabs.i16 v0
  return v1
}

; block0:
;   lhr %r5, %r2
;   lpr %r2, %r5
;   br %r14

function %iabs_i8(i8) -> i8 {
block0(v0: i8):
  v1 = iabs.i8 v0
  return v1
}

; block0:
;   lbr %r5, %r2
;   lpr %r2, %r5
;   br %r14

function %ineg_i64(i64) -> i64 {
block0(v0: i64):
  v1 = ineg.i64 v0
  return v1
}

; block0:
;   lcgr %r2, %r2
;   br %r14

function %ineg_i64_ext32(i32) -> i64 {
block0(v0: i32):
  v1 = sextend.i64 v0
  v2 = ineg.i64 v1
  return v2
}

; block0:
;   lcgfr %r2, %r2
;   br %r14

function %ineg_i32(i32) -> i32 {
block0(v0: i32):
  v1 = ineg.i32 v0
  return v1
}

; block0:
;   lcr %r2, %r2
;   br %r14

function %ineg_i16(i16) -> i16 {
block0(v0: i16):
  v1 = ineg.i16 v0
  return v1
}

; block0:
;   lcr %r2, %r2
;   br %r14

function %ineg_i8(i8) -> i8 {
block0(v0: i8):
  v1 = ineg.i8 v0
  return v1
}

; block0:
;   lcr %r2, %r2
;   br %r14

function %imul_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = imul.i64 v0, v1
  return v2
}

; block0:
;   msgr %r2, %r3
;   br %r14

function %imul_i64_imm16(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 3
  v2 = imul.i64 v0, v1
  return v2
}

; block0:
;   mghi %r2, 3
;   br %r14

function %imul_i64_imm32(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 32769
  v2 = imul.i64 v0, v1
  return v2
}

; block0:
;   msgfi %r2, 32769
;   br %r14

function %imul_i64_mem(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3 = imul.i64 v0, v2
  return v3
}

; block0:
;   msg %r2, 0(%r3)
;   br %r14

function %imul_i64_mem_ext16(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload16.i64 v1
  v3 = imul.i64 v0, v2
  return v3
}

; block0:
;   mgh %r2, 0(%r3)
;   br %r14

function %imul_i64_mem_ext32(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload32.i64 v1
  v3 = imul.i64 v0, v2
  return v3
}

; block0:
;   msgf %r2, 0(%r3)
;   br %r14

function %imul_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = imul.i32 v0, v1
  return v2
}

; block0:
;   msr %r2, %r3
;   br %r14

function %imul_i32_imm16(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 3
  v2 = imul.i32 v0, v1
  return v2
}

; block0:
;   mhi %r2, 3
;   br %r14

function %imul_i32_imm32(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 32769
  v2 = imul.i32 v0, v1
  return v2
}

; block0:
;   msfi %r2, 32769
;   br %r14

function %imul_i32_mem(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3 = imul.i32 v0, v2
  return v3
}

; block0:
;   ms %r2, 0(%r3)
;   br %r14

function %imul_i32_memoff(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3 = imul.i32 v0, v2
  return v3
}

; block0:
;   msy %r2, 4096(%r3)
;   br %r14

function %imul_i32_mem_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1
  v3 = imul.i32 v0, v2
  return v3
}

; block0:
;   mh %r2, 0(%r3)
;   br %r14

function %imul_i32_memoff_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1+4096
  v3 = imul.i32 v0, v2
  return v3
}

; block0:
;   mhy %r2, 4096(%r3)
;   br %r14

function %imul_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = imul.i16 v0, v1
  return v2
}

; block0:
;   msr %r2, %r3
;   br %r14

function %imul_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 3
  v2 = imul.i16 v0, v1
  return v2
}

; block0:
;   mhi %r2, 3
;   br %r14

function %imul_i16_mem(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
  v2 = load.i16 v1
  v3 = imul.i16 v0, v2
  return v3
}

; block0:
;   mh %r2, 0(%r3)
;   br %r14

function %imul_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = imul.i8 v0, v1
  return v2
}

; block0:
;   msr %r2, %r3
;   br %r14

function %imul_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 3
  v2 = imul.i8 v0, v1
  return v2
}

; block0:
;   mhi %r2, 3
;   br %r14

function %imul_i8_mem(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
  v2 = load.i8 v1
  v3 = imul.i8 v0, v2
  return v3
}

; block0:
;   llc %r4, 0(%r3)
;   msr %r2, %r4
;   br %r14

function %umulhi_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = umulhi.i64 v0, v1
  return v2
}

; block0:
;   lgr %r1, %r3
;   mlgr %r0, %r2
;   lgr %r2, %r0
;   br %r14

function %umulhi_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = umulhi.i32 v0, v1
  return v2
}

; block0:
;   lgr %r4, %r3
;   llgfr %r3, %r2
;   lgr %r2, %r4
;   llgfr %r5, %r2
;   msgr %r3, %r5
;   srlg %r2, %r3, 32
;   br %r14

function %umulhi_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = umulhi.i16 v0, v1
  return v2
}

; block0:
;   lgr %r4, %r3
;   llhr %r3, %r2
;   lgr %r2, %r4
;   llhr %r5, %r2
;   msr %r3, %r5
;   srlk %r2, %r3, 16
;   br %r14

function %umulhi_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = umulhi.i8 v0, v1
  return v2
}

; block0:
;   lgr %r4, %r3
;   llcr %r3, %r2
;   lgr %r2, %r4
;   llcr %r5, %r2
;   msr %r3, %r5
;   srlk %r2, %r3, 8
;   br %r14

function %smulhi_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = smulhi.i64 v0, v1
  return v2
}

; block0:
;   mgrk %r0, %r2, %r3
;   lgr %r2, %r0
;   br %r14

function %smulhi_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = smulhi.i32 v0, v1
  return v2
}

; block0:
;   lgr %r4, %r3
;   lgfr %r3, %r2
;   lgr %r2, %r4
;   lgfr %r5, %r2
;   msgr %r3, %r5
;   srag %r2, %r3, 32
;   br %r14

function %smulhi_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = smulhi.i16 v0, v1
  return v2
}

; block0:
;   lgr %r4, %r3
;   lhr %r3, %r2
;   lgr %r2, %r4
;   lhr %r5, %r2
;   msr %r3, %r5
;   srak %r2, %r3, 16
;   br %r14

function %smulhi_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = smulhi.i8 v0, v1
  return v2
}

; block0:
;   lgr %r4, %r3
;   lbr %r3, %r2
;   lgr %r2, %r4
;   lbr %r5, %r2
;   msr %r3, %r5
;   srak %r2, %r3, 8
;   br %r14

function %sdiv_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sdiv.i64 v0, v1
  return v2
}

; block0:
;   lgr %r1, %r2
;   llihf %r4, 2147483647
;   iilf %r4, 4294967295
;   xgr %r4, %r1
;   ngrk %r5, %r4, %r3
;   cgite %r5, -1
;   dsgr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %sdiv_i64_imm(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 2
  v2 = sdiv.i64 v0, v1
  return v2
}

; block0:
;   lgr %r1, %r2
;   lghi %r2, 2
;   dsgr %r0, %r2
;   lgr %r2, %r1
;   br %r14

function %sdiv_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = sdiv.i32 v0, v1
  return v2
}

; block0:
;   lgfr %r1, %r2
;   iilf %r4, 2147483647
;   xrk %r2, %r4, %r1
;   nrk %r4, %r2, %r3
;   cite %r4, -1
;   dsgfr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %sdiv_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 2
  v2 = sdiv.i32 v0, v1
  return v2
}

; block0:
;   lgfr %r1, %r2
;   lhi %r2, 2
;   dsgfr %r0, %r2
;   lgr %r2, %r1
;   br %r14

function %sdiv_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = sdiv.i16 v0, v1
  return v2
}

; block0:
;   lghr %r1, %r2
;   lhr %r4, %r3
;   lhi %r2, 32767
;   xrk %r5, %r2, %r1
;   nrk %r2, %r5, %r4
;   cite %r2, -1
;   dsgfr %r0, %r4
;   lgr %r2, %r1
;   br %r14

function %sdiv_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 2
  v2 = sdiv.i16 v0, v1
  return v2
}

; block0:
;   lghr %r1, %r2
;   lhi %r2, 2
;   dsgfr %r0, %r2
;   lgr %r2, %r1
;   br %r14

function %sdiv_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = sdiv.i8 v0, v1
  return v2
}

; block0:
;   lgbr %r1, %r2
;   lbr %r4, %r3
;   lhi %r2, 127
;   xrk %r5, %r2, %r1
;   nrk %r2, %r5, %r4
;   cite %r2, -1
;   dsgfr %r0, %r4
;   lgr %r2, %r1
;   br %r14

function %sdiv_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 2
  v2 = sdiv.i8 v0, v1
  return v2
}

; block0:
;   lgbr %r1, %r2
;   lhi %r2, 2
;   dsgfr %r0, %r2
;   lgr %r2, %r1
;   br %r14

function %udiv_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = udiv.i64 v0, v1
  return v2
}

; block0:
;   lghi %r0, 0
;   lgr %r1, %r2
;   dlgr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i64_imm(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 2
  v2 = udiv.i64 v0, v1
  return v2
}

; block0:
;   lghi %r0, 0
;   lgr %r1, %r2
;   lghi %r3, 2
;   dlgr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = udiv.i32 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   lgr %r1, %r2
;   dlr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 2
  v2 = udiv.i32 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   lgr %r1, %r2
;   lhi %r3, 2
;   dlr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = udiv.i16 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llhr %r1, %r2
;   llhr %r5, %r3
;   dlr %r0, %r5
;   lgr %r2, %r1
;   br %r14

function %udiv_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 2
  v2 = udiv.i16 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llhr %r1, %r2
;   lhi %r3, 2
;   dlr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = udiv.i8 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llcr %r1, %r2
;   llcr %r5, %r3
;   dlr %r0, %r5
;   lgr %r2, %r1
;   br %r14

function %udiv_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 2
  v2 = udiv.i8 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llcr %r1, %r2
;   lhi %r3, 2
;   dlr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %srem_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = srem.i64 v0, v1
  return v2
}

; block0:
;   lgr %r1, %r2
;   cghi %r3, -1
;   locghie %r1, 0
;   dsgr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %srem_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = srem.i32 v0, v1
  return v2
}

; block0:
;   lgfr %r1, %r2
;   dsgfr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %srem_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = srem.i16 v0, v1
  return v2
}

; block0:
;   lghr %r1, %r2
;   lhr %r4, %r3
;   dsgfr %r0, %r4
;   lgr %r2, %r0
;   br %r14

function %srem_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = srem.i8 v0, v1
  return v2
}

; block0:
;   lgbr %r1, %r2
;   lbr %r4, %r3
;   dsgfr %r0, %r4
;   lgr %r2, %r0
;   br %r14

function %urem_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = urem.i64 v0, v1
  return v2
}

; block0:
;   lghi %r0, 0
;   lgr %r1, %r2
;   dlgr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %urem_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = urem.i32 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   lgr %r1, %r2
;   dlr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %urem_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = urem.i16 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llhr %r1, %r2
;   llhr %r5, %r3
;   dlr %r0, %r5
;   lgr %r2, %r0
;   br %r14

function %urem_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = urem.i8 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llcr %r1, %r2
;   llcr %r5, %r3
;   dlr %r0, %r5
;   lgr %r2, %r0
;   br %r14

