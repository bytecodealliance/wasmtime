test compile precise-output
target s390x

function %vany_true_i64x2(i64x2) -> b1 {
block0(v0: i64x2):
    v1 = vany_true v0
    return v1
}

; block0:
;   vgbm %v3, 0
;   vceqgs %v5, %v24, %v3
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_i32x4(i32x4) -> b1 {
block0(v0: i32x4):
    v1 = vany_true v0
    return v1
}

; block0:
;   vgbm %v3, 0
;   vceqfs %v5, %v24, %v3
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_i16x8(i16x8) -> b1 {
block0(v0: i16x8):
    v1 = vany_true v0
    return v1
}

; block0:
;   vgbm %v3, 0
;   vceqhs %v5, %v24, %v3
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_i8x16(i8x16) -> b1 {
block0(v0: i8x16):
    v1 = vany_true v0
    return v1
}

; block0:
;   vgbm %v3, 0
;   vceqbs %v5, %v24, %v3
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vall_true_i64x2(i64x2) -> b1 {
block0(v0: i64x2):
    v1 = vall_true v0
    return v1
}

; block0:
;   vgbm %v3, 0
;   vceqgs %v5, %v24, %v3
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_i32x4(i32x4) -> b1 {
block0(v0: i32x4):
    v1 = vall_true v0
    return v1
}

; block0:
;   vgbm %v3, 0
;   vceqfs %v5, %v24, %v3
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_i16x8(i16x8) -> b1 {
block0(v0: i16x8):
    v1 = vall_true v0
    return v1
}

; block0:
;   vgbm %v3, 0
;   vceqhs %v5, %v24, %v3
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_i8x16(i8x16) -> b1 {
block0(v0: i8x16):
    v1 = vall_true v0
    return v1
}

; block0:
;   vgbm %v3, 0
;   vceqbs %v5, %v24, %v3
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vany_true_icmp_eq_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp eq v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vceqgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_icmp_ne_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp ne v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vceqgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_icmp_sgt_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp sgt v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vchgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_icmp_sle_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp sle v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vchgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_icmp_slt_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp slt v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vchgs %v5, %v25, %v24
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_icmp_sge_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp sge v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vchgs %v5, %v25, %v24
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_icmp_ugt_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp ugt v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vchlgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_icmp_ule_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp ule v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vchlgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_icmp_ult_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp ult v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vchlgs %v5, %v25, %v24
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_icmp_uge_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp uge v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vchlgs %v5, %v25, %v24
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_fcmp_eq_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp eq v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfcedbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_fcmp_ne_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ne v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfcedbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_fcmp_gt_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp gt v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfchdbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_fcmp_ule_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ule v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfchdbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_fcmp_ge_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ge v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfchedbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_fcmp_ult_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ult v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfchedbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_fcmp_lt_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp lt v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfchdbs %v5, %v25, %v24
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_fcmp_uge_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp uge v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfchdbs %v5, %v25, %v24
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vany_true_fcmp_le_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp le v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfchedbs %v5, %v25, %v24
;   lhi %r2, 0
;   lochino %r2, 1
;   br %r14

function %vany_true_fcmp_ugt_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ugt v0, v1
    v3 = vany_true v2
    return v3
}

; block0:
;   vfchedbs %v5, %v25, %v24
;   lhi %r2, 0
;   lochine %r2, 1
;   br %r14

function %vall_true_icmp_eq_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp eq v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vceqgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_icmp_ne_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp ne v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vceqgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_icmp_sgt_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp sgt v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vchgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_icmp_sle_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp sle v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vchgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_icmp_slt_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp slt v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vchgs %v5, %v25, %v24
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_icmp_sge_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp sge v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vchgs %v5, %v25, %v24
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_icmp_ugt_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp ugt v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vchlgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_icmp_ule_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp ule v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vchlgs %v5, %v24, %v25
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_icmp_ult_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp ult v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vchlgs %v5, %v25, %v24
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_icmp_uge_i64x2(i64x2, i64x2) -> b1 {
block0(v0: i64x2, v1: i64x2):
    v2 = icmp uge v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vchlgs %v5, %v25, %v24
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_fcmp_eq_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp eq v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfcedbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_fcmp_ne_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ne v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfcedbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_fcmp_gt_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp gt v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfchdbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_fcmp_ule_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ule v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfchdbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_fcmp_ge_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ge v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfchedbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_fcmp_ult_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ult v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfchedbs %v5, %v24, %v25
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_fcmp_lt_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp lt v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfchdbs %v5, %v25, %v24
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_fcmp_uge_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp uge v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfchdbs %v5, %v25, %v24
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vall_true_fcmp_le_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp le v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfchedbs %v5, %v25, %v24
;   lhi %r2, 0
;   lochie %r2, 1
;   br %r14

function %vall_true_fcmp_ugt_f64x2(f64x2, f64x2) -> b1 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp ugt v0, v1
    v3 = vall_true v2
    return v3
}

; block0:
;   vfchedbs %v5, %v25, %v24
;   lhi %r2, 0
;   lochio %r2, 1
;   br %r14

function %vhigh_bits(i64x2) -> i64 {
block0(v0: i64x2):
  v1 = vhigh_bits.i64 v0
  return v1
}

; block0:
;   bras %r1, 20 ; data.u128 0x80808080808080808080808080800040 ; vl %v3, 0(%r1)
;   vbperm %v5, %v24, %v3
;   lgdr %r2, %f5
;   br %r14

function %vhigh_bits(i32x4) -> i64 {
block0(v0: i32x4):
  v1 = vhigh_bits.i64 v0
  return v1
}

; block0:
;   bras %r1, 20 ; data.u128 0x80808080808080808080808000204060 ; vl %v3, 0(%r1)
;   vbperm %v5, %v24, %v3
;   lgdr %r2, %f5
;   br %r14

function %vhigh_bits(i16x8) -> i64 {
block0(v0: i16x8):
  v1 = vhigh_bits.i64 v0
  return v1
}

; block0:
;   bras %r1, 20 ; data.u128 0x80808080808080800010203040506070 ; vl %v3, 0(%r1)
;   vbperm %v5, %v24, %v3
;   lgdr %r2, %f5
;   br %r14

function %vhigh_bits(i8x16) -> i64 {
block0(v0: i8x16):
  v1 = vhigh_bits.i64 v0
  return v1
}

; block0:
;   bras %r1, 20 ; data.u128 0x00081018202830384048505860687078 ; vl %v3, 0(%r1)
;   vbperm %v5, %v24, %v3
;   lgdr %r2, %f5
;   br %r14

