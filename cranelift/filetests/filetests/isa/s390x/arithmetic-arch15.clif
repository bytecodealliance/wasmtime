test compile precise-output
set enable_multi_ret_implicit_sret
target s390x arch15

function %imul_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = imul.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmlq %v6, %v1, %v3
;   vst %v6, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vml %v6, %v1, %v3, 4
;   vst %v6, 0(%r2)
;   br %r14

function %mul_uextend_i64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = imul v2, v3
    return v4
}

; VCode:
; block0:
;   lgr %r5, %r2
;   mlgr %r2, %r4
;   vlvgp %v7, %r2, %r3
;   lgr %r2, %r5
;   vst %v7, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   lgr %r5, %r2
;   mlgr %r2, %r4
;   vlvgp %v7, %r2, %r3
;   lgr %r2, %r5
;   vst %v7, 0(%r2)
;   br %r14

function %mul_sextend_i64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = sextend.i128 v0
    v3 = sextend.i128 v1
    v4 = imul v2, v3
    return v4
}

; VCode:
; block0:
;   lgr %r5, %r2
;   mgrk %r2, %r3, %r4
;   vlvgp %v7, %r2, %r3
;   lgr %r2, %r5
;   vst %v7, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   lgr %r5, %r2
;   mgrk %r2, %r3, %r4
;   vlvgp %v7, %r2, %r3
;   lgr %r2, %r5
;   vst %v7, 0(%r2)
;   br %r14

function %sdiv_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = sdiv.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vlcq %v6, %v3
;   veval %v16, %v1, %v3, %v6, 9
;   vrepib %v18, 255
;   vecq %v16, %v18
;   jge .+2 # trap=int_ovf
;   vdq %v22, %v1, %v3, 0
;   vst %v22, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vlc %v6, %v3, 4
;   .byte 0xe7, 0x01
;   lper %f0, %f9
;   ld %f8, 0x720(%r8, %r14)
;   .byte 0x00, 0xff
;   .byte 0x08, 0x45
;   vec %v16, %v18, 4
;   jge 0x26 ; trap: int_ovf
;   .byte 0xe7, 0x61
;   lper %f0, %f0
;   lh %r11, 0x760(%r2, %r14) ; trap: int_divz
;   lpdr %f0, %f0
;   .byte 0x08, 0x0e
;   br %r14

function %udiv_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = udiv.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vdlq %v6, %v1, %v3, 0
;   vst %v6, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   .byte 0xe7, 0x61
;   lper %f0, %f0
;   sth %r11, 0x760(%r14) ; trap: int_divz
;   lpdr %f0, %f0
;   .byte 0x00, 0x0e
;   br %r14

function %srem_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = srem.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v6, 0(%r3)
;   vl %v3, 0(%r4)
;   vrepib %v7, 255
;   vgbm %v16, 0
;   vecq %v3, %v7
;   jne 10 ; vlr %v6, %v16
;   vrq %v21, %v6, %v3, 0
;   vst %v21, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v6, 0(%r3)
;   vl %v3, 0(%r4)
;   vrepib %v7, 0xff
;   vzero %v16
;   vec %v3, %v7, 4
;   jne 0x28
;   vlr %v6, %v16
;   .byte 0xe7, 0x56
;   lper %f0, %f0
;   lh %r11, 0x750(%r3, %r14) ; trap: int_divz
;   lpdr %f0, %f0
;   .byte 0x08, 0x0e
;   br %r14

function %urem_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = urem.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vrlq %v6, %v1, %v3, 0
;   vst %v6, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   .byte 0xe7, 0x61
;   lper %f0, %f0
;   sth %r11, 0x760(%r1, %r14) ; trap: int_divz
;   lpdr %f0, %f0
;   .byte 0x00, 0x0e
;   br %r14

function %umax_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = umax.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmxlq %v6, %v1, %v3
;   vst %v6, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmxl %v6, %v1, %v3, 4
;   vst %v6, 0(%r2)
;   br %r14

function %umin_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = umin.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmnlq %v6, %v1, %v3
;   vst %v6, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmnl %v6, %v1, %v3, 4
;   vst %v6, 0(%r2)
;   br %r14

function %smax_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = smax.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmxq %v6, %v1, %v3
;   vst %v6, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmx %v6, %v1, %v3, 4
;   vst %v6, 0(%r2)
;   br %r14

function %smin_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = smin.i128 v0, v1
  return v2
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmnq %v6, %v1, %v3
;   vst %v6, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vl %v3, 0(%r4)
;   vmn %v6, %v1, %v3, 4
;   vst %v6, 0(%r2)
;   br %r14


function %iabs_i128(i128) -> i128 {
block0(v0: i128):
  v1 = iabs.i128 v0
  return v1
}   

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vlpq %v4, %v1
;   vst %v4, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vlp %v4, %v1, 4
;   vst %v4, 0(%r2)
;   br %r14

function %ineg_i128(i128) -> i128 {
block0(v0: i128):
  v1 = ineg.i128 v0
  return v1
}

; VCode:
; block0:
;   vl %v1, 0(%r3)
;   vlcq %v4, %v1
;   vst %v4, 0(%r2)
;   br %r14
;
; Disassembled:
; block0: ; offset 0x0
;   vl %v1, 0(%r3)
;   vlc %v4, %v1, 4
;   vst %v4, 0(%r2)
;   br %r14

