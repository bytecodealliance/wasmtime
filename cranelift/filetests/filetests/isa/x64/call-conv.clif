test compile
target x86_64 machinst

;; system_v has first param in %rdi, fascall in %rcx
function %one_arg(i32) system_v {
    sig0 = (i32) windows_fastcall
block0(v0: i32):
    ; check:  movq    %rdi, %rcx
    ; nextln: call    *%rdi
    call_indirect sig0, v0(v0)
    return
}

;; system_v has params in %rdi, %xmm0, fascall in %rcx, %xmm1
function %two_args(i32, f32) system_v {
    sig0 = (i32, f32) windows_fastcall
    sig1 = (i32, f32) system_v
block0(v0: i32, v1: f32):
    ; check:  movq    %rdi, %rsi
    ; check:  movaps  %xmm0, %xmm6
    ; check:  movq    %rsi, %rcx
    ; nextln: movaps  %xmm6, %xmm1
    ; nextln: call    *%rsi
    call_indirect sig0, v0(v0, v1)

    ; check:  movq    %rsi, %rdi
    ; nextln: movaps  %xmm6, %xmm0
    ; nextln: call    *%rsi
    call_indirect sig1, v0(v0, v1)
    return
}

;; fastcall preserves xmm6+, rbx, rbp, rdi, rsi, r12-r15
;; system_v preserves no xmm registers, rbx, rbp, r12-r15
function %fastcall_to_systemv(i32) windows_fastcall {
    sig0 = () system_v
block0(v0: i32):
    ; check:  pushq   %rbp
    ; nextln: movq    %rsp, %rbp
    ; nextln: subq    $$176, %rsp
    ; nextln: movdqu  %xmm6, 0(%rsp)
    ; nextln: movdqu  %xmm7, 16(%rsp)
    ; nextln: movdqu  %xmm8, 32(%rsp)
    ; nextln: movdqu  %xmm9, 48(%rsp)
    ; nextln: movdqu  %xmm10, 64(%rsp)
    ; nextln: movdqu  %xmm11, 80(%rsp)
    ; nextln: movdqu  %xmm12, 96(%rsp)
    ; nextln: movdqu  %xmm13, 112(%rsp)
    ; nextln: movdqu  %xmm14, 128(%rsp)
    ; nextln: movdqu  %xmm15, 144(%rsp)
    ; nextln: movq    %rsi, 160(%rsp)
    ; nextln: movq    %rdi, 168(%rsp)
    ; nextln: call    *%rcx
    ; nextln: movdqu  0(%rsp), %xmm6
    ; nextln: movdqu  16(%rsp), %xmm7
    ; nextln: movdqu  32(%rsp), %xmm8
    ; nextln: movdqu  48(%rsp), %xmm9
    ; nextln: movdqu  64(%rsp), %xmm10
    ; nextln: movdqu  80(%rsp), %xmm11
    ; nextln: movdqu  96(%rsp), %xmm12
    ; nextln: movdqu  112(%rsp), %xmm13
    ; nextln: movdqu  128(%rsp), %xmm14
    ; nextln: movdqu  144(%rsp), %xmm15
    ; nextln: movq    160(%rsp), %rsi
    ; nextln: movq    168(%rsp), %rdi
    ; nextln: addq    $$176, %rsp
    ; nextln: movq    %rbp, %rsp
    ; nextln: popq    %rbp
    ; nextln: ret
    call_indirect sig0, v0()
    return
}

function %many_args(
    ;; rdi, rsi, rdx, rcx, r8, r9,
    i64, i64, i64, i64, i64, i64,

    ;; xmm0-7
    f64, f64, f64, f64, f64, f64, f64, f64,

    ;; stack args
    i64, i32, f32, f64
) system_v {
    sig0 = (
      i64, i64, i64, i64, i64, i64, f64, f64, f64, f64, f64, f64, f64, f64, i64,
      i32, f32, f64
    ) windows_fastcall
block0(
      v0: i64, v1:i64, v2:i64, v3:i64,
      v4:i64, v5:i64,
      v6: f64, v7: f64, v8:f64, v9:f64, v10:f64, v11:f64, v12:f64, v13:f64,
      v14:i64, v15:i32, v16:f32, v17:f64
):
    ; check:  pushq   %rbp
    ; nextln: movq    %rsp, %rbp
    ; nextln: subq    $$32, %rsp
    ; nextln: movq    %r12, 0(%rsp)
    ; nextln: movq    %r13, 8(%rsp)
    ; nextln: movq    %r14, 16(%rsp)
    ; nextln: movq    %rdx, %rax
    ; nextln: movq    %rcx, %r10
    ; nextln: movq    %r8, %r11
    ; nextln: movq    %r9, %r12
    ; nextln: movq    16(%rbp), %r13
    ; nextln: movq    24(%rbp), %r14
    ; nextln: movss   32(%rbp), %xmm8
    ; nextln: movsd   40(%rbp), %xmm9
    ; nextln: subq    $$144, %rsp
    ; nextln: virtual_sp_offset_adjust 144
    ; nextln: movq    %rdi, %rcx
    ; nextln: movq    %rsi, %rdx
    ; nextln: movq    %rax, %r8
    ; nextln: movq    %r10, %r9
    ; nextln: movq    %r11, 32(%rsp)
    ; nextln: movq    %r12, 40(%rsp)
    ; nextln: movsd   %xmm0, 48(%rsp)
    ; nextln: movsd   %xmm1, 56(%rsp)
    ; nextln: movsd   %xmm2, 64(%rsp)
    ; nextln: movsd   %xmm3, 72(%rsp)
    ; nextln: movsd   %xmm4, 80(%rsp)
    ; nextln: movsd   %xmm5, 88(%rsp)
    ; nextln: movsd   %xmm6, 96(%rsp)
    ; nextln: movsd   %xmm7, 104(%rsp)
    ; nextln: movq    %r13, 112(%rsp)
    ; nextln: movl    %r14d, 120(%rsp)
    ; nextln: movss   %xmm8, 128(%rsp)
    ; nextln: movsd   %xmm9, 136(%rsp)
    ; nextln: call    *%rdi
    ; nextln: addq    $$144, %rsp
    ; nextln: virtual_sp_offset_adjust -144
    ; nextln: movq    0(%rsp), %r12
    ; nextln: movq    8(%rsp), %r13
    ; nextln: movq    16(%rsp), %r14
    ; nextln: addq    $$32, %rsp
    ; nextln: movq    %rbp, %rsp
    ; nextln: popq    %rbp
    ; nextln: ret
    call_indirect sig0, v0(
      v0, v1, v2, v3,
      v4, v5, v6, v7,
      v8, v9, v10, v11,
      v12, v13, v14, v15,
      v16, v17
    )
    return
}

; rdi => rcx
; rsi => rdx
; rdx => r8
; rcx => r9
; r8 => stack
function %many_ints(i64, i64, i64, i64, i64) system_v {
    sig0 = (i64, i64, i64, i64, i64) windows_fastcall
block0(v0: i64, v1:i64, v2:i64, v3:i64, v4:i64):
    ; check:  pushq   %rbp
    ; nextln: movq    %rsp, %rbp
    ; nextln: movq    %rdx, %rax
    ; nextln: movq    %rcx, %r9
    ; nextln: movq    %r8, %r10
    ; nextln: subq    $$48, %rsp
    ; nextln: virtual_sp_offset_adjust 48
    ; nextln: movq    %rdi, %rcx
    ; nextln: movq    %rsi, %rdx
    ; nextln: movq    %rax, %r8
    ; nextln: movq    %r10, 32(%rsp)
    ; nextln: call    *%rdi
    ; nextln: addq    $$48, %rsp
    ; nextln: virtual_sp_offset_adjust -48
    ; nextln: movq    %rbp, %rsp
    ; nextln: popq    %rbp
    ; nextln: ret
    call_indirect sig0, v0(v0, v1, v2, v3, v4)
    return
}

function %many_args2(i32, f32, i64, f64, i32, i32, i32, f32, f64, f32, f64) system_v {
    sig0 = (i32, f32, i64, f64, i32, i32, i32, f32, f64, f32, f64) windows_fastcall
block0(v0: i32, v1: f32, v2: i64, v3: f64, v4: i32, v5: i32, v6: i32, v7: f32, v8: f64, v9: f32, v10: f64):
    ; check:   pushq   %rbp
    ; nextln:  movq    %rsp, %rbp
    ; nextln:  movaps  %xmm1, %xmm6
    ; nextln:  movq    %rcx, %rax
    ; nextln:  movq    %r8, %r9
    ; nextln:  movaps  %xmm3, %xmm7
    ; nextln:  subq    $$96, %rsp
    ; nextln:  virtual_sp_offset_adjust 96
    ; nextln:  movq    %rdi, %rcx
    ; nextln:  movaps  %xmm0, %xmm1
    ; nextln:  movq    %rsi, %r8
    ; nextln:  movaps  %xmm6, %xmm3
    ; nextln:  movl    %edx, 32(%rsp)
    ; nextln:  movl    %eax, 40(%rsp)
    ; nextln:  movl    %r9d, 48(%rsp)
    ; nextln:  movss   %xmm2, 56(%rsp)
    ; nextln:  movsd   %xmm7, 64(%rsp)
    ; nextln:  movss   %xmm4, 72(%rsp)
    ; nextln:  movsd   %xmm5, 80(%rsp)
    ; nextln:  call    *%rdi
    ; nextln:  addq    $$96, %rsp
    ; nextln:  virtual_sp_offset_adjust -96
    ; nextln:  movq    %rbp, %rsp
    ; nextln:  popq    %rbp
    ; nextln:  ret
    call_indirect sig0, v0(v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10)
    return
}

function %wasmtime_mix1(i32) wasmtime_system_v {
    sig0 = (i32) system_v
block0(v0: i32):
    ; check:  movq    %rdi, %rsi
    ; nextln: movq    %rsi, %rdi
    ; nextln: call    *%rsi
    call_indirect sig0, v0(v0)
    return
}

function %wasmtime_mix2(i32) system_v {
    sig0 = (i32) wasmtime_system_v
block0(v0: i32):
    ; check:  movq    %rdi, %rsi
    ; nextln: movq    %rsi, %rdi
    ; nextln: call    *%rsi
    call_indirect sig0, v0(v0)
    return
}

function %wasmtime_mix2() -> i32, i32 system_v {
    sig0 = () -> i32, i32 wasmtime_system_v
block0:
    ; check:  pushq   %rbp
    ; nextln: movq    %rsp, %rbp
    ; nextln: movl    $$1, %esi
    ; nextln: subq    $$16, %rsp
    ; nextln: virtual_sp_offset_adjust 16
    ; nextln: lea     0(%rsp), %rdi
    ; nextln: call    *%rsi
    ; nextln: movq    0(%rsp), %rsi
    ; nextln: addq    $$16, %rsp
    ; nextln: virtual_sp_offset_adjust -16
    ; nextln: movq    %rsi, %rdx
    ; nextln: movq    %rbp, %rsp
    ; nextln: popq    %rbp
    ; nextln: ret
    v2 = iconst.i32 1
    v0, v1 = call_indirect sig0, v2()
    return v0, v1
}

function %wasmtime_mix3() -> i32, i32 wasmtime_system_v {
    sig0 = () -> i32, i32 system_v
block0:
    ; check:  pushq   %rbp
    ; nextln: movq    %rsp, %rbp
    ; nextln: subq    $$16, %rsp
    ; nextln: movq    %r12, 0(%rsp)
    ; nextln: movq    %rdi, %r12
    ; nextln: movl    $$1, %esi
    ; nextln: call    *%rsi
    ; nextln: movl    %edx, 0(%r12)
    ; nextln: movq    0(%rsp), %r12
    ; nextln: addq    $$16, %rsp
    ; nextln: movq    %rbp, %rsp
    ; nextln: popq    %rbp
    ; nextln: ret
    v2 = iconst.i32 1
    v0, v1 = call_indirect sig0, v2()
    return v0, v1
}

function %wasmtime_mix4() -> i32, i64, i32 wasmtime_system_v {
    sig0 = () -> i32, i64, i32 system_v
block0:
    ; check:  pushq   %rbp
    ; nextln: movq    %rsp, %rbp
    ; nextln: subq    $$16, %rsp
    ; nextln: movq    %r12, 0(%rsp)
    ; nextln: movq    %rdi, %r12
    ; nextln: movl    $$1, %esi
    ; nextln: subq    $$16, %rsp
    ; nextln: virtual_sp_offset_adjust 16
    ; nextln: lea     0(%rsp), %rdi
    ; nextln: call    *%rsi
    ; nextln: movq    0(%rsp), %rsi
    ; nextln: addq    $$16, %rsp
    ; nextln: virtual_sp_offset_adjust -16
    ; nextln: movq    %rdx, 0(%r12)
    ; nextln: movl    %esi, 8(%r12)
    ; nextln: movq    0(%rsp), %r12
    ; nextln: addq    $$16, %rsp
    ; nextln: movq    %rbp, %rsp
    ; nextln: popq    %rbp
    ; nextln: ret
    v3 = iconst.i32 1
    v0, v1, v2 = call_indirect sig0, v3()
    return v0, v1, v2
}

function %wasmtime_mix5() -> f32, i64, i32, f32 wasmtime_system_v {
    sig0 = () -> f32, i64, i32, f32 system_v
block0:
    ; check:  pushq   %rbp
    ; nextln: movq    %rsp, %rbp
    ; nextln: subq    $$16, %rsp
    ; nextln: movq    %r12, 0(%rsp)
    ; nextln: movq    %rdi, %r12
    ; nextln: movl    $$1, %esi
    ; nextln: call    *%rsi
    ; nextln: movq    %rax, 0(%r12)
    ; nextln: movl    %edx, 8(%r12)
    ; nextln: movss   %xmm1, 12(%r12)
    ; nextln: movq    0(%rsp), %r12
    ; nextln: addq    $$16, %rsp
    ; nextln: movq    %rbp, %rsp
    ; nextln: popq    %rbp
    ; nextln: ret
    v5 = iconst.i32 1
    v0, v1, v2, v3 = call_indirect sig0, v5()
    return v0, v1, v2, v3
}

function %wasmtime_mix6(f32, i64, i32, f32) -> f32, i64, i32, f32 wasmtime_system_v {
    sig0 = (f32, i64, i32, f32) -> f32, i64, i32, f32 system_v
block0(v0: f32, v1: i64, v2: i32, v3: f32):
    ; check:  pushq   %rbp
    ; nextln: movq    %rsp, %rbp
    ; nextln: subq    $$16, %rsp
    ; nextln: movq    %r12, 0(%rsp)
    ; nextln: movq    %rdx, %r12
    ; nextln: movl    $$1, %eax
    ; nextln: call    *%rax
    ; nextln: movq    %rax, 0(%r12)
    ; nextln: movl    %edx, 8(%r12)
    ; nextln: movss   %xmm1, 12(%r12)
    ; nextln: movq    0(%rsp), %r12
    ; nextln: addq    $$16, %rsp
    ; nextln: movq    %rbp, %rsp
    ; nextln: popq    %rbp
    ; nextln: ret
    v4 = iconst.i32 1
    v5, v6, v7, v8 = call_indirect sig0, v4(v0, v1, v2, v3)
    return v5, v6, v7, v8
}
