test compile precise-output
target x86_64

function %one_arg(i32) system_v {
    ;; system_v has first param in %rdi, fascall in %rcx
    sig0 = (i32) windows_fastcall
block0(v0: i32):
    call_indirect sig0, v0(v0)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $32, %rsp
;   virtual_sp_offset_adjust 32
; block0:
;   movq    %rdi, %rcx
;   call    *%rcx
;   addq    %rsp, $32, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x20, %rsp
; block1: ; offset 0x8
;   movq %rdi, %rcx
;   callq *%rcx
;   addq $0x20, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %two_args(i32, f32) system_v {
    ;; system_v has params in %rdi, %xmm0, fascall in %rcx, %xmm1
    sig0 = (i32, f32) windows_fastcall
    sig1 = (i32, f32) system_v
block0(v0: i32, v1: f32):
    call_indirect sig0, v0(v0, v1)
    call_indirect sig1, v0(v0, v1)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $32, %rsp
;   virtual_sp_offset_adjust 32
; block0:
;   movdqa  %xmm0, %xmm6
;   movq    %rdi, %rcx
;   movdqa  %xmm6, %xmm1
;   call    *%rdi
;   movdqa  %xmm6, %xmm0
;   call    *%rdi
;   addq    %rsp, $32, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x20, %rsp
; block1: ; offset 0x8
;   movdqa %xmm0, %xmm6
;   movq %rdi, %rcx
;   movdqa %xmm6, %xmm1
;   callq *%rdi
;   movdqa %xmm6, %xmm0
;   callq *%rdi
;   addq $0x20, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %fastcall_to_systemv(i32) windows_fastcall {
    ;; fastcall preserves xmm6+, rbx, rbp, rdi, rsi, r12-r15
    ;; system_v preserves no xmm registers, rbx, rbp, r12-r15
    sig0 = () system_v
block0(v0: i32):
    call_indirect sig0, v0()
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $176, %rsp
;   movq    %rsi, 0(%rsp)
;   movq    %rdi, 8(%rsp)
;   movdqu  %xmm6, 16(%rsp)
;   movdqu  %xmm7, 32(%rsp)
;   movdqu  %xmm8, 48(%rsp)
;   movdqu  %xmm9, 64(%rsp)
;   movdqu  %xmm10, 80(%rsp)
;   movdqu  %xmm11, 96(%rsp)
;   movdqu  %xmm12, 112(%rsp)
;   movdqu  %xmm13, 128(%rsp)
;   movdqu  %xmm14, 144(%rsp)
;   movdqu  %xmm15, 160(%rsp)
; block0:
;   call    *%rcx
;   movq    0(%rsp), %rsi
;   movq    8(%rsp), %rdi
;   movdqu  16(%rsp), %xmm6
;   movdqu  32(%rsp), %xmm7
;   movdqu  48(%rsp), %xmm8
;   movdqu  64(%rsp), %xmm9
;   movdqu  80(%rsp), %xmm10
;   movdqu  96(%rsp), %xmm11
;   movdqu  112(%rsp), %xmm12
;   movdqu  128(%rsp), %xmm13
;   movdqu  144(%rsp), %xmm14
;   movdqu  160(%rsp), %xmm15
;   addq    %rsp, $176, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0xb0, %rsp
;   movq %rsi, (%rsp)
;   movq %rdi, 8(%rsp)
;   movdqu %xmm6, 0x10(%rsp)
;   movdqu %xmm7, 0x20(%rsp)
;   movdqu %xmm8, 0x30(%rsp)
;   movdqu %xmm9, 0x40(%rsp)
;   movdqu %xmm10, 0x50(%rsp)
;   movdqu %xmm11, 0x60(%rsp)
;   movdqu %xmm12, 0x70(%rsp)
;   movdqu %xmm13, 0x80(%rsp)
;   movdqu %xmm14, 0x90(%rsp)
;   movdqu %xmm15, 0xa0(%rsp)
; block1: ; offset 0x61
;   callq *%rcx
;   movq (%rsp), %rsi
;   movq 8(%rsp), %rdi
;   movdqu 0x10(%rsp), %xmm6
;   movdqu 0x20(%rsp), %xmm7
;   movdqu 0x30(%rsp), %xmm8
;   movdqu 0x40(%rsp), %xmm9
;   movdqu 0x50(%rsp), %xmm10
;   movdqu 0x60(%rsp), %xmm11
;   movdqu 0x70(%rsp), %xmm12
;   movdqu 0x80(%rsp), %xmm13
;   movdqu 0x90(%rsp), %xmm14
;   movdqu 0xa0(%rsp), %xmm15
;   addq $0xb0, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %many_args(
    ;; rdi, rsi, rdx, rcx, r8, r9,
    i64, i64, i64, i64, i64, i64,

    ;; xmm0-7
    f64, f64, f64, f64, f64, f64, f64, f64,

    ;; stack args
    i64, i32, f32, f64
) system_v {
    sig0 = (
      i64, i64, i64, i64, i64, i64, f64, f64, f64, f64, f64, f64, f64, f64, i64,
      i32, f32, f64
    ) windows_fastcall
block0(
      v0: i64, v1:i64, v2:i64, v3:i64,
      v4:i64, v5:i64,
      v6: f64, v7: f64, v8:f64, v9:f64, v10:f64, v11:f64, v12:f64, v13:f64,
      v14:i64, v15:i32, v16:f32, v17:f64
):
    call_indirect sig0, v0(
      v0, v1, v2, v3,
      v4, v5, v6, v7,
      v8, v9, v10, v11,
      v12, v13, v14, v15,
      v16, v17
    )
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $144, %rsp
;   virtual_sp_offset_adjust 144
; block0:
;   movq    %rcx, %rax
;   movq    %rdx, %rcx
;   movq    %rsi, %rdx
;   movq    %rdi, %rsi
;   movq    %rax, %rdi
;   movq    16(%rbp), %r10
;   movq    24(%rbp), %r11
;   movss   32(%rbp), %xmm11
;   movsd   40(%rbp), %xmm13
;   movq    %r8, 32(%rsp)
;   movq    %r9, 40(%rsp)
;   movsd   %xmm0, 48(%rsp)
;   movsd   %xmm1, 56(%rsp)
;   movsd   %xmm2, 64(%rsp)
;   movsd   %xmm3, 72(%rsp)
;   movsd   %xmm4, 80(%rsp)
;   movsd   %xmm5, 88(%rsp)
;   movsd   %xmm6, 96(%rsp)
;   movsd   %xmm7, 104(%rsp)
;   movq    %r10, 112(%rsp)
;   movl    %r11d, 120(%rsp)
;   movss   %xmm11, 128(%rsp)
;   movsd   %xmm13, 136(%rsp)
;   movq    %rdi, %r9
;   movq    %rcx, %r8
;   movq    %rsi, %rcx
;   call    *%rcx
;   addq    %rsp, $144, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x90, %rsp
; block1: ; offset 0xb
;   movq %rcx, %rax
;   movq %rdx, %rcx
;   movq %rsi, %rdx
;   movq %rdi, %rsi
;   movq %rax, %rdi
;   movq 0x10(%rbp), %r10
;   movq 0x18(%rbp), %r11
;   movss 0x20(%rbp), %xmm11
;   movsd 0x28(%rbp), %xmm13
;   movq %r8, 0x20(%rsp)
;   movq %r9, 0x28(%rsp)
;   movsd %xmm0, 0x30(%rsp)
;   movsd %xmm1, 0x38(%rsp)
;   movsd %xmm2, 0x40(%rsp)
;   movsd %xmm3, 0x48(%rsp)
;   movsd %xmm4, 0x50(%rsp)
;   movsd %xmm5, 0x58(%rsp)
;   movsd %xmm6, 0x60(%rsp)
;   movsd %xmm7, 0x68(%rsp)
;   movq %r10, 0x70(%rsp)
;   movl %r11d, 0x78(%rsp)
;   movss %xmm11, 0x80(%rsp)
;   movsd %xmm13, 0x88(%rsp)
;   movq %rdi, %r9
;   movq %rcx, %r8
;   movq %rsi, %rcx
;   callq *%rcx
;   addq $0x90, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %many_ints(i64, i64, i64, i64, i64) system_v {
    ;; rdi => rcx
    ;; rsi => rdx
    ;; rdx => r8
    ;; rcx => r9
    ;; r8 => stack
    sig0 = (i64, i64, i64, i64, i64) windows_fastcall
block0(v0: i64, v1:i64, v2:i64, v3:i64, v4:i64):
    call_indirect sig0, v0(v0, v1, v2, v3, v4)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $48, %rsp
;   virtual_sp_offset_adjust 48
; block0:
;   movq    %rdx, %r11
;   movq    %rcx, %r9
;   movq    %rsi, %rdx
;   movq    %rdi, %rcx
;   movq    %r8, 32(%rsp)
;   movq    %r11, %r8
;   call    *%rcx
;   addq    %rsp, $48, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x30, %rsp
; block1: ; offset 0x8
;   movq %rdx, %r11
;   movq %rcx, %r9
;   movq %rsi, %rdx
;   movq %rdi, %rcx
;   movq %r8, 0x20(%rsp)
;   movq %r11, %r8
;   callq *%rcx
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %many_args2(i32, f32, i64, f64, i32, i32, i32, f32, f64, f32, f64) system_v {
    sig0 = (i32, f32, i64, f64, i32, i32, i32, f32, f64, f32, f64) windows_fastcall
block0(v0: i32, v1: f32, v2: i64, v3: f64, v4: i32, v5: i32, v6: i32, v7: f32, v8: f64, v9: f32, v10: f64):
    call_indirect sig0, v0(v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $96, %rsp
;   virtual_sp_offset_adjust 96
; block0:
;   movq    %rsi, %r9
;   movq    %rdi, %rsi
;   movdqa  %xmm1, %xmm6
;   movdqa  %xmm0, %xmm1
;   movl    %edx, 32(%rsp)
;   movl    %ecx, 40(%rsp)
;   movl    %r8d, 48(%rsp)
;   movss   %xmm2, 56(%rsp)
;   movsd   %xmm3, 64(%rsp)
;   movss   %xmm4, 72(%rsp)
;   movsd   %xmm5, 80(%rsp)
;   movq    %rsi, %rcx
;   movq    %r9, %r8
;   movdqa  %xmm6, %xmm3
;   call    *%rcx
;   addq    %rsp, $96, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x60, %rsp
; block1: ; offset 0x8
;   movq %rsi, %r9
;   movq %rdi, %rsi
;   movdqa %xmm1, %xmm6
;   movdqa %xmm0, %xmm1
;   movl %edx, 0x20(%rsp)
;   movl %ecx, 0x28(%rsp)
;   movl %r8d, 0x30(%rsp)
;   movss %xmm2, 0x38(%rsp)
;   movsd %xmm3, 0x40(%rsp)
;   movss %xmm4, 0x48(%rsp)
;   movsd %xmm5, 0x50(%rsp)
;   movq %rsi, %rcx
;   movq %r9, %r8
;   movdqa %xmm6, %xmm3
;   callq *%rcx
;   addq $0x60, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %fastcall_m128i_param(i32, i8x16) system_v {
    sig0 = (i8x16) windows_fastcall
block0(v0: i32, v1: i8x16):
    call_indirect sig0, v0(v1)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $48, %rsp
;   virtual_sp_offset_adjust 48
; block0:
;   lea     32(%rsp), %rcx
;   movdqu  %xmm0, 0(%rcx)
;   call    *%rdi
;   addq    %rsp, $48, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x30, %rsp
; block1: ; offset 0x8
;   leaq 0x20(%rsp), %rcx
;   movdqu %xmm0, (%rcx)
;   callq *%rdi
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %fastcall_m128i_params_and_results(i32, i32, i8x16, i64, i8x16) -> i8x16 system_v {
    sig0 = (i32, i8x16, i64, i8x16) -> i8x16 windows_fastcall
block0(v0: i32, v1: i32, v2: i8x16, v3: i64, v4: i8x16):
    v5 = call_indirect sig0, v0(v1, v2, v3, v4)
    v6 = iadd v5, v5
    return v6
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $64, %rsp
;   virtual_sp_offset_adjust 64
; block0:
;   movq    %rsi, %rcx
;   movq    %rdx, %r8
;   lea     32(%rsp), %rdx
;   movdqu  %xmm0, 0(%rdx)
;   lea     48(%rsp), %r9
;   movdqu  %xmm1, 0(%r9)
;   call    *%rdi
;   paddb   %xmm0, %xmm0, %xmm0
;   addq    %rsp, $64, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
; block1: ; offset 0x8
;   movq %rsi, %rcx
;   movq %rdx, %r8
;   leaq 0x20(%rsp), %rdx
;   movdqu %xmm0, (%rdx)
;   leaq 0x30(%rsp), %r9
;   movdqu %xmm1, (%r9)
;   callq *%rdi
;   paddb %xmm0, %xmm0
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %fastcall_m128i_one_stack_param(i32, i8x16) system_v {
    sig0 = (i32, i32, i32, i32, i8x16) windows_fastcall
block0(v0: i32, v1: i8x16):
    call_indirect sig0, v0(v0, v0, v0, v0, v1)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $64, %rsp
;   virtual_sp_offset_adjust 64
; block0:
;   movq    %rdi, %r9
;   lea     48(%rsp), %rcx
;   movdqu  %xmm0, 0(%rcx)
;   movq    %rcx, 32(%rsp)
;   movq    %r9, %rcx
;   movq    %r9, %rdx
;   movq    %r9, %r8
;   call    *%r9
;   addq    %rsp, $64, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
; block1: ; offset 0x8
;   movq %rdi, %r9
;   leaq 0x30(%rsp), %rcx
;   movdqu %xmm0, (%rcx)
;   movq %rcx, 0x20(%rsp)
;   movq %r9, %rcx
;   movq %r9, %rdx
;   movq %r9, %r8
;   callq *%r9
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %fastcall_m128i_two_stack_param(i32, i8x16) system_v {
    sig0 = (i32, i32, i32, i32, i8x16, i8x16) windows_fastcall
block0(v0: i32, v1: i8x16):
    call_indirect sig0, v0(v0, v0, v0, v0, v1, v1)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $80, %rsp
;   virtual_sp_offset_adjust 80
; block0:
;   movq    %rdi, %r9
;   lea     48(%rsp), %rcx
;   movdqu  %xmm0, 0(%rcx)
;   movq    %rcx, 32(%rsp)
;   lea     64(%rsp), %r10
;   movdqu  %xmm0, 0(%r10)
;   movq    %r10, 40(%rsp)
;   movq    %r9, %rcx
;   movq    %r9, %rdx
;   movq    %r9, %r8
;   call    *%r9
;   addq    %rsp, $80, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x50, %rsp
; block1: ; offset 0x8
;   movq %rdi, %r9
;   leaq 0x30(%rsp), %rcx
;   movdqu %xmm0, (%rcx)
;   movq %rcx, 0x20(%rsp)
;   leaq 0x40(%rsp), %r10
;   movdqu %xmm0, (%r10)
;   movq %r10, 0x28(%rsp)
;   movq %r9, %rcx
;   movq %r9, %rdx
;   movq %r9, %r8
;   callq *%r9
;   addq $0x50, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %fastcall_m128i_reg_and_stack_param(i32, i8x16) system_v {
    sig0 = (i32, i8x16, i32, i32, i8x16, i8x16) windows_fastcall
block0(v0: i32, v1: i8x16):
    call_indirect sig0, v0(v0, v1, v0, v0, v1, v1)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $96, %rsp
;   virtual_sp_offset_adjust 96
; block0:
;   movq    %rdi, %r10
;   lea     48(%rsp), %rdx
;   movdqu  %xmm0, 0(%rdx)
;   lea     64(%rsp), %r9
;   movdqu  %xmm0, 0(%r9)
;   movq    %r9, 32(%rsp)
;   lea     80(%rsp), %rdi
;   movdqu  %xmm0, 0(%rdi)
;   movq    %rdi, 40(%rsp)
;   movq    %r10, %r9
;   movq    %r9, %rcx
;   movq    %r9, %r8
;   call    *%r9
;   addq    %rsp, $96, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x60, %rsp
; block1: ; offset 0x8
;   movq %rdi, %r10
;   leaq 0x30(%rsp), %rdx
;   movdqu %xmm0, (%rdx)
;   leaq 0x40(%rsp), %r9
;   movdqu %xmm0, (%r9)
;   movq %r9, 0x20(%rsp)
;   leaq 0x50(%rsp), %rdi
;   movdqu %xmm0, (%rdi)
;   movq %rdi, 0x28(%rsp)
;   movq %r10, %r9
;   movq %r9, %rcx
;   movq %r9, %r8
;   callq *%r9
;   addq $0x60, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

