test compile precise-output
set enable_multi_ret_implicit_sret
target x86_64

function %f1() winch {
block0:
    return
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f2(i64, i64, i64, i64, i64, i64) -> i64 winch {
  sig0 = () winch
  fn0 = %g sig0

block0(v0:i64, v1:i64, v2:i64, v3:i64, v4:i64, v5:i64):
  call fn0()
  return v0
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
; block0:
;   movq %rdi, <offset:1>+(%rsp)
;   load_ext_name %g+0, %r10
;   call    *%r10
;   movq <offset:1>+(%rsp), %rax
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
; block1: ; offset 0x8
;   movq %rdi, (%rsp)
;   movabsq $0, %r10 ; reloc_external Abs8 %g 0
;   callq *%r10
;   movq (%rsp), %rax
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f3(i64, i64, i64, i64, i64, i64) -> i64 {
  sig0 = () winch
  fn0 = %g sig0

block0(v0:i64, v1:i64, v2:i64, v3:i64, v4:i64, v5:i64):
  call fn0()
  return v0
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block0:
;   movq %rdi, <offset:1>+(%rsp)
;   load_ext_name %g+0, %r10
;   call    *%r10
;   movq <offset:1>+(%rsp), %rax
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block1: ; offset 0x21
;   movq %rdi, (%rsp)
;   movabsq $0, %r10 ; reloc_external Abs8 %g 0
;   callq *%r10
;   movq (%rsp), %rax
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f4(i64, i64, i64, i64, i64, i64) -> i64 winch {
  sig0 = (i64, i64, i64, i64, i64, i64) -> i64 winch
  fn0 = %g sig0

block0(v0:i64, v1:i64, v2:i64, v3:i64, v4:i64, v5:i64):
  v6 = call fn0(v5, v1, v2, v3, v4, v0)
  return v6
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   load_ext_name %g+0, %r10
;   movq %rdi, %rax
;   movq %r9, %rdi
;   movq %rax, %r9
;   call    *%r10
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movabsq $0, %r10 ; reloc_external Abs8 %g 0
;   movq %rdi, %rax
;   movq %r9, %rdi
;   movq %rax, %r9
;   callq *%r10
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f5(i64, i64, i64, i64, i64, i64) -> i64 {
  sig0 = (i64, i64, i64, i64, i64, i64) -> i64 winch
  fn0 = %g sig0

block0(v0:i64, v1:i64, v2:i64, v3:i64, v4:i64, v5:i64):
  v6 = call fn0(v5, v1, v2, v3, v4, v0)
  return v6
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x30, %rsp
;   movq %rbx, (%rsp)
;   movq %r12, 8(%rsp)
;   movq %r13, 0x10(%rsp)
;   movq %r14, 0x18(%rsp)
;   movq %r15, 0x20(%rsp)
; block0:
;   load_ext_name %g+0, %r10
;   movq %rdi, %rax
;   movq %r9, %rdi
;   movq %rax, %r9
;   call    *%r10
;   movq (%rsp), %rbx
;   movq 8(%rsp), %r12
;   movq 0x10(%rsp), %r13
;   movq 0x18(%rsp), %r14
;   movq 0x20(%rsp), %r15
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x30, %rsp
;   movq %rbx, (%rsp)
;   movq %r12, 8(%rsp)
;   movq %r13, 0x10(%rsp)
;   movq %r14, 0x18(%rsp)
;   movq %r15, 0x20(%rsp)
; block1: ; offset 0x20
;   movabsq $0, %r10 ; reloc_external Abs8 %g 0
;   movq %rdi, %rax
;   movq %r9, %rdi
;   movq %rax, %r9
;   callq *%r10
;   movq (%rsp), %rbx
;   movq 8(%rsp), %r12
;   movq 0x10(%rsp), %r13
;   movq 0x18(%rsp), %r14
;   movq 0x20(%rsp), %r15
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function u1:0() system_v {
    sig0 = () winch
    fn0 = u2:0 sig0

block0:
    v5 = func_addr.i64 fn0
    call_indirect sig0, v5()
    call_indirect sig0, v5()
    return
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block0:
;   load_ext_name userextname0+0, %r10
;   movq %r10, <offset:1>+(%rsp)
;   call    *%r10
;   movq <offset:1>+(%rsp), %r10
;   call    *%r10
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block1: ; offset 0x21
;   movabsq $0, %r10 ; reloc_external Abs8 u2:0 0
;   movq %r10, (%rsp)
;   callq *%r10
;   movq (%rsp), %r10
;   callq *%r10
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f6(i64) -> i32 {
  sig0 = () -> i32, i32, f64 winch
  fn0 = %g sig0

block0(v0:i64):
  v1, v2, v3 = call fn0()
  v4 = band.i32 v1, v2
  return v4
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x50, %rsp
;   movq %rbx, 0x20(%rsp)
;   movq %r12, 0x28(%rsp)
;   movq %r13, 0x30(%rsp)
;   movq %r14, 0x38(%rsp)
;   movq %r15, 0x40(%rsp)
; block0:
;   leaq (%rsp), %rdi
;   load_ext_name %g+0, %r10
;   call    *%r10
;   movq <offset:1>+(%rsp), %rax
;   movq <offset:1>+8(%rsp), %rdx
;   andl %edx, %eax
;   movq 0x20(%rsp), %rbx
;   movq 0x28(%rsp), %r12
;   movq 0x30(%rsp), %r13
;   movq 0x38(%rsp), %r14
;   movq 0x40(%rsp), %r15
;   addq $0x50, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x50, %rsp
;   movq %rbx, 0x20(%rsp)
;   movq %r12, 0x28(%rsp)
;   movq %r13, 0x30(%rsp)
;   movq %r14, 0x38(%rsp)
;   movq %r15, 0x40(%rsp)
; block1: ; offset 0x21
;   leaq (%rsp), %rdi
;   movabsq $0, %r10 ; reloc_external Abs8 %g 0
;   callq *%r10
;   movq 4(%rsp), %r11
;   movq %r11, 0x10(%rsp)
;   movq (%rsp), %r11
;   movq %r11, 0x18(%rsp)
;   movq 0x10(%rsp), %rax
;   movq 0x18(%rsp), %rdx
;   andl %edx, %eax
;   movq 0x20(%rsp), %rbx
;   movq 0x28(%rsp), %r12
;   movq 0x30(%rsp), %r13
;   movq 0x38(%rsp), %r14
;   movq 0x40(%rsp), %r15
;   addq $0x50, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %reverse_args(i32, i64, i32, i64) -> i64, i32, i64, i32 winch {
block0(v0: i32, v1: i64, v2: i32, v3: i64):
    return v3, v2, v1, v0
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %r8, 0xc(%rdi)
;   movl %ecx, 8(%rdi)
;   movq %rdx, (%rdi)
;   movq %rsi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %r8, 0xc(%rdi)
;   movl %ecx, 8(%rdi)
;   movq %rdx, (%rdi)
;   movq %rsi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %stack_result_extension() -> i64, i8 uext, i8 uext winch {
block0:
    v0 = iconst.i64 0x00000000ffff2222
    v1 = iconst.i8 85
    v2 = iconst.i8 11
    return v0, v1, v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movl $0xffff2222, %r11d
;   movl $0x55, %r9d
;   movl $0xb, %r10d
;   movq %r11, 8(%rdi)
;   movzbq %r9b, %r11
;   movq %r9, (%rdi)
;   movzbq %r10b, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movl $0xffff2222, %r11d
;   movl $0x55, %r9d
;   movl $0xb, %r10d
;   movq %r11, 8(%rdi)
;   movzbq %r9b, %r11
;   movq %r9, (%rdi)
;   movzbq %r10b, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %stack_result_no_extension() -> i64, i8, i8 winch {
block0:
    v0 = iconst.i64 0x00000000ffff2222
    v1 = iconst.i8 85
    v2 = iconst.i8 11
    return v0, v1, v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movl $0xffff2222, %edx
;   movl $0x55, %r8d
;   movl $0xb, %eax
;   movq %rdx, 1(%rdi)
;   movb %r8b, (%rdi)
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movl $0xffff2222, %edx
;   movl $0x55, %r8d
;   movl $0xb, %eax
;   movq %rdx, 1(%rdi)
;   movb %r8b, (%rdi)
;   movq %rbp, %rsp
;   popq %rbp
;   retq

