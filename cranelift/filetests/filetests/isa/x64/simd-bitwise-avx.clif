test compile precise-output
target x86_64 sse42 has_avx

function %or_from_memory(f32x4, i64) -> f32x4 {
block0(v0: f32x4, v1: i64):
    v2 = load.f32x4 notrap aligned v1
    v3 = bor v0, v2
    return v3
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vorps   %xmm0, 0(%rdi), %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vorps (%rdi), %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %copysign_from_memory(i64) -> f32 {
block0(v0: i64):
    v1 = f32const 0.0
    v2 = load.f32 notrap aligned v0
    v3 = fcopysign v1, v2
    return v3
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   movl    $-2147483648, %eax
;   vmovd %eax, %xmm4
;   vandnps %xmm4, const(0), %xmm6
;   vandps  %xmm4, 0(%rdi), %xmm0
;   vorps   %xmm6, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movl $0x80000000, %eax
;   vmovd %eax, %xmm4
;   vandnps 0x1b(%rip), %xmm4, %xmm6
;   vandps (%rdi), %xmm4, %xmm0
;   vorps %xmm0, %xmm6, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)

function %bor_f32x4(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
    v2 = bor v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vorps   %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vorps %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %band_not_f32x4(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
    v2 = band_not v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vandnps %xmm1, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vandnps %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %band_not_f64x2(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
    v2 = band_not v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vandnpd %xmm1, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vandnpd %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %band_not_i64x2(i64x2, i64x2) -> i64x2 {
block0(v0: i64x2, v1: i64x2):
    v2 = band_not v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpandn  %xmm1, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpandn %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32x4_abs(f32x4) -> f32x4 {
block0(v0: f32x4):
    v1 = fabs v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   uninit  %xmm2
;   vpcmpeqd %xmm2, %xmm2, %xmm4
;   vpsrld  %xmm4, $1, %xmm6
;   vandps  %xmm0, %xmm6, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpeqd %xmm2, %xmm2, %xmm4
;   vpsrld $1, %xmm4, %xmm6
;   vandps %xmm6, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_and(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = band v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpand   %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpand %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32x4_and(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
  v2 = band v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vandps  %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vandps %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f64x2_and(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
  v2 = band v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vandpd  %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vandpd %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_or(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = bor v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpor    %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpor %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32x4_or(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
  v2 = bor v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vorps   %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vorps %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f64x2_or(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
  v2 = bor v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vorpd   %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vorpd %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_xor(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = bxor v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpxor   %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpxor %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32x4_xor(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
  v2 = bxor v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vxorps  %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vxorps %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f64x2_xor(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
  v2 = bxor v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vxorpd  %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vxorpd %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_bitselect(i16x8, i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8, v2: i16x8):
  v3 = bitselect v0, v1, v2
  return v3
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpand   %xmm1, %xmm0, %xmm4
;   vpandn  %xmm0, %xmm2, %xmm6
;   vpor    %xmm6, %xmm4, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpand %xmm0, %xmm1, %xmm4
;   vpandn %xmm2, %xmm0, %xmm6
;   vpor %xmm4, %xmm6, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32x4_bitselect(f32x4, f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4, v2: f32x4):
  v3 = bitselect v0, v1, v2
  return v3
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vandps  %xmm1, %xmm0, %xmm4
;   vandnps %xmm0, %xmm2, %xmm6
;   vorps   %xmm6, %xmm4, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vandps %xmm0, %xmm1, %xmm4
;   vandnps %xmm2, %xmm0, %xmm6
;   vorps %xmm4, %xmm6, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f64x2_bitselect(f64x2, f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2, v2: f64x2):
  v3 = bitselect v0, v1, v2
  return v3
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vandpd  %xmm1, %xmm0, %xmm4
;   vandnpd %xmm0, %xmm2, %xmm6
;   vorpd   %xmm6, %xmm4, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vandpd %xmm0, %xmm1, %xmm4
;   vandnpd %xmm2, %xmm0, %xmm6
;   vorpd %xmm4, %xmm6, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32x4_replace_lane(f32x4, f32) -> f32x4 {
block0(v0: f32x4, v1: f32):
  v2 = insertlane v0, v1, 1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vinsertps $16, %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vinsertps $0x10, %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f64x2_replace_lane(f64x2, f64) -> f64x2 {
block0(v0: f64x2, v1: f64):
  v2 = insertlane v0, v1, 1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vmovlhps %xmm1, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vmovlhps %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i8x16_replace_lane(i8x16, i8) -> i8x16 {
block0(v0: i8x16, v1: i8):
  v2 = insertlane v0, v1, 1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpinsrb $0x1, %edi, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpinsrb $1, %edi, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_replace_lane(i16x8, i16) -> i16x8 {
block0(v0: i16x8, v1: i16):
  v2 = insertlane v0, v1, 1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpinsrw $0x1, %edi, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpinsrw $1, %edi, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i32x4_replace_lane(i32x4, i32) -> i32x4 {
block0(v0: i32x4, v1: i32):
  v2 = insertlane v0, v1, 1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpinsrd $0x1, %edi, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpinsrd $1, %edi, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i64x2_replace_lane(i64x2, i64) -> i64x2 {
block0(v0: i64x2, v1: i64):
  v2 = insertlane v0, v1, 1
  return v2
}

; VCode:
;   pushq %rbp
;   movq    %rsp, %rbp
; block0:
;   vpinsrq $0x1, %rdi, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpinsrq $1, %rdi, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

