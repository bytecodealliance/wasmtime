test compile precise-output
set enable_llvm_abi_extensions=true
set enable_multi_ret_implicit_sret
target x86_64

function %f0(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = iadd v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   addq %rdx, %rax
;   movq %rsi, %rdx
;   adcq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   addq %rdx, %rax
;   movq %rsi, %rdx
;   adcq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f1(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = isub v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   subq %rdx, %rax
;   movq %rsi, %rdx
;   sbbq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   subq %rdx, %rax
;   movq %rsi, %rdx
;   sbbq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f2(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = band v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   andq %rdx, %rax
;   movq %rsi, %rdx
;   andq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   andq %rdx, %rax
;   movq %rsi, %rdx
;   andq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f3(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bor v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   orq %rdx, %rax
;   movq %rsi, %rdx
;   orq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   orq %rdx, %rax
;   movq %rsi, %rdx
;   orq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f4(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bxor v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   xorq %rdx, %rax
;   movq %rsi, %rdx
;   xorq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   xorq %rdx, %rax
;   movq %rsi, %rdx
;   xorq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f5(i128) -> i128 {
block0(v0: i128):
    v1 = bnot v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   notq %rax
;   movq %rsi, %rdx
;   notq %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   notq %rax
;   movq %rsi, %rdx
;   notq %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f6(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = imul v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdx, %r11
;   movq %rdi, %rdx
;   imulq %rcx, %rdx
;   movq %r11, %rcx
;   imulq %rcx, %rsi
;   addq %rsi, %rdx
;   movq %rdi, %rax
;   movq %rdx, %rsi
;   mulq %rcx ;; implicit: %rax, %rdx
;   movq %rdx, %rcx
;   movq %rsi, %rdx
;   addq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdx, %r11
;   movq %rdi, %rdx
;   imulq %rcx, %rdx
;   movq %r11, %rcx
;   imulq %rcx, %rsi
;   addq %rsi, %rdx
;   movq %rdi, %rax
;   movq %rdx, %rsi
;   mulq %rcx
;   movq %rdx, %rcx
;   movq %rsi, %rdx
;   addq %rcx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f7(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = iconcat.i64 v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   movq %rsi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   movq %rsi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f8(i128) -> i64, i64 {
block0(v0: i128):
    v1, v2 = isplit.i128 v0
    return v1, v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   movq %rsi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   movq %rsi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f9(i128, i128) -> i8 {
block0(v0: i128, v1: i128):
    v2 = icmp eq v0, v1
    v3 = icmp ne v0, v1
    v4 = icmp slt v0, v1
    v5 = icmp sle v0, v1
    v6 = icmp sgt v0, v1
    v7 = icmp sge v0, v1
    v8 = icmp ult v0, v1
    v9 = icmp ule v0, v1
    v10 = icmp ugt v0, v1
    v11 = icmp uge v0, v1
    v12 = band v2, v3
    v13 = band v4, v5
    v14 = band v6, v7
    v15 = band v8, v9
    v16 = band v10, v11
    v17 = band v12, v13
    v18 = band v14, v15
    v19 = band v17, v18
    v20 = band v19, v16
    return v20
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x20, %rsp
;   movq %rbx, (%rsp)
;   movq %r12, 8(%rsp)
;   movq %r13, 0x10(%rsp)
;   movq %r14, 0x18(%rsp)
; block0:
;   movq %rdi, %rax
;   xorq %rdx, %rax
;   movq %rsi, %r8
;   xorq %rcx, %r8
;   orq %r8, %rax
;   sete %al
;   movq %rdi, %r8
;   xorq %rdx, %r8
;   movq %rsi, %r9
;   xorq %rcx, %r9
;   orq %r9, %r8
;   setne %r9b
;   cmpq %rdx, %rdi
;   movq %rsi, %r8
;   sbbq %rcx, %r8
;   setl %r8b
;   cmpq %rdi, %rdx
;   movq %rcx, %r10
;   sbbq %rsi, %r10
;   setge %r11b
;   cmpq %rdi, %rdx
;   movq %rcx, %r10
;   sbbq %rsi, %r10
;   setl %r10b
;   cmpq %rdx, %rdi
;   movq %rsi, %rbx
;   sbbq %rcx, %rbx
;   setge %r12b
;   cmpq %rdx, %rdi
;   movq %rsi, %rbx
;   sbbq %rcx, %rbx
;   setb %bl
;   cmpq %rdi, %rdx
;   movq %rcx, %r13
;   sbbq %rsi, %r13
;   setae %r14b
;   cmpq %rdi, %rdx
;   movq %rcx, %r13
;   sbbq %rsi, %r13
;   setb %r13b
;   cmpq %rdx, %rdi
;   sbbq %rcx, %rsi
;   setae %cl
;   andl %r9d, %eax
;   andl %r11d, %r8d
;   andl %r12d, %r10d
;   andl %r14d, %ebx
;   andl %ecx, %r13d
;   andl %r8d, %eax
;   andl %ebx, %r10d
;   andl %r10d, %eax
;   andl %r13d, %eax
;   movq (%rsp), %rbx
;   movq 8(%rsp), %r12
;   movq 0x10(%rsp), %r13
;   movq 0x18(%rsp), %r14
;   addq $0x20, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x20, %rsp
;   movq %rbx, (%rsp)
;   movq %r12, 8(%rsp)
;   movq %r13, 0x10(%rsp)
;   movq %r14, 0x18(%rsp)
; block1: ; offset 0x1b
;   movq %rdi, %rax
;   xorq %rdx, %rax
;   movq %rsi, %r8
;   xorq %rcx, %r8
;   orq %r8, %rax
;   sete %al
;   movq %rdi, %r8
;   xorq %rdx, %r8
;   movq %rsi, %r9
;   xorq %rcx, %r9
;   orq %r9, %r8
;   setne %r9b
;   cmpq %rdx, %rdi
;   movq %rsi, %r8
;   sbbq %rcx, %r8
;   setl %r8b
;   cmpq %rdi, %rdx
;   movq %rcx, %r10
;   sbbq %rsi, %r10
;   setge %r11b
;   cmpq %rdi, %rdx
;   movq %rcx, %r10
;   sbbq %rsi, %r10
;   setl %r10b
;   cmpq %rdx, %rdi
;   movq %rsi, %rbx
;   sbbq %rcx, %rbx
;   setge %r12b
;   cmpq %rdx, %rdi
;   movq %rsi, %rbx
;   sbbq %rcx, %rbx
;   setb %bl
;   cmpq %rdi, %rdx
;   movq %rcx, %r13
;   sbbq %rsi, %r13
;   setae %r14b
;   cmpq %rdi, %rdx
;   movq %rcx, %r13
;   sbbq %rsi, %r13
;   setb %r13b
;   cmpq %rdx, %rdi
;   sbbq %rcx, %rsi
;   setae %cl
;   andl %r9d, %eax
;   andl %r11d, %r8d
;   andl %r12d, %r10d
;   andl %r14d, %ebx
;   andl %ecx, %r13d
;   andl %r8d, %eax
;   andl %ebx, %r10d
;   andl %r10d, %eax
;   andl %r13d, %eax
;   movq (%rsp), %rbx
;   movq 8(%rsp), %r12
;   movq 0x10(%rsp), %r13
;   movq 0x18(%rsp), %r14
;   addq $0x20, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f10(i128) -> i32 {
block0(v0: i128):
    brif v0, block2, block1

block1:
    v1 = iconst.i32 1
    return v1

block2:
    v2 = iconst.i32 2
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   orq %rsi, %rdi
;   jnz     label2; j label1
; block1:
;   movl $0x1, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block2:
;   movl $0x2, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   orq %rsi, %rdi
;   jne 0x17
; block2: ; offset 0xd
;   movl $1, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block3: ; offset 0x17
;   movl $2, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f11(i128) -> i32 {
block0(v0: i128):
    brif v0, block1, block2

block1:
    v1 = iconst.i32 1
    return v1

block2:
    v2 = iconst.i32 2
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   orq %rsi, %rdi
;   jnz     label2; j label1
; block1:
;   movl $0x2, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block2:
;   movl $0x1, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   orq %rsi, %rdi
;   jne 0x17
; block2: ; offset 0xd
;   movl $2, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block3: ; offset 0x17
;   movl $1, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f12(i64) -> i128 {
block0(v0: i64):
    v1 = uextend.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   xorq %rdx, %rdx
;   movq %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f13(i64) -> i128 {
block0(v0: i64):
    v1 = sextend.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rdx
;   sarq $0x3f, %rdx
;   movq %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rdx
;   sarq $0x3f, %rdx
;   movq %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f14(i8) -> i128 {
block0(v0: i8):
    v1 = sextend.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movsbq %dil, %rax
;   movq %rax, %rdx
;   sarq $0x3f, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movsbq %dil, %rax
;   movq %rax, %rdx
;   sarq $0x3f, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f15(i8) -> i128 {
block0(v0: i8):
    v1 = uextend.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movzbq %dil, %rax
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movzbq %dil, %rax
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f16(i128) -> i64 {
block0(v0: i128):
    v1 = ireduce.i64 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f17(i128) -> i8 {
block0(v0: i128):
    v1 = ireduce.i8 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f18(i8) -> i128 {
block0(v0: i8):
    v1 = uextend.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movzbq %dil, %rax
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movzbq %dil, %rax
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f19(i128) -> i128 {
block0(v0: i128):
    v1 = popcnt.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %r11
;   shrq $0x1, %r11
;   movabsq $0x7777777777777777, %r8
;   andq %r8, %r11
;   subq %r11, %rdi
;   shrq $0x1, %r11
;   andq %r8, %r11
;   subq %r11, %rdi
;   shrq $0x1, %r11
;   andq %r8, %r11
;   subq %r11, %rdi
;   movq %rdi, %rax
;   shrq $0x4, %rax
;   addq %rdi, %rax
;   movabsq $0xf0f0f0f0f0f0f0f, %rcx
;   andq %rcx, %rax
;   movabsq $0x101010101010101, %rcx
;   imulq %rcx, %rax
;   shrq $0x38, %rax
;   movq %rsi, %rcx
;   shrq $0x1, %rcx
;   movabsq $0x7777777777777777, %rdx
;   andq %rdx, %rcx
;   subq %rcx, %rsi
;   shrq $0x1, %rcx
;   andq %rdx, %rcx
;   subq %rcx, %rsi
;   shrq $0x1, %rcx
;   andq %rdx, %rcx
;   subq %rcx, %rsi
;   movq %rsi, %rcx
;   shrq $0x4, %rcx
;   addq %rsi, %rcx
;   movabsq $0xf0f0f0f0f0f0f0f, %rdx
;   andq %rdx, %rcx
;   movabsq $0x101010101010101, %rdx
;   imulq %rdx, %rcx
;   shrq $0x38, %rcx
;   addq %rcx, %rax
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %r11
;   shrq $1, %r11
;   movabsq $0x7777777777777777, %r8
;   andq %r8, %r11
;   subq %r11, %rdi
;   shrq $1, %r11
;   andq %r8, %r11
;   subq %r11, %rdi
;   shrq $1, %r11
;   andq %r8, %r11
;   subq %r11, %rdi
;   movq %rdi, %rax
;   shrq $4, %rax
;   addq %rdi, %rax
;   movabsq $0xf0f0f0f0f0f0f0f, %rcx
;   andq %rcx, %rax
;   movabsq $0x101010101010101, %rcx
;   imulq %rcx, %rax
;   shrq $0x38, %rax
;   movq %rsi, %rcx
;   shrq $1, %rcx
;   movabsq $0x7777777777777777, %rdx
;   andq %rdx, %rcx
;   subq %rcx, %rsi
;   shrq $1, %rcx
;   andq %rdx, %rcx
;   subq %rcx, %rsi
;   shrq $1, %rcx
;   andq %rdx, %rcx
;   subq %rcx, %rsi
;   movq %rsi, %rcx
;   shrq $4, %rcx
;   addq %rsi, %rcx
;   movabsq $0xf0f0f0f0f0f0f0f, %rdx
;   andq %rdx, %rcx
;   movabsq $0x101010101010101, %rdx
;   imulq %rdx, %rcx
;   shrq $0x38, %rcx
;   addq %rcx, %rax
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f20(i128) -> i128 {
block0(v0: i128):
    v1 = bitrev.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movabsq $0x5555555555555555, %r8
;   movq %rsi, %rcx
;   andq %r8, %rcx
;   shrq $1, %rsi
;   andq %r8, %rsi
;   shlq $1, %rcx
;   orq %rsi, %rcx
;   movabsq $0x3333333333333333, %rdx
;   movq %rcx, %rax
;   andq %rdx, %rax
;   shrq $0x2, %rcx
;   andq %rdx, %rcx
;   shlq $0x2, %rax
;   orq %rcx, %rax
;   movabsq $0xf0f0f0f0f0f0f0f, %rdx
;   movq %rax, %rcx
;   andq %rdx, %rcx
;   shrq $0x4, %rax
;   andq %rdx, %rax
;   shlq $0x4, %rcx
;   orq %rax, %rcx
;   movabsq $0xff00ff00ff00ff, %rdx
;   movq %rcx, %rax
;   andq %rdx, %rax
;   shrq $0x8, %rcx
;   andq %rdx, %rcx
;   shlq $0x8, %rax
;   orq %rcx, %rax
;   movabsq $0xffff0000ffff, %rdx
;   movq %rax, %rcx
;   andq %rdx, %rcx
;   shrq $0x10, %rax
;   andq %rdx, %rax
;   shlq $0x10, %rcx
;   orq %rax, %rcx
;   movl $0xffffffff, %edx
;   movq %rcx, %rax
;   andq %rdx, %rax
;   shrq $0x20, %rcx
;   shlq $0x20, %rax
;   orq %rcx, %rax
;   movabsq $0x5555555555555555, %r10
;   movq %rdi, %rdx
;   andq %r10, %rdx
;   shrq $1, %rdi
;   andq %r10, %rdi
;   shlq $1, %rdx
;   orq %rdi, %rdx
;   movabsq $0x3333333333333333, %rsi
;   movq %rdx, %rcx
;   andq %rsi, %rcx
;   shrq $0x2, %rdx
;   andq %rsi, %rdx
;   shlq $0x2, %rcx
;   orq %rdx, %rcx
;   movabsq $0xf0f0f0f0f0f0f0f, %rsi
;   movq %rcx, %rdx
;   andq %rsi, %rdx
;   shrq $0x4, %rcx
;   andq %rsi, %rcx
;   shlq $0x4, %rdx
;   orq %rcx, %rdx
;   movabsq $0xff00ff00ff00ff, %rsi
;   movq %rdx, %rcx
;   andq %rsi, %rcx
;   shrq $0x8, %rdx
;   andq %rsi, %rdx
;   shlq $0x8, %rcx
;   orq %rdx, %rcx
;   movabsq $0xffff0000ffff, %rdx
;   movq %rcx, %rsi
;   andq %rdx, %rsi
;   shrq $0x10, %rcx
;   andq %rdx, %rcx
;   shlq $0x10, %rsi
;   orq %rcx, %rsi
;   movl $0xffffffff, %edi
;   movq %rsi, %rdx
;   andq %rdi, %rdx
;   shrq $0x20, %rsi
;   shlq $0x20, %rdx
;   orq %rsi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movabsq $0x5555555555555555, %r8
;   movq %rsi, %rcx
;   andq %r8, %rcx
;   shrq $1, %rsi
;   andq %r8, %rsi
;   shlq $1, %rcx
;   orq %rsi, %rcx
;   movabsq $0x3333333333333333, %rdx
;   movq %rcx, %rax
;   andq %rdx, %rax
;   shrq $2, %rcx
;   andq %rdx, %rcx
;   shlq $2, %rax
;   orq %rcx, %rax
;   movabsq $0xf0f0f0f0f0f0f0f, %rdx
;   movq %rax, %rcx
;   andq %rdx, %rcx
;   shrq $4, %rax
;   andq %rdx, %rax
;   shlq $4, %rcx
;   orq %rax, %rcx
;   movabsq $0xff00ff00ff00ff, %rdx
;   movq %rcx, %rax
;   andq %rdx, %rax
;   shrq $8, %rcx
;   andq %rdx, %rcx
;   shlq $8, %rax
;   orq %rcx, %rax
;   movabsq $0xffff0000ffff, %rdx
;   movq %rax, %rcx
;   andq %rdx, %rcx
;   shrq $0x10, %rax
;   andq %rdx, %rax
;   shlq $0x10, %rcx
;   orq %rax, %rcx
;   movl $0xffffffff, %edx
;   movq %rcx, %rax
;   andq %rdx, %rax
;   shrq $0x20, %rcx
;   shlq $0x20, %rax
;   orq %rcx, %rax
;   movabsq $0x5555555555555555, %r10
;   movq %rdi, %rdx
;   andq %r10, %rdx
;   shrq $1, %rdi
;   andq %r10, %rdi
;   shlq $1, %rdx
;   orq %rdi, %rdx
;   movabsq $0x3333333333333333, %rsi
;   movq %rdx, %rcx
;   andq %rsi, %rcx
;   shrq $2, %rdx
;   andq %rsi, %rdx
;   shlq $2, %rcx
;   orq %rdx, %rcx
;   movabsq $0xf0f0f0f0f0f0f0f, %rsi
;   movq %rcx, %rdx
;   andq %rsi, %rdx
;   shrq $4, %rcx
;   andq %rsi, %rcx
;   shlq $4, %rdx
;   orq %rcx, %rdx
;   movabsq $0xff00ff00ff00ff, %rsi
;   movq %rdx, %rcx
;   andq %rsi, %rcx
;   shrq $8, %rdx
;   andq %rsi, %rdx
;   shlq $8, %rcx
;   orq %rdx, %rcx
;   movabsq $0xffff0000ffff, %rdx
;   movq %rcx, %rsi
;   andq %rdx, %rsi
;   shrq $0x10, %rcx
;   andq %rdx, %rcx
;   shlq $0x10, %rsi
;   orq %rcx, %rsi
;   movl $0xffffffff, %edi
;   movq %rsi, %rdx
;   andq %rdi, %rdx
;   shrq $0x20, %rsi
;   shlq $0x20, %rdx
;   orq %rsi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f21(i128, i64) {
block0(v0: i128, v1: i64):
    store.i128 v0, v1
    return
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, (%rdx)
;   movq %rsi, 8(%rdx)
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, (%rdx) ; trap: heap_oob
;   movq %rsi, 8(%rdx) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f22(i64) -> i128 {
block0(v0: i64):
    v1 = load.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq (%rdi), %rax
;   movq 8(%rdi), %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq (%rdi), %rax ; trap: heap_oob
;   movq 8(%rdi), %rdx ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f23(i128, i8) -> i128 {
block0(v0: i128, v1: i8):
    v2 = iconst.i64 0
    v3 = uextend.i128 v2
    brif v1, block1(v3), block2(v3)

block1(v4: i128):
    v5 = iconst.i64 1
    v6 = uextend.i128 v5
    v7 = iadd.i128 v4, v6
    return v7

block2(v8: i128):
    v9 = iconst.i64 2
    v10 = uextend.i128 v9
    v11 = iadd.i128 v8, v10
    return v11
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   uninit  %rax
;   xorq %rax, %rax
;   testb %dl, %dl
;   jnz     label2; j label1
; block1:
;   addq $0x2, %rax
;   setb %r11b
;   movzbq %r11b, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block2:
;   addq $0x1, %rax
;   setb %cl
;   movzbq %cl, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   xorq %rax, %rax
;   testb %dl, %dl
;   jne 0x20
; block2: ; offset 0xf
;   addq $2, %rax
;   setb %r11b
;   movzbq %r11b, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block3: ; offset 0x20
;   addq $1, %rax
;   setb %cl
;   movzbq %cl, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f24(i128, i128, i64, i128, i128, i128) -> i128 {

block0(v0: i128, v1: i128, v2: i64, v3: i128, v4: i128, v5: i128):
    v6 = iadd.i128 v0, v1
    v7 = uextend.i128 v2
    v8 = iadd.i128 v3, v7
    v9 = iadd.i128 v4, v5
    v10 = iadd.i128 v6, v8
    v11 = iadd.i128 v9, v10
    return v11
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
;   movq %rbx, (%rsp)
;   movq %r12, 8(%rsp)
; block0:
;   movq %rdx, %rbx
;   movq %rcx, %r12
;   movq <offset:0>+-0x30(%rbp), %rcx
;   movq <offset:0>+-0x28(%rbp), %rax
;   movq <offset:0>+-0x20(%rbp), %rdx
;   movq <offset:0>+-0x18(%rbp), %r11
;   movq <offset:0>+-0x10(%rbp), %r10
;   addq %rbx, %rdi
;   movq %r12, %rbx
;   adcq %rbx, %rsi
;   addq %r8, %r9
;   adcq $0x0, %rcx
;   addq %r11, %rax
;   adcq %r10, %rdx
;   addq %r9, %rdi
;   adcq %rcx, %rsi
;   addq %rdi, %rax
;   adcq %rsi, %rdx
;   movq (%rsp), %rbx
;   movq 8(%rsp), %r12
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
;   movq %rbx, (%rsp)
;   movq %r12, 8(%rsp)
; block1: ; offset 0x11
;   movq %rdx, %rbx
;   movq %rcx, %r12
;   movq 0x10(%rbp), %rcx
;   movq 0x18(%rbp), %rax
;   movq 0x20(%rbp), %rdx
;   movq 0x28(%rbp), %r11
;   movq 0x30(%rbp), %r10
;   addq %rbx, %rdi
;   movq %r12, %rbx
;   adcq %rbx, %rsi
;   addq %r8, %r9
;   adcq $0, %rcx
;   addq %r11, %rax
;   adcq %r10, %rdx
;   addq %r9, %rdi
;   adcq %rcx, %rsi
;   addq %rdi, %rax
;   adcq %rsi, %rdx
;   movq (%rsp), %rbx
;   movq 8(%rsp), %r12
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f25(i128) -> i128, i128, i128, i64, i128, i128 {
block0(v0: i128):
    v1 = ireduce.i64 v0
    return v0, v0, v0, v1, v0, v0
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdx, (%rdi)
;   movq %rsi, 8(%rdi)
;   movq %rdx, 0x10(%rdi)
;   movq %rsi, 0x18(%rdi)
;   movq %rsi, 0x20(%rdi)
;   movq %rdx, 0x28(%rdi)
;   movq %rsi, 0x30(%rdi)
;   movq %rdx, 0x38(%rdi)
;   movq %rsi, %rcx
;   movq %rcx, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdx, (%rdi)
;   movq %rsi, 8(%rdi)
;   movq %rdx, 0x10(%rdi)
;   movq %rsi, 0x18(%rdi)
;   movq %rsi, 0x20(%rdi)
;   movq %rdx, 0x28(%rdi)
;   movq %rsi, 0x30(%rdi)
;   movq %rdx, 0x38(%rdi)
;   movq %rsi, %rcx
;   movq %rcx, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f26(i128, i128) -> i128, i128 {
    fn0 = %g(i128, i128) -> i128, i128
block0(v0: i128, v1: i128):
    v2, v3 = call fn0(v0, v1)
    return v2, v3
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x20, %rsp
;   movq %r12, 0x10(%rsp)
;   movq %r13, 0x18(%rsp)
; block0:
;   movq %rdi, %r13
;   leaq (%rsp), %rdi
;   load_ext_name %g+0, %rax
;   call    *%rax
;   movq %r13, %rdi
;   movq %r12, (%rdi)
;   movq 0x10(%rsp), %r12
;   movq 0x18(%rsp), %r13
;   addq $0x20, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x20, %rsp
;   movq %r12, 0x10(%rsp)
;   movq %r13, 0x18(%rsp)
; block1: ; offset 0x12
;   movq %rdi, %r13
;   leaq (%rsp), %rdi
;   movabsq $0, %rax ; reloc_external Abs8 %g 0
;   callq *%rax
;   movq (%rsp), %r12
;   movq %r13, %rdi
;   movq %r12, (%rdi)
;   movq 0x10(%rsp), %r12
;   movq 0x18(%rsp), %r13
;   addq $0x20, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f27(i128) -> i128 {
block0(v0: i128):
    v1 = clz.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq $0xffffffffffffffff, %r8
;   bsrq %rsi, %rsi
;   cmoveq %r8, %rsi
;   movl $0x3f, %r10d
;   subq %rsi, %r10
;   movq $0xffffffffffffffff, %rax
;   bsrq %rdi, %rcx
;   cmoveq %rax, %rcx
;   movl $0x3f, %eax
;   subq %rcx, %rax
;   addq $0x40, %rax
;   cmpq $0x40, %r10
;   cmovneq %r10, %rax
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq $18446744073709551615, %r8
;   bsrq %rsi, %rsi
;   cmoveq %r8, %rsi
;   movl $0x3f, %r10d
;   subq %rsi, %r10
;   movq $18446744073709551615, %rax
;   bsrq %rdi, %rcx
;   cmoveq %rax, %rcx
;   movl $0x3f, %eax
;   subq %rcx, %rax
;   addq $0x40, %rax
;   cmpq $0x40, %r10
;   cmovneq %r10, %rax
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f28(i128) -> i128 {
block0(v0: i128):
    v1 = ctz.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movl $0x40, %r8d
;   bsfq %rdi, %rax
;   cmoveq %r8, %rax
;   movl $0x40, %r9d
;   bsfq %rsi, %rcx
;   cmoveq %r9, %rcx
;   addq $0x40, %rcx
;   cmpq $0x40, %rax
;   cmoveq %rcx, %rax
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movl $0x40, %r8d
;   bsfq %rdi, %rax
;   cmoveq %r8, %rax
;   movl $0x40, %r9d
;   bsfq %rsi, %rcx
;   cmoveq %r9, %rcx
;   addq $0x40, %rcx
;   cmpq $0x40, %rax
;   cmoveq %rcx, %rax
;   xorq %rdx, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f29(i8, i128) -> i8 {
block0(v0: i8, v1: i128):
    v2 = ishl v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rsi, %rcx
;   andq $0x7, %rcx
;   movq %rdi, %rax
;   shlb %cl, %al
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rsi, %rcx
;   andq $7, %rcx
;   movq %rdi, %rax
;   shlb %cl, %al
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f30(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = ishl v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdx, %rax
;   movq %rdx, %rcx
;   movq %rdi, %rdx
;   shlq %cl, %rdx
;   shlq %cl, %rsi
;   movq %rcx, %rax
;   movl $0x40, %ecx
;   movq %rax, %r8
;   subq %r8, %rcx
;   shrq %cl, %rdi
;   uninit  %rax
;   xorq %rax, %rax
;   testq $0x7f, %r8
;   cmoveq %rax, %rdi
;   orq %rsi, %rdi
;   testq $0x40, %r8
;   cmoveq %rdx, %rax
;   cmoveq %rdi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdx, %rax
;   movq %rdx, %rcx
;   movq %rdi, %rdx
;   shlq %cl, %rdx
;   shlq %cl, %rsi
;   movq %rcx, %rax
;   movl $0x40, %ecx
;   movq %rax, %r8
;   subq %r8, %rcx
;   shrq %cl, %rdi
;   xorq %rax, %rax
;   testq $0x7f, %r8
;   cmoveq %rax, %rdi
;   orq %rsi, %rdi
;   testq $0x40, %r8
;   cmoveq %rdx, %rax
;   cmoveq %rdi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f31(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = ushr v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdx, %rax
;   movq %rdx, %rcx
;   shrq %cl, %rdi
;   movq %rsi, %r8
;   shrq %cl, %r8
;   movq %rcx, %rax
;   movl $0x40, %ecx
;   subq %rax, %rcx
;   shlq %cl, %rsi
;   uninit  %rdx
;   xorq %rdx, %rdx
;   testq $0x7f, %rax
;   cmoveq %rdx, %rsi
;   orq %rdi, %rsi
;   testq $0x40, %rax
;   movq %r8, %rax
;   cmoveq %rsi, %rax
;   cmoveq %r8, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdx, %rax
;   movq %rdx, %rcx
;   shrq %cl, %rdi
;   movq %rsi, %r8
;   shrq %cl, %r8
;   movq %rcx, %rax
;   movl $0x40, %ecx
;   subq %rax, %rcx
;   shlq %cl, %rsi
;   xorq %rdx, %rdx
;   testq $0x7f, %rax
;   cmoveq %rdx, %rsi
;   orq %rdi, %rsi
;   testq $0x40, %rax
;   movq %r8, %rax
;   cmoveq %rsi, %rax
;   cmoveq %r8, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = sshr v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdx, %rax
;   movq %rdx, %rcx
;   shrq %cl, %rdi
;   movq %rsi, %r8
;   sarq %cl, %r8
;   movq %rcx, %rax
;   movl $0x40, %ecx
;   movq %rax, %r9
;   subq %r9, %rcx
;   movq %rsi, %rax
;   shlq %cl, %rax
;   uninit  %rdx
;   xorq %rdx, %rdx
;   testq $0x7f, %r9
;   cmoveq %rdx, %rax
;   orq %rax, %rdi
;   sarq $0x3f, %rsi
;   testq $0x40, %r9
;   movq %r8, %rax
;   cmoveq %rdi, %rax
;   movq %rsi, %rdx
;   cmoveq %r8, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdx, %rax
;   movq %rdx, %rcx
;   shrq %cl, %rdi
;   movq %rsi, %r8
;   sarq %cl, %r8
;   movq %rcx, %rax
;   movl $0x40, %ecx
;   movq %rax, %r9
;   subq %r9, %rcx
;   movq %rsi, %rax
;   shlq %cl, %rax
;   xorq %rdx, %rdx
;   testq $0x7f, %r9
;   cmoveq %rdx, %rax
;   orq %rax, %rdi
;   sarq $0x3f, %rsi
;   testq $0x40, %r9
;   movq %r8, %rax
;   cmoveq %rdi, %rax
;   movq %rsi, %rdx
;   cmoveq %r8, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f33(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = rotl v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdx, %rcx
;   movq %rdx, %r10
;   movq %rdi, %rdx
;   shlq %cl, %rdx
;   movq %rcx, %r10
;   movq %rsi, %r9
;   shlq %cl, %r9
;   movl $0x40, %ecx
;   movq %r10, %rax
;   subq %rax, %rcx
;   movq %rdi, %r8
;   shrq %cl, %r8
;   uninit  %rax
;   xorq %rax, %rax
;   movq %r10, %rcx
;   testq $0x7f, %rcx
;   cmoveq %rax, %r8
;   orq %r9, %r8
;   testq $0x40, %rcx
;   cmoveq %rdx, %rax
;   cmoveq %r8, %rdx
;   movl $0x80, %ecx
;   movq %r10, %r8
;   subq %r8, %rcx
;   shrq %cl, %rdi
;   movq %rsi, %r8
;   shrq %cl, %r8
;   movq %rcx, %r9
;   movl $0x40, %ecx
;   movq %r9, %r10
;   subq %r10, %rcx
;   shlq %cl, %rsi
;   uninit  %r9
;   xorq %r9, %r9
;   testq $0x7f, %r10
;   cmoveq %r9, %rsi
;   orq %rdi, %rsi
;   testq $0x40, %r10
;   movq %r8, %rcx
;   cmoveq %rsi, %rcx
;   cmoveq %r8, %r9
;   orq %rcx, %rax
;   orq %r9, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdx, %rcx
;   movq %rdx, %r10
;   movq %rdi, %rdx
;   shlq %cl, %rdx
;   movq %rcx, %r10
;   movq %rsi, %r9
;   shlq %cl, %r9
;   movl $0x40, %ecx
;   movq %r10, %rax
;   subq %rax, %rcx
;   movq %rdi, %r8
;   shrq %cl, %r8
;   xorq %rax, %rax
;   movq %r10, %rcx
;   testq $0x7f, %rcx
;   cmoveq %rax, %r8
;   orq %r9, %r8
;   testq $0x40, %rcx
;   cmoveq %rdx, %rax
;   cmoveq %r8, %rdx
;   movl $0x80, %ecx
;   movq %r10, %r8
;   subq %r8, %rcx
;   shrq %cl, %rdi
;   movq %rsi, %r8
;   shrq %cl, %r8
;   movq %rcx, %r9
;   movl $0x40, %ecx
;   movq %r9, %r10
;   subq %r10, %rcx
;   shlq %cl, %rsi
;   xorq %r9, %r9
;   testq $0x7f, %r10
;   cmoveq %r9, %rsi
;   orq %rdi, %rsi
;   testq $0x40, %r10
;   movq %r8, %rcx
;   cmoveq %rsi, %rcx
;   cmoveq %r8, %r9
;   orq %rcx, %rax
;   orq %r9, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f34(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = rotr v0, v1
    return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdx, %rcx
;   movq %rdx, %r11
;   movq %rdi, %r9
;   shrq %cl, %r9
;   movq %rcx, %r11
;   movq %rsi, %r8
;   shrq %cl, %r8
;   movl $0x40, %ecx
;   movq %r11, %rax
;   subq %rax, %rcx
;   movq %rsi, %r10
;   shlq %cl, %r10
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %r11, %rcx
;   testq $0x7f, %rcx
;   cmoveq %rdx, %r10
;   orq %r9, %r10
;   testq $0x40, %rcx
;   movq %r8, %rax
;   cmoveq %r10, %rax
;   cmoveq %r8, %rdx
;   movl $0x80, %ecx
;   movq %r11, %r8
;   subq %r8, %rcx
;   movq %rdi, %r8
;   shlq %cl, %r8
;   shlq %cl, %rsi
;   movq %rcx, %r9
;   movl $0x40, %ecx
;   movq %r9, %r10
;   subq %r10, %rcx
;   shrq %cl, %rdi
;   uninit  %r9
;   xorq %r9, %r9
;   testq $0x7f, %r10
;   cmoveq %r9, %rdi
;   orq %rsi, %rdi
;   testq $0x40, %r10
;   cmoveq %r8, %r9
;   cmoveq %rdi, %r8
;   orq %r9, %rax
;   orq %r8, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdx, %rcx
;   movq %rdx, %r11
;   movq %rdi, %r9
;   shrq %cl, %r9
;   movq %rcx, %r11
;   movq %rsi, %r8
;   shrq %cl, %r8
;   movl $0x40, %ecx
;   movq %r11, %rax
;   subq %rax, %rcx
;   movq %rsi, %r10
;   shlq %cl, %r10
;   xorq %rdx, %rdx
;   movq %r11, %rcx
;   testq $0x7f, %rcx
;   cmoveq %rdx, %r10
;   orq %r9, %r10
;   testq $0x40, %rcx
;   movq %r8, %rax
;   cmoveq %r10, %rax
;   cmoveq %r8, %rdx
;   movl $0x80, %ecx
;   movq %r11, %r8
;   subq %r8, %rcx
;   movq %rdi, %r8
;   shlq %cl, %r8
;   shlq %cl, %rsi
;   movq %rcx, %r9
;   movl $0x40, %ecx
;   movq %r9, %r10
;   subq %r10, %rcx
;   shrq %cl, %rdi
;   xorq %r9, %r9
;   testq $0x7f, %r10
;   cmoveq %r9, %rdi
;   orq %rsi, %rdi
;   testq $0x40, %r10
;   cmoveq %r8, %r9
;   cmoveq %rdi, %r8
;   orq %r9, %rax
;   orq %r8, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %iabs_i128(i128) -> i128 {
block0(v0: i128):
    v1 = iabs.i128 v0
    return v1
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   uninit  %r8
;   xorq %r8, %r8
;   movq %rdi, %rax
;   negq %rax
;   movq %rsi, %rdx
;   adcq %r8, %rdx
;   negq %rdx
;   cmovsq %rdi, %rax
;   cmovsq %rsi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   xorq %r8, %r8
;   movq %rdi, %rax
;   negq %rax
;   movq %rsi, %rdx
;   adcq %r8, %rdx
;   negq %rdx
;   cmovsq %rdi, %rax
;   cmovsq %rsi, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %mul_wide_i64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   mulq %rsi ;; implicit: %rax, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   mulq %rsi
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %add_concat_64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v10 = iconst.i64 0
    v2 = iconcat v0, v10
    v3 = iconcat v1, v10
    v4 = iadd v2, v3
    return v4
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rdi, %rax
;   addq %rsi, %rax
;   adcq $0x0, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   xorq %rdx, %rdx
;   movq %rdi, %rax
;   addq %rsi, %rax
;   adcq $0, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %mul_uextend_i64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   mulq %rsi ;; implicit: %rax, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   mulq %rsi
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %mul_sextend_i64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = sextend.i128 v0
    v3 = sextend.i128 v1
    v4 = imul v2, v3
    return v4
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   imulq %rsi ;; implicit: %rax, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   imulq %rsi
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %sub_uextend_64(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = isub v2, v3
    return v4
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rdi, %rax
;   subq %rsi, %rax
;   sbbq $0x0, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   xorq %rdx, %rdx
;   movq %rdi, %rax
;   subq %rsi, %rax
;   sbbq $0, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %sink_load_of_i128_half(i64, i64) -> i64, i64 {
block0(v0: i64, v1: i64):
    v10 = load.i64 v0
    v18 = uextend.i128 v1
    v20 = uextend.i128 v10
    v14 = iadd v18, v20
    v15, v16 = isplit v14
    return v15, v16
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rsi, %rax
;   addq (%rdi), %rax
;   setb %sil
;   movzbq %sil, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rsi, %rax
;   addq (%rdi), %rax ; trap: heap_oob
;   setb %sil
;   movzbq %sil, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %sink_two_i128_loads_in_add(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v10 = load.i64 v0
    v11 = load.i64 v0+8
    v18 = uextend.i128 v1
    v20 = iconcat v10, v11
    v14 = iadd v18, v20
    return v14
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq (%rdi), %r8
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rsi, %rax
;   addq %r8, %rax
;   adcq 8(%rdi), %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq (%rdi), %r8 ; trap: heap_oob
;   xorq %rdx, %rdx
;   movq %rsi, %rax
;   addq %r8, %rax
;   adcq 8(%rdi), %rdx ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %sink_two_i128_loads_in_sub(i64, i64) -> i128 {
block0(v0: i64, v1: i64):
    v10 = load.i64 v0
    v11 = load.i64 v0+8
    v18 = uextend.i128 v1
    v20 = iconcat v10, v11
    v14 = isub v18, v20
    return v14
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq (%rdi), %r8
;   uninit  %rdx
;   xorq %rdx, %rdx
;   movq %rsi, %rax
;   subq %r8, %rax
;   sbbq 8(%rdi), %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq (%rdi), %r8 ; trap: heap_oob
;   xorq %rdx, %rdx
;   movq %rsi, %rax
;   subq %r8, %rax
;   sbbq 8(%rdi), %rdx ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %select128(i128, i128) -> i32 {
block0(v0: i128, v1: i128):
    v2 = icmp ult v0, v1
    v3 = iconst.i32 100
    v4 = iconst.i32 200
    v5 = select v2, v3, v4
    return v5
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movl $0xc8, %eax
;   cmpq %rdx, %rdi
;   sbbq %rcx, %rsi
;   cmovbl (%rip), %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movl $0xc8, %eax
;   cmpq %rdx, %rdi
;   sbbq %rcx, %rsi
;   cmovbl 0xa(%rip), %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %ah, (%rax, %rax)
;   addb %al, (%rax)
;   addb %al, (%rax)

function %uadd_overflow_as_i128(i64, i64) -> i64, i64 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = iadd v2, v3
    v5, v6 = isplit v4
    return v5, v6
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   movq %rdi, %rax
;   addq %rsi, %rax
;   setb %sil
;   movzbq %sil, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   addq %rsi, %rax
;   setb %sil
;   movzbq %sil, %rdx
;   movq %rbp, %rsp
;   popq %rbp
;   retq

