test compile precise-output
target x86_64

function %f0(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = iadd v2, v1
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   addl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   addl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f1(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = iadd v1, v2
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   addl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   addl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f2(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = isub v2, v1
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   subl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   subl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f3(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = band v2, v1
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   andl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   andl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f4(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = band v1, v2
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   andl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   andl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f5(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = bor v2, v1
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   orl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   orl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f6(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = bor v1, v2
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   orl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   orl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f7(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = bxor v2, v1
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   xorl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   xorl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f8(i64, i32) {
block0(v0: i64, v1: i32):
  v2 = load.i32 v0+32
  v3 = bxor v1, v2
  store v3, v0+32
  return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   xorl %esi, 0x20(%rdi)
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   xorl %esi, 0x20(%rdi) ; trap: heap_oob
;   movq %rbp, %rsp
;   popq %rbp
;   retq

