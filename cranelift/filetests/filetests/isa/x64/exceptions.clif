test compile precise-output
target x86_64

function %f0(i32) -> i32, f32, f64 {
    sig0 = (i32) -> f32 tail
    fn0 = %g(i32) -> f32 tail

    block0(v1: i32):
        v2 = f64const 0x1.0
        try_call fn0(v1), sig0, block1(ret0, v2), [ default: block2(exn0) ]

    block1(v3: f32, v4: f64):
        v5 = iconst.i32 1
        return v5, v3, v4

    block2(v6: i64):
        v7 = ireduce.i32 v6
        v8 = iadd_imm.i32 v7, 1
        v9 = f32const 0x0.0        
        return v8, v9, v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block0:
;   movabsq $0x3ff0000000000000, %rcx
;   movq %rcx, %xmm1
;   movdqu %xmm1, <offset:1>+(%rsp)
;   load_ext_name %g+0, %rdx
;   call    *%rdx; jmp MachLabel(1); catch [default: MachLabel(2)]
; block1:
;   movl $0x1, %eax
;   movdqu <offset:1>+(%rsp), %xmm1
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block2:
;   movdqu <offset:1>+(%rsp), %xmm1
;   leal 1(%rax), %eax
;   uninit  %xmm0
;   xorps %xmm0, %xmm0
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block1: ; offset 0x21
;   movabsq $0x3ff0000000000000, %rcx
;   movq %rcx, %xmm1
;   movdqu %xmm1, (%rsp)
;   movabsq $0, %rdx ; reloc_external Abs8 %g 0
;   callq *%rdx
; block2: ; offset 0x41
;   movl $1, %eax
;   movdqu (%rsp), %xmm1
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block3: ; offset 0x6d
;   movdqu (%rsp), %xmm1
;   addl $1, %eax
;   xorps %xmm0, %xmm0
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f1(i32) -> i32, f32, f64 {
    sig0 = (i32) -> f32 tail
    fn0 = %g(i32) -> f32 tail

    block0(v1: i32):
        brif v1, block1, block2

    block1:
        v2 = f64const 0x1.0
        try_call fn0(v1), sig0, block3(ret0, v2), [ default: block4(exn0) ]

    block2:
        v3 = iconst.i64 42
        v4 = f32const 0x1234.0
        v5 = f64const 0x5678.0
        brif v1, block4(v3), block3(v4, v5)

    block3(v6: f32, v7: f64):
        v8 = iconst.i32 1
        return v8, v6, v7

    block4(v9: i64):
        v10 = ireduce.i32 v9
        v11 = iadd_imm.i32 v10, 1
        v12 = f32const 0x0.0
        v13 = bitcast.f64 v9
        return v11, v12, v13
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block0:
;   testl %edi, %edi
;   jnz     label4; j label1
; block1:
;   movl $0x2a, %eax
;   movl $0x4591a000, %ecx
;   movd %ecx, %xmm0
;   movabsq $0x40d59e0000000000, %rcx
;   movq %rcx, %xmm1
;   testl %edi, %edi
;   jnz     label2; j label3
; block2:
;   movq %rax, %r11
;   jmp     label8
; block3:
;   movdqu %xmm1, <offset:1>+(%rsp)
;   jmp     label7
; block4:
;   movabsq $0x3ff0000000000000, %r10
;   movq %r10, %xmm1
;   movdqu %xmm1, <offset:1>+(%rsp)
;   load_ext_name %g+0, %r11
;   call    *%r11; jmp MachLabel(6); catch [default: MachLabel(5)]
; block5:
;   movq %rax, %rsi
;   movq %rsi, %r11
;   jmp     label8
; block6:
;   jmp     label7
; block7:
;   movl $0x1, %eax
;   movdqu <offset:1>+(%rsp), %xmm1
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block8:
;   leal 1(%r11), %eax
;   movq %r11, %rsi
;   uninit  %xmm0
;   xorps %xmm0, %xmm0
;   movq %rsi, %xmm1
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block1: ; offset 0x21
;   testl %edi, %edi
;   jne 0x60
; block2: ; offset 0x29
;   movl $0x2a, %eax
;   movl $0x4591a000, %ecx
;   movd %ecx, %xmm0
;   movabsq $0x40d59e0000000000, %rcx
;   movq %rcx, %xmm1
;   testl %edi, %edi
;   je 0x56
; block3: ; offset 0x4e
;   movq %rax, %r11
;   jmp 0xbd
; block4: ; offset 0x56
;   movdqu %xmm1, (%rsp)
;   jmp 0x91
; block5: ; offset 0x60
;   movabsq $0x3ff0000000000000, %r10
;   movq %r10, %xmm1
;   movdqu %xmm1, (%rsp)
;   movabsq $0, %r11 ; reloc_external Abs8 %g 0
;   callq *%r11
;   jmp 0x91
; block6: ; offset 0x86
;   movq %rax, %rsi
;   movq %rsi, %r11
;   jmp 0xbd
; block7: ; offset 0x91
;   movl $1, %eax
;   movdqu (%rsp), %xmm1
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block8: ; offset 0xbd
;   leal 1(%r11), %eax
;   movq %r11, %rsi
;   xorps %xmm0, %xmm0
;   movq %rsi, %xmm1
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f2(i32) -> i32, f32, f64 {
    sig0 = (i32) -> f32 tail
    fn0 = %g(i32) -> f32 tail

    block0(v1: i32):
        v2 = f64const 0x1.0
        v10 = func_addr.i64 fn0
        try_call_indirect v10(v1), sig0, block1(ret0, v2), [ default: block2(exn0) ]

    block1(v3: f32, v4: f64):
        v5 = iconst.i32 1
        return v5, v3, v4

    block2(v6: i64):
        v7 = ireduce.i32 v6
        v8 = iadd_imm.i32 v7, 1
        v9 = f32const 0x0.0        
        return v8, v9, v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block0:
;   movabsq $0x3ff0000000000000, %rcx
;   movq %rcx, %xmm1
;   movdqu %xmm1, <offset:1>+(%rsp)
;   load_ext_name %g+0, %rdx
;   call    *%rdx; jmp MachLabel(1); catch [default: MachLabel(2)]
; block1:
;   movl $0x1, %eax
;   movdqu <offset:1>+(%rsp), %xmm1
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block2:
;   movdqu <offset:1>+(%rsp), %xmm1
;   leal 1(%rax), %eax
;   uninit  %xmm0
;   xorps %xmm0, %xmm0
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block1: ; offset 0x21
;   movabsq $0x3ff0000000000000, %rcx
;   movq %rcx, %xmm1
;   movdqu %xmm1, (%rsp)
;   movabsq $0, %rdx ; reloc_external Abs8 %g 0
;   callq *%rdx
; block2: ; offset 0x41
;   movl $1, %eax
;   movdqu (%rsp), %xmm1
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block3: ; offset 0x6d
;   movdqu (%rsp), %xmm1
;   addl $1, %eax
;   xorps %xmm0, %xmm0
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f3() system_v {
    sig0 = () system_v
    fn0 = u0:1 sig0

block0:
    jump block1

block1:
    try_call fn0(), sig0, block2, []

block2:
    jump block2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   jmp     label1
; block1:
;   load_ext_name userextname0+0, %rcx
;   call    *%rcx; jmp MachLabel(2); catch []
; block2:
;   jmp     label3
; block3:
;   jmp     label3
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movabsq $0, %rcx ; reloc_external Abs8 u0:1 0
;   callq *%rcx
; block2: ; offset 0x10
;   jmp 0x10

function %f4(i64, i32) -> i32, f32, f64 {
    sig0 = (i32) -> f32 tail
    fn0 = %g(i32) -> f32 tail

    block0(v0: i64, v1: i32):
        v2 = f64const 0x1.0
        try_call fn0(v1), sig0, block1(ret0, v2), [ context v0, tag0: block2(exn0), tag1: block2(exn0), context v1, tag0: block3  ]

    block1(v3: f32, v4: f64):
        v5 = iconst.i32 1
        return v5, v3, v4

    block2(v6: i64):
        v7 = ireduce.i32 v6
        v8 = iadd_imm.i32 v7, 1
        v9 = f32const 0x0.0        
        return v8, v9, v2

    block3:
        jump block2(v0)
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x50, %rsp
;   movq %rbx, 0x20(%rsp)
;   movq %r12, 0x28(%rsp)
;   movq %r13, 0x30(%rsp)
;   movq %r14, 0x38(%rsp)
;   movq %r15, 0x40(%rsp)
; block0:
;   movq %rdi, <offset:1>+8(%rsp)
;   movabsq $0x3ff0000000000000, %rdx
;   movq %rdx, %xmm1
;   movdqu %xmm1, <offset:1>+0x10(%rsp)
;   load_ext_name %g+0, %r8
;   movq %rsi, %rdi
;   movq %rsi, <offset:1>+(%rsp)
;   call    *%r8; jmp MachLabel(3); catch [context stack1, tag0: MachLabel(1), tag1: MachLabel(2), context stack0, tag0: MachLabel(4)]
; block1:
;   movq %rax, %rdi
;   movdqu <offset:1>+0x10(%rsp), %xmm1
;   jmp     label5
; block2:
;   movq %rax, %rdi
;   movdqu <offset:1>+0x10(%rsp), %xmm1
;   jmp     label5
; block3:
;   movl $0x1, %eax
;   movdqu <offset:1>+0x10(%rsp), %xmm1
;   movq 0x20(%rsp), %rbx
;   movq 0x28(%rsp), %r12
;   movq 0x30(%rsp), %r13
;   movq 0x38(%rsp), %r14
;   movq 0x40(%rsp), %r15
;   addq $0x50, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block4:
;   movdqu <offset:1>+0x10(%rsp), %xmm1
;   movq <offset:1>+8(%rsp), %rdi
;   jmp     label5
; block5:
;   leal 1(%rdi), %eax
;   uninit  %xmm0
;   xorps %xmm0, %xmm0
;   movq 0x20(%rsp), %rbx
;   movq 0x28(%rsp), %r12
;   movq 0x30(%rsp), %r13
;   movq 0x38(%rsp), %r14
;   movq 0x40(%rsp), %r15
;   addq $0x50, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x50, %rsp
;   movq %rbx, 0x20(%rsp)
;   movq %r12, 0x28(%rsp)
;   movq %r13, 0x30(%rsp)
;   movq %r14, 0x38(%rsp)
;   movq %r15, 0x40(%rsp)
; block1: ; offset 0x21
;   movq %rdi, 8(%rsp)
;   movabsq $0x3ff0000000000000, %rdx
;   movq %rdx, %xmm1
;   movdqu %xmm1, 0x10(%rsp)
;   movabsq $0, %r8 ; reloc_external Abs8 %g 0
;   movq %rsi, %rdi
;   movq %rsi, (%rsp)
;   callq *%r8
;   jmp 0x70
; block2: ; offset 0x54
;   movq %rax, %rdi
;   movdqu 0x10(%rsp), %xmm1
;   jmp 0xa8
; block3: ; offset 0x62
;   movq %rax, %rdi
;   movdqu 0x10(%rsp), %xmm1
;   jmp 0xa8
; block4: ; offset 0x70
;   movl $1, %eax
;   movdqu 0x10(%rsp), %xmm1
;   movq 0x20(%rsp), %rbx
;   movq 0x28(%rsp), %r12
;   movq 0x30(%rsp), %r13
;   movq 0x38(%rsp), %r14
;   movq 0x40(%rsp), %r15
;   addq $0x50, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
; block5: ; offset 0x9d
;   movdqu 0x10(%rsp), %xmm1
;   movq 8(%rsp), %rdi
; block6: ; offset 0xa8
;   leal 1(%rdi), %eax
;   xorps %xmm0, %xmm0
;   movq 0x20(%rsp), %rbx
;   movq 0x28(%rsp), %r12
;   movq 0x30(%rsp), %r13
;   movq 0x38(%rsp), %r14
;   movq 0x40(%rsp), %r15
;   addq $0x50, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

