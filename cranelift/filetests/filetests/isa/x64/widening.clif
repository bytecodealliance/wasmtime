test compile precise-output
target x86_64

function %f1(i8x16) -> i16x8 {
block0(v0: i8x16):
  v1 = swiden_low v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pmovsxbw %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f2(i16x8) -> i32x4 {
block0(v0: i16x8):
  v1 = swiden_low v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pmovsxwd %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f3(i32x4) -> i64x2 {
block0(v0: i32x4):
  v1 = swiden_low v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pmovsxdq %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f4(i8x16) -> i16x8 {
block0(v0: i8x16):
  v1 = swiden_high v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm3
;   palignr $8, %xmm3, %xmm0, %xmm3
;   pmovsxbw %xmm3, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f5(i16x8) -> i32x4 {
block0(v0: i16x8):
  v1 = swiden_high v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm3
;   palignr $8, %xmm3, %xmm0, %xmm3
;   pmovsxwd %xmm3, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f6(i32x4) -> i64x2 {
block0(v0: i32x4):
  v1 = swiden_high v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufd  $238, %xmm0, %xmm3
;   pmovsxdq %xmm3, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f7(i8x16) -> i16x8 {
block0(v0: i8x16):
  v1 = uwiden_low v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pmovzxbw %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f8(i16x8) -> i32x4 {
block0(v0: i16x8):
  v1 = uwiden_low v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pmovzxwd %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f9(i32x4) -> i64x2 {
block0(v0: i32x4):
  v1 = uwiden_low v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pmovzxdq %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f10(i8x16) -> i16x8 {
block0(v0: i8x16):
  v1 = uwiden_high v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm3
;   palignr $8, %xmm3, %xmm0, %xmm3
;   pmovzxbw %xmm3, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f11(i16x8) -> i32x4 {
block0(v0: i16x8):
  v1 = uwiden_high v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm3
;   palignr $8, %xmm3, %xmm0, %xmm3
;   pmovzxwd %xmm3, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %f12(i32x4) -> i64x2 {
block0(v0: i32x4):
  v1 = uwiden_high v0
  return v1
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufd  $238, %xmm0, %xmm3
;   pmovzxdq %xmm3, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

