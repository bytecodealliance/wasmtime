test compile precise-output
set enable_simd
target x86_64 has_avx512vl has_avx512vbmi

function %shuffle_in_bounds(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    ;; pick the second lane of v1, the rest use the first lane of v0
    v2 = shuffle v0, v1, 0x11000000000000000000000000000000
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm5
;   movdqu  const(0), %xmm0
;   movdqa  %xmm5, %xmm6
;   vpermi2b %xmm1, %xmm6, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movdqa %xmm0, %xmm5
;   movdqu 0x10(%rip), %xmm0
;   movdqa %xmm5, %xmm6
;   vpermi2b %xmm1, %xmm6, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)

function %shuffle_out_of_bounds(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    ;; pick zero for the first lane, the rest use first lane of v0
    ;; This should introduce two constants, one for the permutation and one to
    ;; mask the non-zero values for lanes 1-15
    v2 = shuffle v0, v1, 0x80000000000000000000000000000000
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm7
;   movdqu  const(1), %xmm0
;   movdqu  const(0), %xmm6
;   movdqa  %xmm7, %xmm9
;   vpermi2b %xmm1, %xmm9, %xmm6, %xmm6
;   andps   %xmm0, %xmm6, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movdqa %xmm0, %xmm7
;   movdqu 0x30(%rip), %xmm0
;   movdqu 0x18(%rip), %xmm6
;   movdqa %xmm7, %xmm9
;   vpermi2b %xmm1, %xmm9, %xmm6
;   andps %xmm6, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   addb %al, (%rax)
;   cmpb $0xff, %bh

function %f3(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [3 0 31 26 4 6 12 11 23 13 24 4 2 15 17 5]
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm5
;   movdqu  const(0), %xmm0
;   movdqa  %xmm5, %xmm6
;   vpermi2b %xmm1, %xmm6, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movdqa %xmm0, %xmm5
;   movdqu 0x10(%rip), %xmm0
;   movdqa %xmm5, %xmm6
;   vpermi2b %xmm1, %xmm6, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;   addb %al, (%rbx)
;   addb %bl, (%rdi)
;   sbbb (%rsi, %rax), %al
;   orb $0xb, %al

