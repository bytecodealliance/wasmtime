test compile precise-output
set enable_multi_ret_implicit_sret
target x86_64

function %f0(i64 vmctx) -> i64, i64, i64, i64 {
  gv0 = vmctx
  stack_limit = gv0
  ss0 = explicit_slot 8, align=16
  ss1 = explicit_slot 8, align=16
  ss2 = explicit_slot 4
  ss3 = explicit_slot 4

block0(v0: i64):
  v1 = stack_addr.i64 ss0
  v2 = stack_addr.i64 ss1
  v3 = stack_addr.i64 ss2
  v4 = stack_addr.i64 ss3
  return v1, v2, v3, v4
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   movq %rsi, %r10
;   addq $0x30, %r10
;   cmpq %rsp, %r10
;   jnbe #trap=stk_ovf
;   subq $0x30, %rsp
; block0:
;   leaq <offset:1>+(%rsp), %rax
;   leaq <offset:1>+0x10(%rsp), %rdx
;   leaq <offset:1>+0x18(%rsp), %r8
;   leaq <offset:1>+0x20(%rsp), %r9
;   movq %r8, (%rdi)
;   movq %r9, 8(%rdi)
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   movq %rsi, %r10
;   addq $0x30, %r10
;   cmpq %rsp, %r10
;   ja 0x3b
;   subq $0x30, %rsp
; block1: ; offset 0x18
;   leaq (%rsp), %rax
;   leaq 0x10(%rsp), %rdx
;   leaq 0x18(%rsp), %r8
;   leaq 0x20(%rsp), %r9
;   movq %r8, (%rdi)
;   movq %r9, 8(%rdi)
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;   ud2 ; trap: stk_ovf

function %f1(i32, i64, f32, f64, i8x16) -> i32, i64, f32, f64, i8x16 {
  ss0 = explicit_slot 40

block0(v0: i32, v1: i64, v2: f32, v3: f64, v4: i8x16):
  stack_store v0, ss0+0
  stack_store v1, ss0+4
  stack_store v2, ss0+12
  stack_store v3, ss0+16
  stack_store v4, ss0+24
  v5 = stack_load.i32 ss0+0
  v6 = stack_load.i64 ss0+4
  v7 = stack_load.f32 ss0+12
  v8 = stack_load.f64 ss0+16
  v9 = stack_load.i8x16 ss0+24
  return v5, v6, v7, v8, v9
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x30, %rsp
; block0:
;   movl %esi, <offset:1>+(%rsp)
;   movq %rdx, <offset:1>+4(%rsp)
;   movss %xmm0, <offset:1>+0xc(%rsp)
;   movsd %xmm1, <offset:1>+0x10(%rsp)
;   movdqu %xmm2, <offset:1>+0x18(%rsp)
;   movl <offset:1>+(%rsp), %eax
;   movq <offset:1>+4(%rsp), %rdx
;   movss <offset:1>+0xc(%rsp), %xmm0
;   movsd <offset:1>+0x10(%rsp), %xmm1
;   movdqu <offset:1>+0x18(%rsp), %xmm2
;   movdqu %xmm2, (%rdi)
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x30, %rsp
; block1: ; offset 0x8
;   movl %esi, (%rsp)
;   movq %rdx, 4(%rsp)
;   movss %xmm0, 0xc(%rsp)
;   movsd %xmm1, 0x10(%rsp)
;   movdqu %xmm2, 0x18(%rsp)
;   movl (%rsp), %eax
;   movq 4(%rsp), %rdx
;   movss 0xc(%rsp), %xmm0
;   movsd 0x10(%rsp), %xmm1
;   movdqu 0x18(%rsp), %xmm2
;   movdqu %xmm2, (%rdi)
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

