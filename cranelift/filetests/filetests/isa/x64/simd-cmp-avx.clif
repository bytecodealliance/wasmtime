test compile precise-output
target x86_64 sse42 has_avx

function %i8x16_eq(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
  v2 = icmp eq v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpcmpeqb %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpeqb %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_eq(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = icmp eq v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpcmpeqw %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpeqw %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i32x4_eq(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
  v2 = icmp eq v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpcmpeqd %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpeqd %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i64x2_eq(i64x2, i64x2) -> i64x2 {
block0(v0: i64x2, v1: i64x2):
  v2 = icmp eq v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpcmpeqq %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpeqq %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i8x16_gt(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
  v2 = icmp sgt v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpcmpgtb %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpgtb %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_gt(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = icmp sgt v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpcmpgtw %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpgtw %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i32x4_gt(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
  v2 = icmp sgt v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpcmpgtd %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpgtd %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i64x2_gt(i64x2, i64x2) -> i64x2 {
block0(v0: i64x2, v1: i64x2):
  v2 = icmp sgt v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpcmpgtq %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpcmpgtq %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32x4_min(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
  v2 = fmin v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vminps  %xmm0, %xmm1, %xmm3
;   vminps  %xmm1, %xmm0, %xmm5
;   vorps   %xmm3, %xmm5, %xmm7
;   vcmpps  $3, %xmm7, %xmm5, %xmm1
;   vorps   %xmm7, %xmm1, %xmm3
;   vpsrld  %xmm1, $10, %xmm5
;   vandnps %xmm5, %xmm3, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vminps %xmm1, %xmm0, %xmm3
;   vminps %xmm0, %xmm1, %xmm5
;   vorps %xmm5, %xmm3, %xmm7
;   vcmpunordps %xmm5, %xmm7, %xmm1
;   vorps %xmm1, %xmm7, %xmm3
;   vpsrld $0xa, %xmm1, %xmm5
;   vandnps %xmm3, %xmm5, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f64x2_min(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
  v2 = fmin v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vminpd  %xmm0, %xmm1, %xmm3
;   vminpd  %xmm1, %xmm0, %xmm5
;   vorpd   %xmm3, %xmm5, %xmm7
;   vcmppd  $3, %xmm3, %xmm5, %xmm1
;   vorpd   %xmm7, %xmm1, %xmm3
;   vpsrlq  %xmm1, $13, %xmm5
;   vandnpd %xmm5, %xmm3, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vminpd %xmm1, %xmm0, %xmm3
;   vminpd %xmm0, %xmm1, %xmm5
;   vorpd %xmm5, %xmm3, %xmm7
;   vcmpunordpd %xmm5, %xmm3, %xmm1
;   vorpd %xmm1, %xmm7, %xmm3
;   vpsrlq $0xd, %xmm1, %xmm5
;   vandnpd %xmm3, %xmm5, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f32x4_max(f32x4, f32x4) -> f32x4 {
block0(v0: f32x4, v1: f32x4):
  v2 = fmax v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vmaxps  %xmm0, %xmm1, %xmm3
;   vmaxps  %xmm1, %xmm0, %xmm5
;   vxorps  %xmm3, %xmm5, %xmm7
;   vorps   %xmm3, %xmm7, %xmm1
;   vsubps  %xmm1, %xmm7, %xmm3
;   vcmpps  $3, %xmm1, %xmm1, %xmm5
;   vpsrld  %xmm5, $10, %xmm7
;   vandnps %xmm7, %xmm3, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vmaxps %xmm1, %xmm0, %xmm3
;   vmaxps %xmm0, %xmm1, %xmm5
;   vxorps %xmm5, %xmm3, %xmm7
;   vorps %xmm7, %xmm3, %xmm1
;   vsubps %xmm7, %xmm1, %xmm3
;   vcmpunordps %xmm1, %xmm1, %xmm5
;   vpsrld $0xa, %xmm5, %xmm7
;   vandnps %xmm3, %xmm7, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f64x2_max(f64x2, f64x2) -> f64x2 {
block0(v0: f64x2, v1: f64x2):
  v2 = fmax v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vmaxpd  %xmm0, %xmm1, %xmm3
;   vmaxpd  %xmm1, %xmm0, %xmm5
;   vxorpd  %xmm3, %xmm5, %xmm7
;   vorpd   %xmm3, %xmm7, %xmm1
;   vsubpd  %xmm1, %xmm7, %xmm3
;   vcmppd  $3, %xmm1, %xmm1, %xmm5
;   vpsrlq  %xmm5, $13, %xmm7
;   vandnpd %xmm7, %xmm3, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vmaxpd %xmm1, %xmm0, %xmm3
;   vmaxpd %xmm0, %xmm1, %xmm5
;   vxorpd %xmm5, %xmm3, %xmm7
;   vorpd %xmm7, %xmm3, %xmm1
;   vsubpd %xmm7, %xmm1, %xmm3
;   vcmpunordpd %xmm1, %xmm1, %xmm5
;   vpsrlq $0xd, %xmm5, %xmm7
;   vandnpd %xmm3, %xmm7, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i8x16_min(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
  v2 = smin v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpminsb %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpminsb %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %u8x16_min(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
  v2 = umin v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpminub %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpminub %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_min(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = smin v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpminsw %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpminsw %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %u16x8_min(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = umin v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpminuw %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpminuw %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i32x4_min(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
  v2 = smin v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpminsd %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpminsd %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %u32x4_min(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
  v2 = umin v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpminud %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpminud %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i8x16_max(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
  v2 = smax v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpmaxsb %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpmaxsb %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %u8x16_max(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
  v2 = umax v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpmaxub %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpmaxub %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i16x8_max(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = smax v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpmaxsw %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpmaxsw %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %u16x8_max(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
  v2 = umax v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpmaxuw %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpmaxuw %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %i32x4_max(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
  v2 = smax v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpmaxsd %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpmaxsd %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %u32x4_max(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
  v2 = umax v0, v1
  return v2
}

; VCode:
;   pushq %rbp
;   movq %rsp, %rbp
; block0:
;   vpmaxud %xmm0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   vpmaxud %xmm1, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

