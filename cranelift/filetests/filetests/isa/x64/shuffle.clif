test compile precise-output
target x86_64 sse41

function %punpcklbw(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, 0x17071606150514041303120211011000
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   punpcklbw %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   punpcklbw %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %punpckhbw(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, 0x1f0f1e0e1d0d1c0c1b0b1a0a19091808
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   punpckhbw %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   punpckhbw %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %punpcklwd(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 16 17 2 3 18 19 4 5 20 21 6 7 22 23]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   punpcklwd %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   punpcklwd %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %punpckhwd(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [8 9 24 25 10 11 26 27 12 13 28 29 14 15 30 31]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   punpckhwd %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   punpckhwd %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshufd_0022(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 0 1 2 3 8 9 10 11 8 9 10 11]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufd  $160, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshufd $0xa0, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshufd_3120(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [12 13 14 15 4 5 6 7 8 9 10 11 0 1 2 3]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufd  $39, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshufd $0x27, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshufd_7546(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [28 29 30 31 20 21 22 23 16 17 18 19 24 25 26 27]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufd  $135, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshufd $0x87, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %not_single_pshufd(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [8 9 10 11 12 13 14 15 20 21 22 23 20 21 22 23]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   shufps  $94, %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   shufps $0x5e, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %punpckldq(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 16 17 18 19 4 5 6 7 20 21 22 23]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   punpckldq %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   punpckldq %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %punpckhdq(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [8 9 10 11 24 25 26 27 12 13 14 15 28 29 30 31]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   punpckhdq %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   punpckhdq %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %punpcklqdq(i64x2, i64x2) -> i64x2 {
block0(v0: i64x2, v1: i64x2):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 4 5 6 7 16 17 18 19 20 21 22 23]
    v5 = bitcast.i64x2 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   punpcklqdq %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   punpcklqdq %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %punpckhqdq(i64x2, i64x2) -> i64x2 {
block0(v0: i64x2, v1: i64x2):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [8 9 10 11 12 13 14 15 24 25 26 27 28 29 30 31]
    v5 = bitcast.i64x2 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   punpckhqdq %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   punpckhqdq %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %shufps_3277(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [12 13 14 15 8 9 10 11 28 29 30 31 28 29 30 31]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   shufps  $251, %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   shufps $0xfb, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %shufps_6500(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [24 25 26 27 20 21 22 23 0 1 2 3 0 1 2 3]
    v5 = bitcast.i32x4 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm4
;   movdqa  %xmm1, %xmm0
;   shufps  $6, %xmm0, %xmm4, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movdqa %xmm0, %xmm4
;   movdqa %xmm1, %xmm0
;   shufps $6, %xmm4, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshuflw_3210(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [6 7 4 5 2 3 0 1 8 9 10 11 12 13 14 15]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshuflw $27, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshuflw $0x1b, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshuflw_3131(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [6 7 4 5 6 7 4 5 8 9 10 11 12 13 14 15]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshuflw $187, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshuflw $0xbb, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshuflw_rhs_3210(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [22 23 20 21 18 19 16 17 24 25 26 27 28 29 30 31]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshuflw $27, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshuflw $0x1b, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshuflw_rhs_3131(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [22 23 18 19 22 23 18 19 24 25 26 27 28 29 30 31]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshuflw $119, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshuflw $0x77, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshufhw_3210(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 4 5 6 7 14 15 12 13 10 11 8 9]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufhw $27, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshufhw $0x1b, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshufhw_3131(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [0 1 2 3 4 5 6 7 14 15 10 11 14 15 10 11]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufhw $119, %xmm0, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshufhw $0x77, %xmm0, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshufhw_rhs_3210(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [16 17 18 19 20 21 22 23 30 31 28 29 26 27 24 25]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufhw $27, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshufhw $0x1b, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pshufhw_rhs_3131(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [16 17 18 19 20 21 22 23 30 31 26 27 30 31 26 27]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pshufhw $119, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pshufhw $0x77, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %shuffle_all_zeros(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   uninit  %xmm4
;   pxor %xmm4, %xmm4
;   pshufb  %xmm0, %xmm4, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pxor %xmm4, %xmm4
;   pshufb %xmm4, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %palignr_0(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pblendw $0, %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pblendw $0, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %palignr_1(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16]
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm4
;   movdqa  %xmm1, %xmm0
;   palignr $1, %xmm0, %xmm4, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movdqa %xmm0, %xmm4
;   movdqa %xmm1, %xmm0
;   palignr $1, %xmm4, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %palignr_5(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20]
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm4
;   movdqa  %xmm1, %xmm0
;   palignr $5, %xmm0, %xmm4, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movdqa %xmm0, %xmm4
;   movdqa %xmm1, %xmm0
;   palignr $5, %xmm4, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %palignr_11(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26]
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm4
;   movdqa  %xmm1, %xmm0
;   palignr $11, %xmm0, %xmm4, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movdqa %xmm0, %xmm4
;   movdqa %xmm1, %xmm0
;   palignr $0xb, %xmm4, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %palignr_16(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = shuffle v0, v1, [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]
    return v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pblendw $255, %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pblendw $0xff, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %pblendw_0b10011001(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = bitcast.i8x16 little v0
    v3 = bitcast.i8x16 little v1
    v4 = shuffle v2, v3, [16 17 2 3 4 5 22 23 24 25 10 11 12 13 30 31]
    v5 = bitcast.i16x8 little v4
    return v5
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   pblendw $153, %xmm0, %xmm1, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   pblendw $0x99, %xmm1, %xmm0
;   movq %rbp, %rsp
;   popq %rbp
;   retq

