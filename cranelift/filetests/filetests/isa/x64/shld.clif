test compile precise-output
target x86_64

function %x64_shld_i32_20(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = ushr_imm v0, 12
    v3 = ishl_imm v1, 20
    v4 = bor v2, v3
    return v4
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rsi, %rax
;   shldl $0x14, %edi, %eax
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rsi, %rax
;   shldl $0x14, %edi, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %x64_shld_i32_20_swap(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = ishl_imm v0, 20
    v3 = ushr_imm v1, 12
    v4 = bor v2, v3
    return v4
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rdi, %rax
;   shldl $0x14, %esi, %eax
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   shldl $0x14, %esi, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %x64_shld_i32_28(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = ushr_imm v0, 4
    v3 = ishl_imm v1, 28
    v4 = bor v2, v3
    return v4
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rsi, %rax
;   shldl $0x1c, %edi, %eax
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rsi, %rax
;   shldl $0x1c, %edi, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %x64_shld_i32_28_swap(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = ishl_imm v0, 28
    v3 = ushr_imm v1, 4
    v4 = bor v2, v3
    return v4
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rdi, %rax
;   shldl $0x1c, %esi, %eax
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   shldl $0x1c, %esi, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %x64_shld_i64_52(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = ushr_imm v0, 12
    v3 = ishl_imm v1, 52
    v4 = bor v2, v3
    return v4
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rsi, %rax
;   shldq $0x34, %rdi, %rax
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rsi, %rax
;   shldq $0x34, %rdi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %x64_shld_i64_52_swap(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = ishl_imm v0, 52
    v3 = ushr_imm v1, 12
    v4 = bor v2, v3
    return v4
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rdi, %rax
;   shldq $0x34, %rsi, %rax
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   shldq $0x34, %rsi, %rax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %x64_shld_i16_3(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
    v2 = ushr_imm v0, 3
    v3 = ishl_imm v1, 13
    v4 = bor v2, v3
    return v4
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rsi, %rax
;   shldw $0xd, %di, %ax
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rsi, %rax
;   shldw $0xd, %di, %ax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %x64_shld_i8_3(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = ushr_imm v0, 3
    v3 = ishl_imm v1, 5
    v4 = bor v2, v3
    return v4
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   shrb    $3, %dil, %dil
;   shlb    $5, %sil, %sil
;   movq    %rdi, %rax
;   orl %esi, %eax
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   shrb $3, %dil
;   shlb $5, %sil
;   movq %rdi, %rax
;   orl %esi, %eax
;   movq %rbp, %rsp
;   popq %rbp
;   retq

