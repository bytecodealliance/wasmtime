test compile
set unwind_info=false
set enable_heap_access_spectre_mitigation=true
target aarch64

function %dynamic_heap_check(i64 vmctx, i32) -> i64 {
    gv0 = vmctx
    gv1 = load.i64 notrap aligned gv0
    heap0 = dynamic gv0, bound gv1, offset_guard 0x1000, index_type i32

block0(v0: i64, v1: i32):
    v2 = heap_addr.i64 heap0, v1, 0
    return v2
}

; check: Block 0:
; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: mov w2, w1
; nextln: ldr x3, [x0]
; nextln: mov x3, x3
; nextln: subs xzr, x2, x3
; nextln: b.ls label1 ; b label2
; check: Block 1:
; check: add x0, x0, x1, UXTW
; nextln: subs xzr, x2, x3
; nextln: movz x1, #0
; nextln: csel x0, x1, x0, hi
; nextln: ldp fp, lr, [sp], #16
; nextln: ret
; check: Block 2:
; check: udf

function %static_heap_check(i64 vmctx, i32) -> i64 {
    gv0 = vmctx
    heap0 = static gv0, bound 0x1_0000, offset_guard 0x1000, index_type i32

block0(v0: i64, v1: i32):
    v2 = heap_addr.i64 heap0, v1, 0
    return v2
}

; check: Block 0:
; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: mov w2, w1
; nextln: subs xzr, x2, #65536
; nextln: b.ls label1 ; b label2
; check: Block 1:
; check: add x0, x0, x1, UXTW
; nextln: subs xzr, x2, #65536
; nextln: movz x1, #0
; nextln: csel x0, x1, x0, hi
; nextln: ldp fp, lr, [sp], #16
; nextln: ret
; check: Block 2:
; check: udf
