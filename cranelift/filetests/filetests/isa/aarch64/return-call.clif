test compile precise-output

target aarch64

;;;; Test passing `i64`s ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

function %callee_i64(i64) -> i64 tail {
block0(v0: i64):
    v1 = iadd_imm.i64 v0, 10
    return v1
}

; VCode:
; block0:
;   add x2, x2, #10
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   add x2, x2, #0xa
;   ret

function %call_i64(i64) -> i64 tail {
    fn0 = %callee_i64(i64) -> i64 tail

block0(v0: i64):
    return_call fn0(v0)
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   load_ext_name x3, TestCase(%callee_i64)+0
;   return_call_ind x3 new_stack_arg_size:0 x2=x2
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldr x3, #0x10
;   b #0x18
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %callee_i64 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldp x29, x30, [sp], #0x10
;   br x3

;;;; Test colocated tail calls ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

function %colocated_i64(i64) -> i64 tail {
    fn0 = colocated %callee_i64(i64) -> i64 tail

block0(v0: i64):
    return_call fn0(v0)
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   return_call TestCase(%callee_i64) new_stack_arg_size:0 x2=x2
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldp x29, x30, [sp], #0x10
;   b #0xc ; reloc_external Call %callee_i64 0

;;;; Test passing `f64`s ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

function %callee_f64(f64) -> f64 tail {
block0(v0: f64):
    v1 = f64const 0x10.0
    v2 = fadd.f64 v0, v1
    return v2
}

; VCode:
; block0:
;   fmov d3, #16
;   fadd d0, d0, d3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   fmov d3, #16.00000000
;   fadd d0, d0, d3
;   ret

function %call_f64(f64) -> f64 tail {
    fn0 = %callee_f64(f64) -> f64 tail

block0(v0: f64):
    return_call fn0(v0)
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   load_ext_name x2, TestCase(%callee_f64)+0
;   return_call_ind x2 new_stack_arg_size:0 v0=v0
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldr x2, #0x10
;   b #0x18
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %callee_f64 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldp x29, x30, [sp], #0x10
;   br x2

;;;; Test passing `i8`s ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

function %callee_i8(i8) -> i8 tail {
block0(v0: i8):
    v1 = iconst.i8 0
    v2 = icmp eq v0, v1
    return v2
}

; VCode:
; block0:
;   uxtb w2, w2
;   subs wzr, w2, #0
;   cset x2, eq
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   uxtb w2, w2
;   cmp w2, #0
;   cset x2, eq
;   ret

function %call_i8(i8) -> i8 tail {
    fn0 = %callee_i8(i8) -> i8 tail

block0(v0: i8):
    return_call fn0(v0)
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   load_ext_name x3, TestCase(%callee_i8)+0
;   return_call_ind x3 new_stack_arg_size:0 x2=x2
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldr x3, #0x10
;   b #0x18
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %callee_i8 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldp x29, x30, [sp], #0x10
;   br x3

;;;; Test passing many arguments on stack ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

function %tail_callee_stack_args(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) -> i64 tail {
block0(v0: i64, v1: i64, v2: i64, v3: i64, v4: i64, v5: i64, v6: i64, v7: i64, v8: i64, v9: i64, v10: i64, v11: i64, v12: i64, v13: i64, v14: i64, v15: i64, v16: i64, v17: i64, v18: i64, v19: i64, v20: i64, v21: i64, v22: i64, v23: i64, v24: i64, v25: i64):
    return v25
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   ldr x9, [sp, #16]
;   ldr x2, [sp, #24]
;   ldp fp, lr, [sp], #16
;   add sp, sp, #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldur x9, [sp, #0x10]
;   ldur x2, [sp, #0x18]
;   ldp x29, x30, [sp], #0x10
;   add sp, sp, #0x10
;   ret

function %tail_caller_stack_args() -> i64 tail {
    fn0 = %tail_callee_stack_args(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) -> i64 tail

block0:
    v0 = iconst.i64 10
    v1 = iconst.i64 15
    v2 = iconst.i64 20
    v3 = iconst.i64 25
    v4 = iconst.i64 30
    v5 = iconst.i64 35
    v6 = iconst.i64 40
    v7 = iconst.i64 45
    v8 = iconst.i64 50
    v9 = iconst.i64 55
    v10 = iconst.i64 60
    v11 = iconst.i64 65
    v12 = iconst.i64 70
    v13 = iconst.i64 75
    v14 = iconst.i64 80
    v15 = iconst.i64 85
    v16 = iconst.i64 90
    v17 = iconst.i64 95
    v18 = iconst.i64 100
    v19 = iconst.i64 105
    v20 = iconst.i64 110
    v21 = iconst.i64 115
    v22 = iconst.i64 120
    v23 = iconst.i64 125
    v24 = iconst.i64 130
    v25 = iconst.i64 135
    return_call fn0(v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22, v23, v24, v25)
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   sub sp, sp, #16
;   ldr fp, [sp, #16]
;   stp fp, lr, [sp]
;   mov fp, sp
; block0:
;   movz x2, #10
;   movz x3, #15
;   movz x4, #20
;   movz x5, #25
;   movz x6, #30
;   movz x7, #35
;   movz x8, #40
;   movz x9, #45
;   movz x10, #50
;   movz x11, #55
;   movz x12, #60
;   movz x13, #65
;   movz x14, #70
;   movz x15, #75
;   movz x19, #80
;   movz x20, #85
;   movz x21, #90
;   movz x22, #95
;   movz x23, #100
;   movz x24, #105
;   movz x25, #110
;   movz x26, #115
;   movz x27, #120
;   movz x28, #125
;   movz x0, #130
;   movz x1, #135
;   str x0, [sp, #16]
;   str x1, [sp, #24]
;   load_ext_name x0, TestCase(%tail_callee_stack_args)+0
;   return_call_ind x0 new_stack_arg_size:16 x2=x2 x3=x3 x4=x4 x5=x5 x6=x6 x7=x7 x8=x8 x9=x9 x10=x10 x11=x11 x12=x12 x13=x13 x14=x14 x15=x15 x19=x19 x20=x20 x21=x21 x22=x22 x23=x23 x24=x24 x25=x25 x26=x26 x27=x27 x28=x28
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   sub sp, sp, #0x10
;   ldur x29, [sp, #0x10]
;   stp x29, x30, [sp]
;   mov x29, sp
; block1: ; offset 0x18
;   mov x2, #0xa
;   mov x3, #0xf
;   mov x4, #0x14
;   mov x5, #0x19
;   mov x6, #0x1e
;   mov x7, #0x23
;   mov x8, #0x28
;   mov x9, #0x2d
;   mov x10, #0x32
;   mov x11, #0x37
;   mov x12, #0x3c
;   mov x13, #0x41
;   mov x14, #0x46
;   mov x15, #0x4b
;   mov x19, #0x50
;   mov x20, #0x55
;   mov x21, #0x5a
;   mov x22, #0x5f
;   mov x23, #0x64
;   mov x24, #0x69
;   mov x25, #0x6e
;   mov x26, #0x73
;   mov x27, #0x78
;   mov x28, #0x7d
;   mov x0, #0x82
;   mov x1, #0x87
;   stur x0, [sp, #0x10]
;   stur x1, [sp, #0x18]
;   ldr x0, #0x90
;   b #0x98
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %tail_callee_stack_args 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldp x29, x30, [sp], #0x10
;   br x0

;;;; Test diff blocks with diff return calls with diff # of stack args ;;;;;;;;;

function %different_callee1(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) -> i64 tail {
block0(v0: i64, v1: i64, v2: i64, v3: i64, v4: i64, v5: i64, v6: i64, v7: i64, v8: i64, v9: i64, v10: i64, v11: i64, v12: i64, v13: i64, v14: i64, v15: i64, v16: i64, v17: i64, v18: i64, v19: i64, v20: i64, v21: i64, v22: i64, v23: i64, v24: i64, v25: i64):
    return v25
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   ldr x9, [sp, #16]
;   ldr x2, [sp, #24]
;   ldp fp, lr, [sp], #16
;   add sp, sp, #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldur x9, [sp, #0x10]
;   ldur x2, [sp, #0x18]
;   ldp x29, x30, [sp], #0x10
;   add sp, sp, #0x10
;   ret

function %different_callee2(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) -> i64 tail {
block0(v0: i64, v1: i64, v2: i64, v3: i64, v4: i64, v5: i64, v6: i64, v7: i64, v8: i64, v9: i64, v10: i64, v11: i64, v12: i64, v13: i64, v14: i64, v15: i64, v16: i64, v17: i64, v18: i64, v19: i64, v20: i64, v21: i64, v22: i64, v23: i64, v24: i64, v25: i64, v26: i64):
    return v26
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   ldr x9, [sp, #16]
;   ldr x11, [sp, #24]
;   ldr x2, [sp, #32]
;   ldp fp, lr, [sp], #16
;   add sp, sp, #32
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldur x9, [sp, #0x10]
;   ldur x11, [sp, #0x18]
;   ldur x2, [sp, #0x20]
;   ldp x29, x30, [sp], #0x10
;   add sp, sp, #0x20
;   ret

function %caller_of_different_callees(i64) -> i64 tail {
    fn0 = %different_callee1(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) -> i64 tail
    fn1 = %different_callee2(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64) -> i64 tail

block0(v99: i64):
    v0 = iconst.i64 10
    v1 = iconst.i64 15
    v2 = iconst.i64 20
    v3 = iconst.i64 25
    v4 = iconst.i64 30
    v5 = iconst.i64 35
    v6 = iconst.i64 40
    v7 = iconst.i64 45
    v8 = iconst.i64 50
    v9 = iconst.i64 55
    v10 = iconst.i64 60
    v11 = iconst.i64 65
    v12 = iconst.i64 70
    v13 = iconst.i64 75
    v14 = iconst.i64 80
    v15 = iconst.i64 85
    v16 = iconst.i64 90
    v17 = iconst.i64 95
    v18 = iconst.i64 100
    v19 = iconst.i64 105
    v20 = iconst.i64 110
    v21 = iconst.i64 115
    v22 = iconst.i64 120
    v23 = iconst.i64 125
    v24 = iconst.i64 130
    v25 = iconst.i64 135
    brif v99, block1, block2

block1:
    return_call fn0(v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22, v23, v24, v25)

block2:
    v26 = iconst.i64 140
    return_call fn1(v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22, v23, v24, v25, v26)
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   sub sp, sp, #32
;   ldr fp, [sp, #32]
;   stp fp, lr, [sp]
;   mov fp, sp
;   sub sp, sp, #16
; block0:
;   str x2, [sp]
;   movz x2, #10
;   str x2, [sp, #8]
;   movz x3, #15
;   movz x4, #20
;   movz x5, #25
;   movz x6, #30
;   movz x7, #35
;   movz x8, #40
;   movz x9, #45
;   movz x10, #50
;   movz x11, #55
;   movz x12, #60
;   movz x13, #65
;   movz x14, #70
;   movz x15, #75
;   movz x19, #80
;   movz x20, #85
;   movz x21, #90
;   movz x22, #95
;   movz x23, #100
;   movz x24, #105
;   movz x25, #110
;   movz x26, #115
;   movz x27, #120
;   movz x28, #125
;   movz x1, #130
;   movz x0, #135
;   ldr x2, [sp]
;   cbnz x2, label2 ; b label1
; block1:
;   movz x2, #140
;   str x1, [sp, #32]
;   str x0, [sp, #40]
;   str x2, [sp, #48]
;   load_ext_name x0, TestCase(%different_callee2)+0
;   ldr x2, [sp, #8]
;   return_call_ind x0 new_stack_arg_size:32 x2=x2 x3=x3 x4=x4 x5=x5 x6=x6 x7=x7 x8=x8 x9=x9 x10=x10 x11=x11 x12=x12 x13=x13 x14=x14 x15=x15 x19=x19 x20=x20 x21=x21 x22=x22 x23=x23 x24=x24 x25=x25 x26=x26 x27=x27 x28=x28
; block2:
;   ldr x2, [sp, #8]
;   str x1, [sp, #48]
;   str x0, [sp, #56]
;   load_ext_name x0, TestCase(%different_callee1)+0
;   return_call_ind x0 new_stack_arg_size:16 x2=x2 x3=x3 x4=x4 x5=x5 x6=x6 x7=x7 x8=x8 x9=x9 x10=x10 x11=x11 x12=x12 x13=x13 x14=x14 x15=x15 x19=x19 x20=x20 x21=x21 x22=x22 x23=x23 x24=x24 x25=x25 x26=x26 x27=x27 x28=x28
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   sub sp, sp, #0x20
;   ldur x29, [sp, #0x20]
;   stp x29, x30, [sp]
;   mov x29, sp
;   sub sp, sp, #0x10
; block1: ; offset 0x1c
;   stur x2, [sp]
;   mov x2, #0xa
;   stur x2, [sp, #8]
;   mov x3, #0xf
;   mov x4, #0x14
;   mov x5, #0x19
;   mov x6, #0x1e
;   mov x7, #0x23
;   mov x8, #0x28
;   mov x9, #0x2d
;   mov x10, #0x32
;   mov x11, #0x37
;   mov x12, #0x3c
;   mov x13, #0x41
;   mov x14, #0x46
;   mov x15, #0x4b
;   mov x19, #0x50
;   mov x20, #0x55
;   mov x21, #0x5a
;   mov x22, #0x5f
;   mov x23, #0x64
;   mov x24, #0x69
;   mov x25, #0x6e
;   mov x26, #0x73
;   mov x27, #0x78
;   mov x28, #0x7d
;   mov x1, #0x82
;   mov x0, #0x87
;   ldur x2, [sp]
;   cbnz x2, #0xc4
; block2: ; offset 0x94
;   mov x2, #0x8c
;   stur x1, [sp, #0x20]
;   stur x0, [sp, #0x28]
;   stur x2, [sp, #0x30]
;   ldr x0, #0xac
;   b #0xb4
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %different_callee2 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur x2, [sp, #8]
;   add sp, sp, #0x10
;   ldp x29, x30, [sp], #0x10
;   br x0
; block3: ; offset 0xc4
;   ldur x2, [sp, #8]
;   stur x1, [sp, #0x30]
;   stur x0, [sp, #0x38]
;   ldr x0, #0xd8
;   b #0xe0
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %different_callee1 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   add sp, sp, #0x10
;   ldp x29, x30, [sp], #0x10
;   add sp, sp, #0x10
;   br x0

