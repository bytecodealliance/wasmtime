test compile precise-output
set unwind_info=false
set enable_probestack=false
set enable_llvm_abi_extensions
target aarch64

function %f1(i64) -> i64 {
    fn0 = %g(i64) -> i64

block0(v0: i64):
    v1 = call fn0(v0)
    return v1
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   load_ext_name x3, TestCase(%g)+0
;   blr x3
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldr x3, #0x10
;   b #0x18
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x3
;   ldp x29, x30, [sp], #0x10
;   ret

function %f2(i32) -> i64 {
    fn0 = %g(i32 uext) -> i64

block0(v0: i32):
    v1 = call fn0(v0)
    return v1
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   load_ext_name x3, TestCase(%g)+0
;   blr x3
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldr x3, #0x10
;   b #0x18
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x3
;   ldp x29, x30, [sp], #0x10
;   ret

function %f3(i32) -> i32 uext {
block0(v0: i32):
    return v0
}

; VCode:
; block0:
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   ret

function %f4(i32) -> i64 {
    fn0 = %g(i32 sext) -> i64

block0(v0: i32):
    v1 = call fn0(v0)
    return v1
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   load_ext_name x3, TestCase(%g)+0
;   blr x3
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldr x3, #0x10
;   b #0x18
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x3
;   ldp x29, x30, [sp], #0x10
;   ret

function %f5(i32) -> i32 sext {
block0(v0: i32):
    return v0
}

; VCode:
; block0:
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   ret

function %f6(i8) -> i64 {
    fn0 = %g(i32, i32, i32, i32, i32, i32, i32, i32, i8 sext) -> i64

block0(v0: i8):
    v1 = iconst.i32 42
    v2 = call fn0(v1, v1, v1, v1, v1, v1, v1, v1, v0)
    return v2
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   sub sp, sp, #16
; block0:
;   movz w7, #42
;   strb w0, [sp]
;   load_ext_name x8, TestCase(%g)+0
;   mov x0, x7
;   mov x1, x7
;   mov x2, x7
;   mov x3, x7
;   mov x4, x7
;   mov x5, x7
;   mov x6, x7
;   blr x8
;   add sp, sp, #16
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   sub sp, sp, #0x10
; block1: ; offset 0xc
;   mov w7, #0x2a
;   sturb w0, [sp]
;   ldr x8, #0x1c
;   b #0x24
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   mov x0, x7
;   mov x1, x7
;   mov x2, x7
;   mov x3, x7
;   mov x4, x7
;   mov x5, x7
;   mov x6, x7
;   blr x8
;   add sp, sp, #0x10
;   ldp x29, x30, [sp], #0x10
;   ret

function %f7(i8) -> i32, i32, i32, i32, i32, i32, i32, i32, i8 sext {
block0(v0: i8):
    v1 = iconst.i32 42
    return v1, v1, v1, v1, v1, v1, v1, v1, v0
}

; VCode:
; block0:
;   movz w7, #42
;   strb w0, [x1]
;   mov x0, x7
;   mov x1, x7
;   mov x2, x7
;   mov x3, x7
;   mov x4, x7
;   mov x5, x7
;   mov x6, x7
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov w7, #0x2a
;   sturb w0, [x1]
;   mov x0, x7
;   mov x1, x7
;   mov x2, x7
;   mov x3, x7
;   mov x4, x7
;   mov x5, x7
;   mov x6, x7
;   ret

function %f8() {
    fn0 = %g0() -> f32
    fn1 = %g1() -> f64
    fn2 = %g2()
    fn3 = %g3(f32)
    fn4 = %g4(f64)

block0:
    v0 = call fn0()
    v1 = call fn1()
    v2 = call fn1()
    call fn2()
    call fn3(v0)
    call fn4(v1)
    call fn4(v2)
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   sub sp, sp, #48
; block0:
;   load_ext_name x9, TestCase(%g0)+0
;   blr x9
;   str q0, [sp, #32]
;   load_ext_name x9, TestCase(%g1)+0
;   blr x9
;   str q0, [sp, #16]
;   load_ext_name x9, TestCase(%g1)+0
;   blr x9
;   str q0, [sp]
;   load_ext_name x9, TestCase(%g2)+0
;   blr x9
;   load_ext_name x10, TestCase(%g3)+0
;   ldr q0, [sp, #32]
;   blr x10
;   load_ext_name x11, TestCase(%g4)+0
;   ldr q0, [sp, #16]
;   blr x11
;   load_ext_name x12, TestCase(%g4)+0
;   ldr q0, [sp]
;   blr x12
;   add sp, sp, #48
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   sub sp, sp, #0x30
; block1: ; offset 0xc
;   ldr x9, #0x14
;   b #0x1c
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g0 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp, #0x20]
;   ldr x9, #0x2c
;   b #0x34
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g1 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp, #0x10]
;   ldr x9, #0x44
;   b #0x4c
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g1 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp]
;   ldr x9, #0x5c
;   b #0x64
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g2 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   ldr x10, #0x70
;   b #0x78
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g3 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp, #0x20]
;   blr x10
;   ldr x11, #0x88
;   b #0x90
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g4 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp, #0x10]
;   blr x11
;   ldr x12, #0xa0
;   b #0xa8
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g4 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp]
;   blr x12
;   add sp, sp, #0x30
;   ldp x29, x30, [sp], #0x10
;   ret

function %f9() {
    fn0 = %g0() -> i8x16
    fn1 = %g1()
    fn2 = %g2(i8x16)

block0:
    v0 = call fn0()
    v1 = call fn0()
    v2 = call fn0()
    call fn1()
    call fn2(v0)
    call fn2(v1)
    call fn2(v2)
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   sub sp, sp, #48
; block0:
;   load_ext_name x9, TestCase(%g0)+0
;   blr x9
;   str q0, [sp, #32]
;   load_ext_name x9, TestCase(%g0)+0
;   blr x9
;   str q0, [sp, #16]
;   load_ext_name x9, TestCase(%g0)+0
;   blr x9
;   str q0, [sp]
;   load_ext_name x9, TestCase(%g1)+0
;   blr x9
;   load_ext_name x10, TestCase(%g2)+0
;   ldr q0, [sp, #32]
;   blr x10
;   load_ext_name x11, TestCase(%g2)+0
;   ldr q0, [sp, #16]
;   blr x11
;   load_ext_name x12, TestCase(%g2)+0
;   ldr q0, [sp]
;   blr x12
;   add sp, sp, #48
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   sub sp, sp, #0x30
; block1: ; offset 0xc
;   ldr x9, #0x14
;   b #0x1c
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g0 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp, #0x20]
;   ldr x9, #0x2c
;   b #0x34
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g0 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp, #0x10]
;   ldr x9, #0x44
;   b #0x4c
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g0 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp]
;   ldr x9, #0x5c
;   b #0x64
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g1 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   ldr x10, #0x70
;   b #0x78
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g2 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp, #0x20]
;   blr x10
;   ldr x11, #0x88
;   b #0x90
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g2 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp, #0x10]
;   blr x11
;   ldr x12, #0xa0
;   b #0xa8
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g2 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp]
;   blr x12
;   add sp, sp, #0x30
;   ldp x29, x30, [sp], #0x10
;   ret

function %f10() {
    fn0 = %g0() -> f32
    fn1 = %g1() -> f64
    fn2 = %g2() -> i8x16
    fn3 = %g3()
    fn4 = %g4(f32)
    fn5 = %g5(f64)
    fn6 = %g6(i8x16)

block0:
    v0 = call fn0()
    v1 = call fn1()
    v2 = call fn2()
    call fn3()
    call fn4(v0)
    call fn5(v1)
    call fn6(v2)
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   sub sp, sp, #48
; block0:
;   load_ext_name x9, TestCase(%g0)+0
;   blr x9
;   str q0, [sp, #32]
;   load_ext_name x9, TestCase(%g1)+0
;   blr x9
;   str q0, [sp, #16]
;   load_ext_name x9, TestCase(%g2)+0
;   blr x9
;   str q0, [sp]
;   load_ext_name x9, TestCase(%g3)+0
;   blr x9
;   load_ext_name x10, TestCase(%g4)+0
;   ldr q0, [sp, #32]
;   blr x10
;   load_ext_name x11, TestCase(%g5)+0
;   ldr q0, [sp, #16]
;   blr x11
;   load_ext_name x12, TestCase(%g6)+0
;   ldr q0, [sp]
;   blr x12
;   add sp, sp, #48
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   sub sp, sp, #0x30
; block1: ; offset 0xc
;   ldr x9, #0x14
;   b #0x1c
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g0 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp, #0x20]
;   ldr x9, #0x2c
;   b #0x34
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g1 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp, #0x10]
;   ldr x9, #0x44
;   b #0x4c
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g2 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   stur q0, [sp]
;   ldr x9, #0x5c
;   b #0x64
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g3 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x9
;   ldr x10, #0x70
;   b #0x78
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g4 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp, #0x20]
;   blr x10
;   ldr x11, #0x88
;   b #0x90
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g5 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp, #0x10]
;   blr x11
;   ldr x12, #0xa0
;   b #0xa8
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g6 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   ldur q0, [sp]
;   blr x12
;   add sp, sp, #0x30
;   ldp x29, x30, [sp], #0x10
;   ret

function %f11(i128, i64) -> i64 {
block0(v0: i128, v1: i64):
    v2, v3 = isplit v0
    return v3
}

; VCode:
; block0:
;   mov x0, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov x0, x1
;   ret

function %f11_call(i64) -> i64 {
    fn0 = %f11(i128, i64) -> i64

block0(v0: i64):
    v1 = iconst.i64 42
    v2 = iconcat v1, v0
    v3 = call fn0(v2, v1)
    return v3
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   mov x1, x0
;   movz x2, #42
;   load_ext_name x4, TestCase(%f11)+0
;   mov x0, x2
;   blr x4
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   mov x1, x0
;   mov x2, #0x2a
;   ldr x4, #0x18
;   b #0x20
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %f11 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   mov x0, x2
;   blr x4
;   ldp x29, x30, [sp], #0x10
;   ret

function %f12(i64, i128) -> i64 {
block0(v0: i64, v1: i128):
    v2, v3 = isplit v1
    return v2
}

; VCode:
; block0:
;   mov x0, x2
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov x0, x2
;   ret

function %f12_call(i64) -> i64 {
    fn0 = %f12(i64, i128) -> i64

block0(v0: i64):
    v1 = iconst.i64 42
    v2 = iconcat v0, v1
    v3 = call fn0(v1, v2)
    return v3
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   mov x2, x0
;   movz x3, #42
;   load_ext_name x4, TestCase(%f12)+0
;   mov x0, x3
;   blr x4
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   mov x2, x0
;   mov x3, #0x2a
;   ldr x4, #0x18
;   b #0x20
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %f12 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   mov x0, x3
;   blr x4
;   ldp x29, x30, [sp], #0x10
;   ret

function %f13(i64, i128) -> i64 apple_aarch64 {
block0(v0: i64, v1: i128):
    v2, v3 = isplit v1
    return v2
}

; VCode:
; block0:
;   mov x0, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov x0, x1
;   ret

function %f13_call(i64) -> i64 apple_aarch64 {
    fn0 = %f13(i64, i128) -> i64 apple_aarch64

block0(v0: i64):
    v1 = iconst.i64 42
    v2 = iconcat v0, v1
    v3 = call fn0(v1, v2)
    return v3
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   mov x1, x0
;   movz x2, #42
;   load_ext_name x4, TestCase(%f13)+0
;   mov x0, x2
;   blr x4
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   mov x1, x0
;   mov x2, #0x2a
;   ldr x4, #0x18
;   b #0x20
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %f13 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   mov x0, x2
;   blr x4
;   ldp x29, x30, [sp], #0x10
;   ret

function %f14(i128, i128, i128, i64, i128) -> i128 {
block0(v0: i128, v1: i128, v2: i128, v3: i64, v4: i128):
    return v4
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   ldr x0, [sp, #16]
;   ldr x1, [sp, #24]
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldur x0, [sp, #0x10]
;   ldur x1, [sp, #0x18]
;   ldp x29, x30, [sp], #0x10
;   ret

function %f14_call(i128, i64) -> i128 {
    fn0 = %f14(i128, i128, i128, i64, i128) -> i128

block0(v0: i128, v1: i64):
    v2 = call fn0(v0, v0, v0, v1, v0)
    return v2
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   sub sp, sp, #16
; block0:
;   mov x6, x2
;   str x0, [sp]
;   mov x4, x0
;   str x1, [sp, #8]
;   mov x5, x1
;   load_ext_name x8, TestCase(%f14)+0
;   mov x2, x4
;   mov x3, x5
;   blr x8
;   add sp, sp, #16
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   sub sp, sp, #0x10
; block1: ; offset 0xc
;   mov x6, x2
;   stur x0, [sp]
;   mov x4, x0
;   stur x1, [sp, #8]
;   mov x5, x1
;   ldr x8, #0x28
;   b #0x30
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %f14 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   mov x2, x4
;   mov x3, x5
;   blr x8
;   add sp, sp, #0x10
;   ldp x29, x30, [sp], #0x10
;   ret

function %f15(i128, i128, i128, i64, i128) -> i128 apple_aarch64{
block0(v0: i128, v1: i128, v2: i128, v3: i64, v4: i128):
    return v4
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   ldr x0, [sp, #16]
;   ldr x1, [sp, #24]
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldur x0, [sp, #0x10]
;   ldur x1, [sp, #0x18]
;   ldp x29, x30, [sp], #0x10
;   ret

function %f15_call(i128, i64) -> i128 apple_aarch64 {
    fn0 = %f15(i128, i128, i128, i64, i128) -> i128 apple_aarch64

block0(v0: i128, v1: i64):
    v2 = call fn0(v0, v0, v0, v1, v0)
    return v2
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   sub sp, sp, #16
; block0:
;   mov x6, x2
;   str x0, [sp]
;   mov x4, x0
;   str x1, [sp, #8]
;   mov x5, x1
;   load_ext_name x8, TestCase(%f15)+0
;   mov x2, x4
;   mov x3, x5
;   blr x8
;   add sp, sp, #16
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   sub sp, sp, #0x10
; block1: ; offset 0xc
;   mov x6, x2
;   stur x0, [sp]
;   mov x4, x0
;   stur x1, [sp, #8]
;   mov x5, x1
;   ldr x8, #0x28
;   b #0x30
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %f15 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   mov x2, x4
;   mov x3, x5
;   blr x8
;   add sp, sp, #0x10
;   ldp x29, x30, [sp], #0x10
;   ret

function %f17(i64 sret) {
block0(v0: i64):
    v1 = iconst.i64 42
    store v1, v0
    return
}

; VCode:
; block0:
;   movz x2, #42
;   str x2, [x8]
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov x2, #0x2a
;   str x2, [x8] ; trap: heap_oob
;   ret

function %f18(i64) -> i64 {
    fn0 = %g(i64 sret) -> i64

block0(v0: i64):
    v1 = call fn0(v0)
    return v1
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   mov x8, x0
;   load_ext_name x3, TestCase(%g)+0
;   blr x3
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   mov x8, x0
;   ldr x3, #0x14
;   b #0x1c
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x3
;   ldp x29, x30, [sp], #0x10
;   ret

function %f18(i64 sret) {
    fn0 = %g(i64 sret)

block0(v0: i64):
    call fn0(v0)
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   str x23, [sp, #-16]!
; block0:
;   mov x23, x8
;   load_ext_name x2, TestCase(%g)+0
;   blr x2
;   mov x8, x23
;   ldr x23, [sp], #16
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   str x23, [sp, #-0x10]!
; block1: ; offset 0xc
;   mov x23, x8
;   ldr x2, #0x18
;   b #0x20
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x2
;   mov x8, x23
;   ldr x23, [sp], #0x10
;   ldp x29, x30, [sp], #0x10
;   ret

function %f19() system_v {
    fn0 = %g() fast

block0:
    call fn0()
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
; block0:
;   load_ext_name x0, TestCase(%g)+0
;   blr x0
;   ldp fp, lr, [sp], #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
; block1: ; offset 0x8
;   ldr x0, #0x10
;   b #0x18
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %g 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x0
;   ldp x29, x30, [sp], #0x10
;   ret

function %second_f16(f16, f16) -> f16 system_v {
block0(v0: f16, v1: f16):
    return v1
}

; VCode:
; block0:
;   mov v0.16b, v1.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov v0.16b, v1.16b
;   ret

function %second_f128(f128, f128) -> f128 system_v {
block0(v0: f128, v1: f128):
    return v1
}

; VCode:
; block0:
;   mov v0.16b, v1.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov v0.16b, v1.16b
;   ret

function %second_f16_apple(f16, f16) -> f16 apple_aarch64 {
block0(v0: f16, v1: f16):
    return v1
}

; VCode:
; block0:
;   mov v0.16b, v1.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov v0.16b, v1.16b
;   ret

function %second_f128_apple(f128, f128) -> f128 apple_aarch64 {
block0(v0: f128, v1: f128):
    return v1
}

; VCode:
; block0:
;   mov v0.16b, v1.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov v0.16b, v1.16b
;   ret

