test compile precise-output
set unwind_info=false
target aarch64

function %a(i8) -> i8 {
block0(v0: i8):
    v1 = bitrev v0
    return v1
}

; VCode:
; block0:
;   rbit w2, w0
;   lsr w0, w2, #24
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit w2, w0
;   lsr w0, w2, #0x18
;   ret

function %a(i16) -> i16 {
block0(v0: i16):
    v1 = bitrev v0
    return v1
}

; VCode:
; block0:
;   rbit w2, w0
;   lsr w0, w2, #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit w2, w0
;   lsr w0, w2, #0x10
;   ret

function %a(i32) -> i32 {
block0(v0: i32):
    v1 = bitrev v0
    return v1
}

; VCode:
; block0:
;   rbit w0, w0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit w0, w0
;   ret

function %a(i64) -> i64 {
block0(v0: i64):
    v1 = bitrev v0
    return v1
}

; VCode:
; block0:
;   rbit x0, x0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit x0, x0
;   ret

function %a(i128) -> i128 {
block0(v0: i128):
    v1 = bitrev v0
    return v1
}

; VCode:
; block0:
;   mov x6, x1
;   rbit x1, x0
;   rbit x0, x6
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov x6, x1
;   rbit x1, x0
;   rbit x0, x6
;   ret

function %b(i8) -> i8 {
block0(v0: i8):
    v1 = clz v0
    return v1
}

; VCode:
; block0:
;   uxtb w2, w0
;   clz w4, w2
;   sub w0, w4, #24
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   uxtb w2, w0
;   clz w4, w2
;   sub w0, w4, #0x18
;   ret

function %b(i16) -> i16 {
block0(v0: i16):
    v1 = clz v0
    return v1
}

; VCode:
; block0:
;   uxth w2, w0
;   clz w4, w2
;   sub w0, w4, #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   uxth w2, w0
;   clz w4, w2
;   sub w0, w4, #0x10
;   ret

function %b(i32) -> i32 {
block0(v0: i32):
    v1 = clz v0
    return v1
}

; VCode:
; block0:
;   clz w0, w0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   clz w0, w0
;   ret

function %b(i64) -> i64 {
block0(v0: i64):
    v1 = clz v0
    return v1
}

; VCode:
; block0:
;   clz x0, x0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   clz x0, x0
;   ret

function %b(i128) -> i128 {
block0(v0: i128):
    v1 = clz v0
    return v1
}

; VCode:
; block0:
;   clz x3, x1
;   clz x5, x0
;   lsr x7, x3, #6
;   madd x0, x5, x7, x3
;   movz x1, #0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   clz x3, x1
;   clz x5, x0
;   lsr x7, x3, #6
;   madd x0, x5, x7, x3
;   mov x1, #0
;   ret

function %c(i8) -> i8 {
block0(v0: i8):
    v1 = cls v0
    return v1
}

; VCode:
; block0:
;   sxtb w2, w0
;   cls w4, w2
;   sub w0, w4, #24
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   sxtb w2, w0
;   cls w4, w2
;   sub w0, w4, #0x18
;   ret

function %c(i16) -> i16 {
block0(v0: i16):
    v1 = cls v0
    return v1
}

; VCode:
; block0:
;   sxth w2, w0
;   cls w4, w2
;   sub w0, w4, #16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   sxth w2, w0
;   cls w4, w2
;   sub w0, w4, #0x10
;   ret

function %c(i32) -> i32 {
block0(v0: i32):
    v1 = cls v0
    return v1
}

; VCode:
; block0:
;   cls w0, w0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   cls w0, w0
;   ret

function %c(i64) -> i64 {
block0(v0: i64):
    v1 = cls v0
    return v1
}

; VCode:
; block0:
;   cls x0, x0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   cls x0, x0
;   ret

function %c(i128) -> i128 {
block0(v0: i128):
    v1 = cls v0
    return v1
}

; VCode:
; block0:
;   cls x3, x0
;   cls x5, x1
;   eon x7, x1, x0
;   lsr x9, x7, #63
;   madd x11, x3, x9, x9
;   subs xzr, x5, #63
;   csel x14, x11, xzr, eq
;   add x0, x14, x5
;   movz x1, #0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   cls x3, x0
;   cls x5, x1
;   eon x7, x1, x0
;   lsr x9, x7, #0x3f
;   madd x11, x3, x9, x9
;   cmp x5, #0x3f
;   csel x14, x11, xzr, eq
;   add x0, x14, x5
;   mov x1, #0
;   ret

function %d(i8) -> i8 {
block0(v0: i8):
    v1 = ctz v0
    return v1
}

; VCode:
; block0:
;   rbit w2, w0
;   orr w4, w2, #8388608
;   clz w0, w4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit w2, w0
;   orr w4, w2, #0x800000
;   clz w0, w4
;   ret

function %d(i16) -> i16 {
block0(v0: i16):
    v1 = ctz v0
    return v1
}

; VCode:
; block0:
;   rbit w2, w0
;   orr w4, w2, #32768
;   clz w0, w4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit w2, w0
;   orr w4, w2, #0x8000
;   clz w0, w4
;   ret

function %d(i32) -> i32 {
block0(v0: i32):
    v1 = ctz v0
    return v1
}

; VCode:
; block0:
;   rbit w2, w0
;   clz w0, w2
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit w2, w0
;   clz w0, w2
;   ret

function %d(i64) -> i64 {
block0(v0: i64):
    v1 = ctz v0
    return v1
}

; VCode:
; block0:
;   rbit x2, x0
;   clz x0, x2
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit x2, x0
;   clz x0, x2
;   ret

function %d(i128) -> i128 {
block0(v0: i128):
    v1 = ctz v0
    return v1
}

; VCode:
; block0:
;   rbit x3, x0
;   rbit x5, x1
;   clz x7, x3
;   clz x9, x5
;   lsr x11, x7, #6
;   madd x0, x9, x11, x7
;   movz x1, #0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   rbit x3, x0
;   rbit x5, x1
;   clz x7, x3
;   clz x9, x5
;   lsr x11, x7, #6
;   madd x0, x9, x11, x7
;   mov x1, #0
;   ret

function %d(i128) -> i128 {
block0(v0: i128):
    v1 = popcnt v0
    return v1
}

; VCode:
; block0:
;   fmov d4, x0
;   mov v4.d[1], v4.d[1], x1
;   cnt v7.16b, v4.16b
;   addv b17, v7.16b
;   umov w0, v17.b[0]
;   movz x1, #0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   fmov d4, x0
;   mov v4.d[1], x1
;   cnt v7.16b, v4.16b
;   addv b17, v7.16b
;   umov w0, v17.b[0]
;   mov x1, #0
;   ret

function %d(i64) -> i64 {
block0(v0: i64):
    v1 = popcnt v0
    return v1
}

; VCode:
; block0:
;   fmov d2, x0
;   cnt v4.8b, v2.8b
;   addv b6, v4.8b
;   umov w0, v6.b[0]
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   fmov d2, x0
;   cnt v4.8b, v2.8b
;   addv b6, v4.8b
;   umov w0, v6.b[0]
;   ret

function %d(i32) -> i32 {
block0(v0: i32):
    v1 = popcnt v0
    return v1
}

; VCode:
; block0:
;   fmov s2, w0
;   cnt v4.8b, v2.8b
;   addv b6, v4.8b
;   umov w0, v6.b[0]
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   fmov s2, w0
;   cnt v4.8b, v2.8b
;   addv b6, v4.8b
;   umov w0, v6.b[0]
;   ret

function %d(i16) -> i16 {
block0(v0: i16):
    v1 = popcnt v0
    return v1
}

; VCode:
; block0:
;   fmov s2, w0
;   cnt v4.8b, v2.8b
;   addp v6.8b, v4.8b, v4.8b
;   umov w0, v6.b[0]
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   fmov s2, w0
;   cnt v4.8b, v2.8b
;   addp v6.8b, v4.8b, v4.8b
;   umov w0, v6.b[0]
;   ret

function %d(i8) -> i8 {
block0(v0: i8):
    v1 = popcnt v0
    return v1
}

; VCode:
; block0:
;   fmov s2, w0
;   cnt v4.8b, v2.8b
;   umov w0, v4.b[0]
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   fmov s2, w0
;   cnt v4.8b, v2.8b
;   umov w0, v4.b[0]
;   ret

function %sextend_i8() -> i32 {
block0:
    v1 = iconst.i8 -1
    v2 = sextend.i32 v1
    return v2
}

; VCode:
; block0:
;   movz w1, #255
;   sxtb w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov w1, #0xff
;   sxtb w0, w1
;   ret

function %sextend_i8() -> i32 {
block0:
    v1 = iconst.i8 -1
    v2 = sextend.i32 v1
    return v2
}

; VCode:
; block0:
;   movz w1, #255
;   sxtb w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mov w1, #0xff
;   sxtb w0, w1
;   ret

function %bnot_i32(i32) -> i32 {
block0(v0: i32):
    v1 = bnot v0
    return v1
}

; VCode:
; block0:
;   orn w0, wzr, w0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mvn w0, w0
;   ret

function %bnot_i64(i64) -> i64 {
block0(v0: i64):
    v1 = bnot v0
    return v1
}

; VCode:
; block0:
;   orn x0, xzr, x0
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mvn x0, x0
;   ret

function %bnot_i64_with_shift(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = ishl.i64 v0, v1
    v3 = bnot v2
    return v3
}

; VCode:
; block0:
;   orn x0, xzr, x0, LSL 3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mvn x0, x0, lsl #3
;   ret

function %bnot_i128(i128) -> i128 {
block0(v0: i128):
    v1 = bnot v0
    return v1
}

; VCode:
; block0:
;   orn x0, xzr, x0
;   orn x1, xzr, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mvn x0, x0
;   mvn x1, x1
;   ret

function %bnot_i8x16(i8x16) -> i8x16 {
block0(v0: i8x16):
    v1 = bnot v0
    return v1
}

; VCode:
; block0:
;   mvn v0.16b, v0.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   mvn v0.16b, v0.16b
;   ret

function %band_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = band v0, v1
    return v2
}

; VCode:
; block0:
;   and w0, w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and w0, w0, w1
;   ret

function %band_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = band v0, v1
    return v2
}

; VCode:
; block0:
;   and x0, x0, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and x0, x0, x1
;   ret

function %band_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = band v0, v1
    return v2
}

; VCode:
; block0:
;   and x0, x0, x2
;   and x1, x1, x3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and x0, x0, x2
;   and x1, x1, x3
;   ret

function %band_i8x16(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = band v0, v1
    return v2
}

; VCode:
; block0:
;   and v0.16b, v0.16b, v1.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and v0.16b, v0.16b, v1.16b
;   ret

function %band_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = band v0, v1
    return v2
}

; VCode:
; block0:
;   and x0, x0, #3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and x0, x0, #3
;   ret

function %band_i64_constant2(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = band v1, v0
    return v2
}

; VCode:
; block0:
;   and x0, x0, #3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and x0, x0, #3
;   ret

function %band_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = band v0, v3
    return v4
}

; VCode:
; block0:
;   and x0, x0, x1, LSL 3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and x0, x0, x1, lsl #3
;   ret

function %band_i64_constant_shift2(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = band v3, v0
    return v4
}

; VCode:
; block0:
;   and x0, x0, x1, LSL 3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and x0, x0, x1, lsl #3
;   ret

function %bor_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = bor v0, v1
    return v2
}

; VCode:
; block0:
;   orr w0, w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr w0, w0, w1
;   ret

function %bor_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = bor v0, v1
    return v2
}

; VCode:
; block0:
;   orr x0, x0, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr x0, x0, x1
;   ret

function %bor_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bor v0, v1
    return v2
}

; VCode:
; block0:
;   orr x0, x0, x2
;   orr x1, x1, x3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr x0, x0, x2
;   orr x1, x1, x3
;   ret

function %bor_i8x16(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = bor v0, v1
    return v2
}

; VCode:
; block0:
;   orr v0.16b, v0.16b, v1.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr v0.16b, v0.16b, v1.16b
;   ret

function %bor_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = bor v0, v1
    return v2
}

; VCode:
; block0:
;   orr x0, x0, #3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr x0, x0, #3
;   ret

function %bor_i64_constant2(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = bor v1, v0
    return v2
}

; VCode:
; block0:
;   orr x0, x0, #3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr x0, x0, #3
;   ret

function %bor_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = bor v0, v3
    return v4
}

; VCode:
; block0:
;   orr x0, x0, x1, LSL 3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr x0, x0, x1, lsl #3
;   ret

function %bor_i64_constant_shift2(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = bor v3, v0
    return v4
}

; VCode:
; block0:
;   orr x0, x0, x1, LSL 3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr x0, x0, x1, lsl #3
;   ret

function %bxor_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = bxor v0, v1
    return v2
}

; VCode:
; block0:
;   eor w0, w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor w0, w0, w1
;   ret

function %bxor_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = bxor v0, v1
    return v2
}

; VCode:
; block0:
;   eor x0, x0, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor x0, x0, x1
;   ret

function %bxor_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bxor v0, v1
    return v2
}

; VCode:
; block0:
;   eor x0, x0, x2
;   eor x1, x1, x3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor x0, x0, x2
;   eor x1, x1, x3
;   ret

function %bxor_i8x16(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = bxor v0, v1
    return v2
}

; VCode:
; block0:
;   eor v0.16b, v0.16b, v1.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor v0.16b, v0.16b, v1.16b
;   ret

function %bxor_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = bxor v0, v1
    return v2
}

; VCode:
; block0:
;   eor x0, x0, #3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor x0, x0, #3
;   ret

function %bxor_i64_constant2(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = bxor v1, v0
    return v2
}

; VCode:
; block0:
;   eor x0, x0, #3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor x0, x0, #3
;   ret

function %bxor_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = bxor v0, v3
    return v4
}

; VCode:
; block0:
;   eor x0, x0, x1, LSL 3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor x0, x0, x1, lsl #3
;   ret

function %bxor_i64_constant_shift2(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = bxor v3, v0
    return v4
}

; VCode:
; block0:
;   eor x0, x0, x1, LSL 3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor x0, x0, x1, lsl #3
;   ret

function %band_not_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = band_not v0, v1
    return v2
}

; VCode:
; block0:
;   bic w0, w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   bic w0, w0, w1
;   ret

function %band_not_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = band_not v0, v1
    return v2
}

; VCode:
; block0:
;   bic x0, x0, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   bic x0, x0, x1
;   ret

function %band_not_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = band_not v0, v1
    return v2
}

; VCode:
; block0:
;   bic x0, x0, x2
;   bic x1, x1, x3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   bic x0, x0, x2
;   bic x1, x1, x3
;   ret

function %band_not_i8x16(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = band_not v0, v1
    return v2
}

; VCode:
; block0:
;   bic v0.16b, v0.16b, v1.16b
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   bic v0.16b, v0.16b, v1.16b
;   ret

function %band_not_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 4
    v2 = band_not v0, v1
    return v2
}

; VCode:
; block0:
;   bic x0, x0, #4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   and x0, x0, #0xfffffffffffffffb
;   ret

function %band_not_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 4
    v3 = ishl.i64 v1, v2
    v4 = band_not v0, v3
    return v4
}

; VCode:
; block0:
;   bic x0, x0, x1, LSL 4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   bic x0, x0, x1, lsl #4
;   ret

function %bor_not_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = bor_not v0, v1
    return v2
}

; VCode:
; block0:
;   orn w0, w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orn w0, w0, w1
;   ret

function %bor_not_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = bor_not v0, v1
    return v2
}

; VCode:
; block0:
;   orn x0, x0, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orn x0, x0, x1
;   ret

function %bor_not_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bor_not v0, v1
    return v2
}

; VCode:
; block0:
;   orn x0, x0, x2
;   orn x1, x1, x3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orn x0, x0, x2
;   orn x1, x1, x3
;   ret

function %bor_not_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 4
    v2 = bor_not v0, v1
    return v2
}

; VCode:
; block0:
;   orn x0, x0, #4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orr x0, x0, #0xfffffffffffffffb
;   ret

function %bor_not_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 4
    v3 = ishl.i64 v1, v2
    v4 = bor_not v0, v3
    return v4
}

; VCode:
; block0:
;   orn x0, x0, x1, LSL 4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   orn x0, x0, x1, lsl #4
;   ret

function %bxor_not_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = bxor_not v0, v1
    return v2
}

; VCode:
; block0:
;   eon w0, w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eon w0, w0, w1
;   ret

function %bxor_not_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = bxor_not v0, v1
    return v2
}

; VCode:
; block0:
;   eon x0, x0, x1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eon x0, x0, x1
;   ret

function %bxor_not_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bxor_not v0, v1
    return v2
}

; VCode:
; block0:
;   eon x0, x0, x2
;   eon x1, x1, x3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eon x0, x0, x2
;   eon x1, x1, x3
;   ret

function %bxor_not_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 4
    v2 = bxor_not v0, v1
    return v2
}

; VCode:
; block0:
;   eon x0, x0, #4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eor x0, x0, #0xfffffffffffffffb
;   ret

function %bxor_not_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 4
    v3 = ishl.i64 v1, v2
    v4 = bxor_not v0, v3
    return v4
}

; VCode:
; block0:
;   eon x0, x0, x1, LSL 4
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eon x0, x0, x1, lsl #4
;   ret

function %ishl_i128_i8(i128, i8) -> i128 {
block0(v0: i128, v1: i8):
    v2 = ishl.i128 v0, v1
    return v2
}

; VCode:
; block0:
;   lsl x4, x0, x2
;   lsl x6, x1, x2
;   orn w8, wzr, w2
;   lsr x10, x0, #1
;   lsr x12, x10, x8
;   orr x14, x6, x12
;   ands xzr, x2, #64
;   csel x0, xzr, x4, ne
;   csel x1, x4, x14, ne
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   lsl x4, x0, x2
;   lsl x6, x1, x2
;   mvn w8, w2
;   lsr x10, x0, #1
;   lsr x12, x10, x8
;   orr x14, x6, x12
;   tst x2, #0x40
;   csel x0, xzr, x4, ne
;   csel x1, x4, x14, ne
;   ret

function %ishl_i128_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = ishl.i128 v0, v1
    return v2
}

; VCode:
; block0:
;   lsl x5, x0, x2
;   lsl x7, x1, x2
;   orn w9, wzr, w2
;   lsr x11, x0, #1
;   lsr x13, x11, x9
;   orr x15, x7, x13
;   ands xzr, x2, #64
;   csel x0, xzr, x5, ne
;   csel x1, x5, x15, ne
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   lsl x5, x0, x2
;   lsl x7, x1, x2
;   mvn w9, w2
;   lsr x11, x0, #1
;   lsr x13, x11, x9
;   orr x15, x7, x13
;   tst x2, #0x40
;   csel x0, xzr, x5, ne
;   csel x1, x5, x15, ne
;   ret

function %ushr_i128_i8(i128, i8) -> i128 {
block0(v0: i128, v1: i8):
    v2 = ushr.i128 v0, v1
    return v2
}

; VCode:
; block0:
;   lsr x4, x0, x2
;   lsr x6, x1, x2
;   orn w8, wzr, w2
;   lsl x10, x1, #1
;   lsl x12, x10, x8
;   orr x14, x4, x12
;   ands xzr, x2, #64
;   csel x0, x6, x14, ne
;   csel x1, xzr, x6, ne
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   lsr x4, x0, x2
;   lsr x6, x1, x2
;   mvn w8, w2
;   lsl x10, x1, #1
;   lsl x12, x10, x8
;   orr x14, x4, x12
;   tst x2, #0x40
;   csel x0, x6, x14, ne
;   csel x1, xzr, x6, ne
;   ret

function %ushr_i128_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = ushr.i128 v0, v1
    return v2
}

; VCode:
; block0:
;   lsr x5, x0, x2
;   lsr x7, x1, x2
;   orn w9, wzr, w2
;   lsl x11, x1, #1
;   lsl x13, x11, x9
;   orr x15, x5, x13
;   ands xzr, x2, #64
;   csel x0, x7, x15, ne
;   csel x1, xzr, x7, ne
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   lsr x5, x0, x2
;   lsr x7, x1, x2
;   mvn w9, w2
;   lsl x11, x1, #1
;   lsl x13, x11, x9
;   orr x15, x5, x13
;   tst x2, #0x40
;   csel x0, x7, x15, ne
;   csel x1, xzr, x7, ne
;   ret

function %sshr_i128_i8(i128, i8) -> i128 {
block0(v0: i128, v1: i8):
    v2 = sshr.i128 v0, v1
    return v2
}

; VCode:
; block0:
;   lsr x4, x0, x2
;   asr x6, x1, x2
;   orn w8, wzr, w2
;   lsl x10, x1, #1
;   lsl x12, x10, x8
;   asr x14, x1, #63
;   orr x0, x4, x12
;   ands xzr, x2, #64
;   csel x0, x6, x0, ne
;   csel x1, x14, x6, ne
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   lsr x4, x0, x2
;   asr x6, x1, x2
;   mvn w8, w2
;   lsl x10, x1, #1
;   lsl x12, x10, x8
;   asr x14, x1, #0x3f
;   orr x0, x4, x12
;   tst x2, #0x40
;   csel x0, x6, x0, ne
;   csel x1, x14, x6, ne
;   ret

function %sshr_i128_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = sshr.i128 v0, v1
    return v2
}

; VCode:
; block0:
;   lsr x5, x0, x2
;   asr x7, x1, x2
;   orn w9, wzr, w2
;   lsl x11, x1, #1
;   lsl x13, x11, x9
;   asr x15, x1, #63
;   orr x1, x5, x13
;   ands xzr, x2, #64
;   csel x0, x7, x1, ne
;   csel x1, x15, x7, ne
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   lsr x5, x0, x2
;   asr x7, x1, x2
;   mvn w9, w2
;   lsl x11, x1, #1
;   lsl x13, x11, x9
;   asr x15, x1, #0x3f
;   orr x1, x5, x13
;   tst x2, #0x40
;   csel x0, x7, x1, ne
;   csel x1, x15, x7, ne
;   ret

function %bnot_of_bxor(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = bxor v0, v1
  v3 = bnot v2
  return v3
}

; VCode:
; block0:
;   eon w0, w0, w1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eon w0, w0, w1
;   ret

function %bnot_of_bxor(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = bxor v0, v1
  v3 = bnot v2
  return v3
}

; VCode:
; block0:
;   eon x0, x0, x2
;   eon x1, x1, x3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   eon x0, x0, x2
;   eon x1, x1, x3
;   ret

