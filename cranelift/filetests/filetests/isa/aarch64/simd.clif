test compile
target aarch64

function %f1() -> i64x2 {
block0:
  v0 = iconst.i64 281474976710657
  v1 = splat.i64x2 v0
  return v1
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  movz x0, #1
; nextln:  movk x0, #1, LSL #48
; nextln:  dup v0.2d, x0
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f2() -> i16x8 {
block0:
  v0 = iconst.i32 42679
  v1 = ireduce.i16 v0
  v2 = splat.i16x8 v1
  return v2
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  movz x0, #42679
; nextln:  dup v0.8h, w0
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f3() -> b8x16 {
block0:
  v0 = bconst.b32 true
  v1 = breduce.b8 v0
  v2 = splat.b8x16 v1
  return v2
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  movi v0.16b, #255
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f4(i32, i8x16, i8x16) -> i8x16 {
block0(v0: i32, v1: i8x16, v2: i8x16):
   v3 = select v0, v1, v2
   return v3
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  subs wzr, w0, wzr
; nextln:  vcsel v0.16b, v0.16b, v1.16b, ne (if-then-else diamond)
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f5(i64) -> i8x16 {
block0(v0: i64):
  v1 = load.i8 v0
  v2 = splat.i8x16 v1
  return v2
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  ld1r { v0.16b }, [x0]
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f6(i64, i64) -> i8x16, i8x16 {
block0(v0: i64, v1: i64):
  v2 = load.i8 v0
  v3 = load.i8 v1
  v4 = splat.i8x16 v2
  v5 = splat.i8x16 v3
  return v4, v5
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  ld1r { v0.16b }, [x0]
; nextln:  ld1r { v1.16b }, [x1]
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f7(i64, i64) -> i8x16, i8x16 {
block0(v0: i64, v1: i64):
  v2 = load.i8 v0
  v3 = load.i8 v1
  v4 = splat.i8x16 v3
  v5 = splat.i8x16 v2
  return v4, v5
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  ldrb w0, [x0]
; nextln:  ld1r { v0.16b }, [x1]
; nextln:  dup v1.16b, w0
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f8(i64, i64) -> i8x16, i8x16 {
block0(v0: i64, v1: i64):
  v2 = load.i8 v0
  v3 = splat.i8x16 v2
  v4 = splat.i8x16 v2
  return v3, v4
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  ldrb w0, [x0]
; nextln:  dup v0.16b, w0
; nextln:  dup v1.16b, w0
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f9() -> i32x2 {
block0:
  v0 = iconst.i32 4278190335
  v1 = splat.i32x2 v0
  return v1
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  movi v0.2d, #18374687579166474495
; nextln:  fmov d0, d0
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f10() -> i32x4 {
block0:
  v0 = iconst.i32 4293918720
  v1 = splat.i32x4 v0
  return v1
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  mvni v0.4s, #15, MSL #16
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret

function %f11() -> f32x4 {
block0:
  v0 = f32const 0x1.5
  v1 = splat.f32x4 v0
  return v1
}

; check:  stp fp, lr, [sp, #-16]!
; nextln:  mov fp, sp
; nextln:  fmov v0.4s, #1.3125
; nextln:  mov sp, fp
; nextln:  ldp fp, lr, [sp], #16
; nextln:  ret
