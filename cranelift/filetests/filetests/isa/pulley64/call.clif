test compile precise-output
set enable_multi_ret_implicit_sret
target pulley64

function %colocated_args_i64_rets_i64() -> i64 {
    fn0 = colocated %g(i64) -> i64

block0:
    v0 = iconst.i64 0
    v1 = call fn0(v0)
    v2 = iconst.i64 1
    return v2
}

; VCode:
;   x30 = xconst8 -16
;   x27 = xadd32 x27, x30
;   store64 sp+8, x28 // flags =  notrap aligned
;   store64 sp+0, x29 // flags =  notrap aligned
;   x29 = xmov x27
; block0:
;   x0 = xconst8 0
;   call CallInfo { dest: TestCase(%g), uses: [CallArgPair { vreg: p0i, preg: p0i }], defs: [CallRetPair { vreg: Writable { reg: p0i }, preg: p0i }], clobbers: PRegSet { bits: [65534, 65279, 4294967295, 0] }, callee_conv: Fast, caller_conv: Fast, callee_pop_size: 0 }
;   x0 = xconst8 1
;   x28 = load64_u sp+8 // flags = notrap aligned
;   x29 = load64_u sp+0 // flags = notrap aligned
;   x30 = xconst8 16
;   x27 = xadd32 x27, x30
;   ret
;
; Disassembled:
; xconst8 spilltmp0, -16
; xadd32 sp, sp, spilltmp0
; store64_offset8 sp, 8, lr
; store64 sp, fp
; xmov fp, sp
; xconst8 x0, 0
; call 0x0    // target = 0x13
; xconst8 x0, 1
; load64_offset8 lr, sp, 8
; load64 fp, sp
; xconst8 spilltmp0, 16
; xadd32 sp, sp, spilltmp0
; ret

function %colocated_args_i32_rets_i32() -> i32 {
    fn0 = colocated %g(i32) -> i32

block0:
    v0 = iconst.i32 0
    v1 = call fn0(v0)
    v2 = iconst.i32 1
    return v2
}

; VCode:
;   x30 = xconst8 -16
;   x27 = xadd32 x27, x30
;   store64 sp+8, x28 // flags =  notrap aligned
;   store64 sp+0, x29 // flags =  notrap aligned
;   x29 = xmov x27
; block0:
;   x0 = xconst8 0
;   call CallInfo { dest: TestCase(%g), uses: [CallArgPair { vreg: p0i, preg: p0i }], defs: [CallRetPair { vreg: Writable { reg: p0i }, preg: p0i }], clobbers: PRegSet { bits: [65534, 65279, 4294967295, 0] }, callee_conv: Fast, caller_conv: Fast, callee_pop_size: 0 }
;   x0 = xconst8 1
;   x28 = load64_u sp+8 // flags = notrap aligned
;   x29 = load64_u sp+0 // flags = notrap aligned
;   x30 = xconst8 16
;   x27 = xadd32 x27, x30
;   ret
;
; Disassembled:
; xconst8 spilltmp0, -16
; xadd32 sp, sp, spilltmp0
; store64_offset8 sp, 8, lr
; store64 sp, fp
; xmov fp, sp
; xconst8 x0, 0
; call 0x0    // target = 0x13
; xconst8 x0, 1
; load64_offset8 lr, sp, 8
; load64 fp, sp
; xconst8 spilltmp0, 16
; xadd32 sp, sp, spilltmp0
; ret

function %colocated_args_i64_i32_i64_i32() {
    fn0 = colocated %g(i64, i32, i64, i32)

block0:
    v0 = iconst.i64 0
    v1 = iconst.i32 1
    v2 = iconst.i64 2
    v3 = iconst.i32 3
    call fn0(v0, v1, v2, v3)
    return
}

; VCode:
;   x30 = xconst8 -16
;   x27 = xadd32 x27, x30
;   store64 sp+8, x28 // flags =  notrap aligned
;   store64 sp+0, x29 // flags =  notrap aligned
;   x29 = xmov x27
; block0:
;   x0 = xconst8 0
;   x1 = xconst8 1
;   x2 = xconst8 2
;   x3 = xconst8 3
;   call CallInfo { dest: TestCase(%g), uses: [CallArgPair { vreg: p0i, preg: p0i }, CallArgPair { vreg: p1i, preg: p1i }, CallArgPair { vreg: p2i, preg: p2i }, CallArgPair { vreg: p3i, preg: p3i }], defs: [], clobbers: PRegSet { bits: [65535, 65279, 4294967295, 0] }, callee_conv: Fast, caller_conv: Fast, callee_pop_size: 0 }
;   x28 = load64_u sp+8 // flags = notrap aligned
;   x29 = load64_u sp+0 // flags = notrap aligned
;   x30 = xconst8 16
;   x27 = xadd32 x27, x30
;   ret
;
; Disassembled:
; xconst8 spilltmp0, -16
; xadd32 sp, sp, spilltmp0
; store64_offset8 sp, 8, lr
; store64 sp, fp
; xmov fp, sp
; xconst8 x0, 0
; xconst8 x1, 1
; xconst8 x2, 2
; xconst8 x3, 3
; call 0x0    // target = 0x1c
; load64_offset8 lr, sp, 8
; load64 fp, sp
; xconst8 spilltmp0, 16
; xadd32 sp, sp, spilltmp0
; ret

function %colocated_rets_i64_i64_i64_i64() -> i64 {
    fn0 = colocated %g() -> i64, i64, i64, i64

block0:
    v0, v1, v2, v3 = call fn0()
    v4 = iadd v0, v2
    v5 = iadd v1, v3
    v6 = iadd v4, v5
    return v6
}

; VCode:
;   x30 = xconst8 -16
;   x27 = xadd32 x27, x30
;   store64 sp+8, x28 // flags =  notrap aligned
;   store64 sp+0, x29 // flags =  notrap aligned
;   x29 = xmov x27
; block0:
;   call CallInfo { dest: TestCase(%g), uses: [], defs: [CallRetPair { vreg: Writable { reg: p0i }, preg: p0i }, CallRetPair { vreg: Writable { reg: p1i }, preg: p1i }, CallRetPair { vreg: Writable { reg: p2i }, preg: p2i }, CallRetPair { vreg: Writable { reg: p3i }, preg: p3i }], clobbers: PRegSet { bits: [65520, 65279, 4294967295, 0] }, callee_conv: Fast, caller_conv: Fast, callee_pop_size: 0 }
;   x4 = xadd64 x0, x2
;   x3 = xadd64 x1, x3
;   x0 = xadd64 x4, x3
;   x28 = load64_u sp+8 // flags = notrap aligned
;   x29 = load64_u sp+0 // flags = notrap aligned
;   x30 = xconst8 16
;   x27 = xadd32 x27, x30
;   ret
;
; Disassembled:
; xconst8 spilltmp0, -16
; xadd32 sp, sp, spilltmp0
; store64_offset8 sp, 8, lr
; store64 sp, fp
; xmov fp, sp
; call 0x0    // target = 0x10
; xadd64 x4, x0, x2
; xadd64 x3, x1, x3
; xadd64 x0, x4, x3
; load64_offset8 lr, sp, 8
; load64 fp, sp
; xconst8 spilltmp0, 16
; xadd32 sp, sp, spilltmp0
; ret

function %colocated_stack_args() {
    fn0 = colocated %g(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64)

block0:
    v0 = iconst.i64 0
    call fn0(v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0, v0)
    return
}

; VCode:
;   x30 = xconst8 -16
;   x27 = xadd32 x27, x30
;   store64 sp+8, x28 // flags =  notrap aligned
;   store64 sp+0, x29 // flags =  notrap aligned
;   x29 = xmov x27
;   x30 = xconst8 -48
;   x27 = xadd32 x27, x30
; block0:
;   x15 = xconst8 0
;   store64 OutgoingArg(0), x15 // flags =  notrap aligned
;   store64 OutgoingArg(8), x15 // flags =  notrap aligned
;   store64 OutgoingArg(16), x15 // flags =  notrap aligned
;   store64 OutgoingArg(24), x15 // flags =  notrap aligned
;   store64 OutgoingArg(32), x15 // flags =  notrap aligned
;   store64 OutgoingArg(40), x15 // flags =  notrap aligned
;   x0 = xmov x15
;   x1 = xmov x15
;   x2 = xmov x15
;   x3 = xmov x15
;   x4 = xmov x15
;   x5 = xmov x15
;   x6 = xmov x15
;   x7 = xmov x15
;   x8 = xmov x15
;   x9 = xmov x15
;   x10 = xmov x15
;   x11 = xmov x15
;   x12 = xmov x15
;   x13 = xmov x15
;   x14 = xmov x15
;   call CallInfo { dest: TestCase(%g), uses: [CallArgPair { vreg: p0i, preg: p0i }, CallArgPair { vreg: p1i, preg: p1i }, CallArgPair { vreg: p2i, preg: p2i }, CallArgPair { vreg: p3i, preg: p3i }, CallArgPair { vreg: p4i, preg: p4i }, CallArgPair { vreg: p5i, preg: p5i }, CallArgPair { vreg: p6i, preg: p6i }, CallArgPair { vreg: p7i, preg: p7i }, CallArgPair { vreg: p8i, preg: p8i }, CallArgPair { vreg: p9i, preg: p9i }, CallArgPair { vreg: p10i, preg: p10i }, CallArgPair { vreg: p11i, preg: p11i }, CallArgPair { vreg: p12i, preg: p12i }, CallArgPair { vreg: p13i, preg: p13i }, CallArgPair { vreg: p14i, preg: p14i }, CallArgPair { vreg: p15i, preg: p15i }], defs: [], clobbers: PRegSet { bits: [65535, 65279, 4294967295, 0] }, callee_conv: Fast, caller_conv: Fast, callee_pop_size: 0 }
;   x30 = xconst8 48
;   x27 = xadd32 x27, x30
;   x28 = load64_u sp+8 // flags = notrap aligned
;   x29 = load64_u sp+0 // flags = notrap aligned
;   x30 = xconst8 16
;   x27 = xadd32 x27, x30
;   ret
;
; Disassembled:
; xconst8 spilltmp0, -16
; xadd32 sp, sp, spilltmp0
; store64_offset8 sp, 8, lr
; store64 sp, fp
; xmov fp, sp
; xconst8 spilltmp0, -48
; xadd32 sp, sp, spilltmp0
; xconst8 x15, 0
; store64 sp, x15
; store64_offset8 sp, 8, x15
; store64_offset8 sp, 16, x15
; store64_offset8 sp, 24, x15
; store64_offset8 sp, 32, x15
; store64_offset8 sp, 40, x15
; xmov x0, x15
; xmov x1, x15
; xmov x2, x15
; xmov x3, x15
; xmov x4, x15
; xmov x5, x15
; xmov x6, x15
; xmov x7, x15
; xmov x8, x15
; xmov x9, x15
; xmov x10, x15
; xmov x11, x15
; xmov x12, x15
; xmov x13, x15
; xmov x14, x15
; call 0x0    // target = 0x5d
; xconst8 spilltmp0, 48
; xadd32 sp, sp, spilltmp0
; load64_offset8 lr, sp, 8
; load64 fp, sp
; xconst8 spilltmp0, 16
; xadd32 sp, sp, spilltmp0
; ret

function %colocated_stack_rets() -> i64 {
    fn0 = colocated %g() -> i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64

block0:
    v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v20 = call fn0()

    v22 = iadd v0, v1
    v23 = iadd v2, v3
    v24 = iadd v4, v5
    v25 = iadd v6, v7
    v26 = iadd v8, v9
    v27 = iadd v10, v11
    v28 = iadd v12, v13
    v29 = iadd v14, v15
    v30 = iadd v16, v17
    v31 = iadd v17, v18
    v32 = iadd v19, v20

    v33 = iadd v22, v23
    v34 = iadd v24, v25
    v35 = iadd v26, v27
    v36 = iadd v28, v29
    v37 = iadd v30, v31
    v38 = iadd v32, v32

    v39 = iadd v33, v34
    v40 = iadd v35, v36
    v41 = iadd v37, v38

    v42 = iadd v39, v40
    v43 = iadd v41, v41

    v44 = iadd v42, v43
    return v44
}

; VCode:
;   x30 = xconst8 -16
;   x27 = xadd32 x27, x30
;   store64 sp+8, x28 // flags =  notrap aligned
;   store64 sp+0, x29 // flags =  notrap aligned
;   x29 = xmov x27
;   x30 = xconst8 -64
;   x27 = xadd32 x27, x30
;   store64 sp+56, x18 // flags =  notrap aligned
;   store64 sp+48, x20 // flags =  notrap aligned
; block0:
;   x0 = load_addr OutgoingArg(0)
;   call CallInfo { dest: TestCase(%g), uses: [CallArgPair { vreg: p0i, preg: p0i }], defs: [CallRetPair { vreg: Writable { reg: p0i }, preg: p0i }, CallRetPair { vreg: Writable { reg: p1i }, preg: p1i }, CallRetPair { vreg: Writable { reg: p2i }, preg: p2i }, CallRetPair { vreg: Writable { reg: p3i }, preg: p3i }, CallRetPair { vreg: Writable { reg: p4i }, preg: p4i }, CallRetPair { vreg: Writable { reg: p5i }, preg: p5i }, CallRetPair { vreg: Writable { reg: p6i }, preg: p6i }, CallRetPair { vreg: Writable { reg: p7i }, preg: p7i }, CallRetPair { vreg: Writable { reg: p8i }, preg: p8i }, CallRetPair { vreg: Writable { reg: p9i }, preg: p9i }, CallRetPair { vreg: Writable { reg: p10i }, preg: p10i }, CallRetPair { vreg: Writable { reg: p11i }, preg: p11i }, CallRetPair { vreg: Writable { reg: p12i }, preg: p12i }, CallRetPair { vreg: Writable { reg: p13i }, preg: p13i }, CallRetPair { vreg: Writable { reg: p14i }, preg: p14i }, CallRetPair { vreg: Writable { reg: p15i }, preg: p15i }], clobbers: PRegSet { bits: [0, 65279, 4294967295, 0] }, callee_conv: Fast, caller_conv: Fast, callee_pop_size: 0 }
;   x18 = xmov x13
;   x20 = xmov x11
;   x24 = load64_u OutgoingArg(0) // flags = notrap aligned
;   x11 = load64_u OutgoingArg(8) // flags = notrap aligned
;   x13 = load64_u OutgoingArg(16) // flags = notrap aligned
;   x19 = load64_u OutgoingArg(24) // flags = notrap aligned
;   x21 = load64_u OutgoingArg(32) // flags = notrap aligned
;   x25 = xadd64 x0, x1
;   x23 = xadd64 x2, x3
;   x5 = xadd64 x4, x5
;   x6 = xadd64 x6, x7
;   x7 = xadd64 x8, x9
;   x0 = xmov x20
;   x4 = xadd64 x10, x0
;   x10 = xmov x18
;   x8 = xadd64 x12, x10
;   x14 = xadd64 x14, x15
;   x15 = xadd64 x24, x11
;   x13 = xadd64 x11, x13
;   x0 = xadd64 x19, x21
;   x1 = xadd64 x25, x23
;   x2 = xadd64 x5, x6
;   x3 = xadd64 x7, x4
;   x14 = xadd64 x8, x14
;   x13 = xadd64 x15, x13
;   x15 = xadd64 x0, x0
;   x0 = xadd64 x1, x2
;   x14 = xadd64 x3, x14
;   x13 = xadd64 x13, x15
;   x14 = xadd64 x0, x14
;   x13 = xadd64 x13, x13
;   x0 = xadd64 x14, x13
;   x18 = load64_u sp+56 // flags = notrap aligned
;   x20 = load64_u sp+48 // flags = notrap aligned
;   x30 = xconst8 64
;   x27 = xadd32 x27, x30
;   x28 = load64_u sp+8 // flags = notrap aligned
;   x29 = load64_u sp+0 // flags = notrap aligned
;   x30 = xconst8 16
;   x27 = xadd32 x27, x30
;   ret
;
; Disassembled:
; xconst8 spilltmp0, -16
; xadd32 sp, sp, spilltmp0
; store64_offset8 sp, 8, lr
; store64 sp, fp
; xmov fp, sp
; xconst8 spilltmp0, -64
; xadd32 sp, sp, spilltmp0
; store64_offset8 sp, 56, x18
; store64_offset8 sp, 48, x20
; xmov x0, sp
; call 0x0    // target = 0x21
; xmov x18, x13
; xmov x20, x11
; load64 x24, sp
; load64_offset8 x11, sp, 8
; load64_offset8 x13, sp, 16
; load64_offset8 x19, sp, 24
; load64_offset8 x21, sp, 32
; xadd64 x25, x0, x1
; xadd64 x23, x2, x3
; xadd64 x5, x4, x5
; xadd64 x6, x6, x7
; xadd64 x7, x8, x9
; xmov x0, x20
; xadd64 x4, x10, x0
; xmov x10, x18
; xadd64 x8, x12, x10
; xadd64 x14, x14, x15
; xadd64 x15, x24, x11
; xadd64 x13, x11, x13
; xadd64 x0, x19, x21
; xadd64 x1, x25, x23
; xadd64 x2, x5, x6
; xadd64 x3, x7, x4
; xadd64 x14, x8, x14
; xadd64 x13, x15, x13
; xadd64 x15, x0, x0
; xadd64 x0, x1, x2
; xadd64 x14, x3, x14
; xadd64 x13, x13, x15
; xadd64 x14, x0, x14
; xadd64 x13, x13, x13
; xadd64 x0, x14, x13
; load64_offset8 x18, sp, 56
; load64_offset8 x20, sp, 48
; xconst8 spilltmp0, 64
; xadd32 sp, sp, spilltmp0
; load64_offset8 lr, sp, 8
; load64 fp, sp
; xconst8 spilltmp0, 16
; xadd32 sp, sp, spilltmp0
; ret

function %call_indirect(i64) -> i64 {
    sig0 = () -> i64 tail

block0(v0: i64):
    v1 = call_indirect sig0, v0()
    return v1
}

; VCode:
;   x30 = xconst8 -16
;   x27 = xadd32 x27, x30
;   store64 sp+8, x28 // flags =  notrap aligned
;   store64 sp+0, x29 // flags =  notrap aligned
;   x29 = xmov x27
; block0:
;   indirect_call x0, CallInfo { dest: XReg(p0i), uses: [], defs: [CallRetPair { vreg: Writable { reg: p0i }, preg: p0i }], clobbers: PRegSet { bits: [65534, 65279, 4294967295, 0] }, callee_conv: Tail, caller_conv: Fast, callee_pop_size: 0 }
;   x28 = load64_u sp+8 // flags = notrap aligned
;   x29 = load64_u sp+0 // flags = notrap aligned
;   x30 = xconst8 16
;   x27 = xadd32 x27, x30
;   ret
;
; Disassembled:
; xconst8 spilltmp0, -16
; xadd32 sp, sp, spilltmp0
; store64_offset8 sp, 8, lr
; store64 sp, fp
; xmov fp, sp
; call_indirect x0
; load64_offset8 lr, sp, 8
; load64 fp, sp
; xconst8 spilltmp0, 16
; xadd32 sp, sp, spilltmp0
; ret

