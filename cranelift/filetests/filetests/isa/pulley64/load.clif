test compile precise-output
target pulley64

function %load_i8(i64) -> i8 {
block0(v0: i64):
    v1 = load.i8 v0
    return v1
}

; VCode:
; block0:
;   xload8_u32_z x0, x0, 0
;   ret
;
; Disassembled:
; xload8_u32_z x0, x0, 0
; ret

function %load_i8_s32(i64) -> i32 {
block0(v0: i64):
    v1 = sload8.i32 v0
    return v1
}

; VCode:
; block0:
;   xload8_s32_z x0, x0, 0
;   ret
;
; Disassembled:
; xload8_s32_z x0, x0, 0
; ret

function %load_i8_u32(i64) -> i32 {
block0(v0: i64):
    v1 = uload8.i32 v0
    return v1
}

; VCode:
; block0:
;   xload8_u32_z x0, x0, 0
;   ret
;
; Disassembled:
; xload8_u32_z x0, x0, 0
; ret

function %load_i16(i64) -> i16 {
block0(v0: i64):
    v1 = load.i16 v0
    return v1
}

; VCode:
; block0:
;   xload16le_u32_z x0, x0, 0
;   ret
;
; Disassembled:
; xload16le_u32_z x0, x0, 0
; ret

function %load_i16_s32(i64) -> i32 {
block0(v0: i64):
    v1 = sload16.i32 v0
    return v1
}

; VCode:
; block0:
;   xload16le_s32_z x0, x0, 0
;   ret
;
; Disassembled:
; xload16le_s32_z x0, x0, 0
; ret

function %load_i16_u32(i64) -> i32 {
block0(v0: i64):
    v1 = uload16.i32 v0
    return v1
}

; VCode:
; block0:
;   xload16le_u32_z x0, x0, 0
;   ret
;
; Disassembled:
; xload16le_u32_z x0, x0, 0
; ret

function %load_i32(i64) -> i32 {
block0(v0: i64):
    v1 = load.i32 v0
    return v1
}

; VCode:
; block0:
;   xload32le_z x0, x0, 0
;   ret
;
; Disassembled:
; xload32le_z x0, x0, 0
; ret

function %load_i32_s64(i64) -> i64 {
block0(v0: i64):
    v1 = sload32.i64 v0
    return v1
}

; VCode:
; block0:
;   xload32le_z x2, x0, 0
;   sext32 x0, x2
;   ret
;
; Disassembled:
; xload32le_z x2, x0, 0
; sext32 x0, x2
; ret

function %load_i32_u64(i64) -> i64 {
block0(v0: i64):
    v1 = uload32.i64 v0
    return v1
}

; VCode:
; block0:
;   xload32le_z x2, x0, 0
;   zext32 x0, x2
;   ret
;
; Disassembled:
; xload32le_z x2, x0, 0
; zext32 x0, x2
; ret

function %load_i64(i64) -> i64 {
block0(v0: i64):
    v1 = load.i64 v0
    return v1
}

; VCode:
; block0:
;   xload64le_z x0, x0, 0
;   ret
;
; Disassembled:
; xload64le_z x0, x0, 0
; ret

function %load_i8_offset(i64) -> i8 {
block0(v0: i64):
    v1 = load.i8 v0+4
    return v1
}

; VCode:
; block0:
;   xload8_u32_z x0, x0, 4
;   ret
;
; Disassembled:
; xload8_u32_z x0, x0, 4
; ret

function %load_i8_s32_offset(i64) -> i32 {
block0(v0: i64):
    v1 = sload8.i32 v0+4
    return v1
}

; VCode:
; block0:
;   xload8_s32_z x0, x0, 4
;   ret
;
; Disassembled:
; xload8_s32_z x0, x0, 4
; ret

function %load_i8_u32_offset(i64) -> i32 {
block0(v0: i64):
    v1 = uload8.i32 v0+4
    return v1
}

; VCode:
; block0:
;   xload8_u32_z x0, x0, 4
;   ret
;
; Disassembled:
; xload8_u32_z x0, x0, 4
; ret

function %load_i16_offset(i64) -> i16 {
block0(v0: i64):
    v1 = load.i16 v0+4
    return v1
}

; VCode:
; block0:
;   xload16le_u32_z x0, x0, 4
;   ret
;
; Disassembled:
; xload16le_u32_z x0, x0, 4
; ret

function %load_i16_s32_offset(i64) -> i32 {
block0(v0: i64):
    v1 = sload16.i32 v0+4
    return v1
}

; VCode:
; block0:
;   xload16le_s32_z x0, x0, 4
;   ret
;
; Disassembled:
; xload16le_s32_z x0, x0, 4
; ret

function %load_i16_u32_offset(i64) -> i32 {
block0(v0: i64):
    v1 = uload16.i32 v0+4
    return v1
}

; VCode:
; block0:
;   xload16le_u32_z x0, x0, 4
;   ret
;
; Disassembled:
; xload16le_u32_z x0, x0, 4
; ret

function %load_i32_offset(i64) -> i32 {
block0(v0: i64):
    v1 = load.i32 v0+4
    return v1
}

; VCode:
; block0:
;   xload32le_z x0, x0, 4
;   ret
;
; Disassembled:
; xload32le_z x0, x0, 4
; ret

function %load_i32_s64_offset(i64) -> i64 {
block0(v0: i64):
    v1 = sload32.i64 v0+4
    return v1
}

; VCode:
; block0:
;   xload32le_z x2, x0, 4
;   sext32 x0, x2
;   ret
;
; Disassembled:
; xload32le_z x2, x0, 4
; sext32 x0, x2
; ret

function %load_i32_u64_offset(i64) -> i64 {
block0(v0: i64):
    v1 = uload32.i64 v0+4
    return v1
}

; VCode:
; block0:
;   xload32le_z x2, x0, 4
;   zext32 x0, x2
;   ret
;
; Disassembled:
; xload32le_z x2, x0, 4
; zext32 x0, x2
; ret

function %load_i64_offset(i64) -> i64 {
block0(v0: i64):
    v1 = load.i64 v0+65536
    return v1
}

; VCode:
; block0:
;   xload64le_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload64le_z x0, x0, 65536
; ret

function %load_i8_big_offset(i64) -> i8 {
block0(v0: i64):
    v1 = load.i8 v0+65536
    return v1
}

; VCode:
; block0:
;   xload8_u32_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload8_u32_z x0, x0, 65536
; ret

function %load_i8_s32_big_offset(i64) -> i32 {
block0(v0: i64):
    v1 = sload8.i32 v0+65536
    return v1
}

; VCode:
; block0:
;   xload8_s32_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload8_s32_z x0, x0, 65536
; ret

function %load_i8_u32_big_offset(i64) -> i32 {
block0(v0: i64):
    v1 = uload8.i32 v0+65536
    return v1
}

; VCode:
; block0:
;   xload8_u32_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload8_u32_z x0, x0, 65536
; ret

function %load_i16_big_offset(i64) -> i16 {
block0(v0: i64):
    v1 = load.i16 v0+65536
    return v1
}

; VCode:
; block0:
;   xload16le_u32_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload16le_u32_z x0, x0, 65536
; ret

function %load_i16_s32_big_offset(i64) -> i32 {
block0(v0: i64):
    v1 = sload16.i32 v0+65536
    return v1
}

; VCode:
; block0:
;   xload16le_s32_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload16le_s32_z x0, x0, 65536
; ret

function %load_i16_u32_big_offset(i64) -> i32 {
block0(v0: i64):
    v1 = uload16.i32 v0+65536
    return v1
}

; VCode:
; block0:
;   xload16le_u32_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload16le_u32_z x0, x0, 65536
; ret

function %load_i32_big_offset(i64) -> i32 {
block0(v0: i64):
    v1 = load.i32 v0+65536
    return v1
}

; VCode:
; block0:
;   xload32le_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload32le_z x0, x0, 65536
; ret

function %load_i32_s64_big_offset(i64) -> i64 {
block0(v0: i64):
    v1 = sload32.i64 v0+65536
    return v1
}

; VCode:
; block0:
;   xload32le_z x2, x0, 65536
;   sext32 x0, x2
;   ret
;
; Disassembled:
; xload32le_z x2, x0, 65536
; sext32 x0, x2
; ret

function %load_i32_u64_big_offset(i64) -> i64 {
block0(v0: i64):
    v1 = uload32.i64 v0+65536
    return v1
}

; VCode:
; block0:
;   xload32le_z x2, x0, 65536
;   zext32 x0, x2
;   ret
;
; Disassembled:
; xload32le_z x2, x0, 65536
; zext32 x0, x2
; ret

function %load_i64_big_offset(i64) -> i64 {
block0(v0: i64):
    v1 = load.i64 v0+65536
    return v1
}

; VCode:
; block0:
;   xload64le_z x0, x0, 65536
;   ret
;
; Disassembled:
; xload64le_z x0, x0, 65536
; ret

function %load_i64_with_add_and_offset(i64) -> i64 {
block0(v0: i64):
    v1 = iadd_imm v0, 10
    v2 = load.i64 v1+8
    return v2
}

; VCode:
; block0:
;   xload64le_z x0, x0, 18
;   ret
;
; Disassembled:
; xload64le_z x0, x0, 18
; ret

