test optimize precise-output
set opt_level=speed
target x86_64

function %urem32_pow2(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i32 8
    v2 = urem v0, v1
    return v2
}

; function %urem32_pow2(i32) -> i32 fast {
; block0(v0: i32):
;     v3 = iconst.i32 7
;     v4 = band v0, v3  ; v3 = 7
;     v2 -> v4
;     return v4
; }

function %urem32_by_const(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i32 1337
    v2 = urem v0, v1
    return v2
}

; function %urem32_by_const(i32) -> i32 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -2010957013
;     v4 = umulhi v0, v3  ; v3 = -2010957013
;     v5 = isub v0, v4
;     v6 = iconst.i32 1
;     v7 = ushr v5, v6  ; v6 = 1
;     v8 = iadd v4, v7
;     v9 = iconst.i32 10
;     v10 = ushr v8, v9  ; v9 = 10
;     v1 = iconst.i32 1337
;     v11 = imul v10, v1  ; v1 = 1337
;     v12 = isub v0, v11
;     v2 -> v12
;     return v12
; }

function %urem64_pow2(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 16
    v2 = urem v0, v1
    return v2
}

; function %urem64_pow2(i64) -> i64 fast {
; block0(v0: i64):
;     v3 = iconst.i64 15
;     v4 = band v0, v3  ; v3 = 15
;     v2 -> v4
;     return v4
; }

function %urem64_by_const(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 12345
    v2 = urem v0, v1
    return v2
}

; function %urem64_by_const(i64) -> i64 fast {
; block0(v0: i64):
;     v3 = iconst.i64 0x54f0_77c7_18e7_c21f
;     v4 = umulhi v0, v3  ; v3 = 0x54f0_77c7_18e7_c21f
;     v5 = iconst.i64 12
;     v6 = ushr v4, v5  ; v5 = 12
;     v1 = iconst.i64 0x3039
;     v7 = imul v6, v1  ; v1 = 0x3039
;     v8 = isub v0, v7
;     v2 -> v8
;     return v8
; }

