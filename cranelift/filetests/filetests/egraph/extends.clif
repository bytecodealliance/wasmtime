test optimize
set opt_level=speed
target x86_64

function %f1() -> i64 {
block0:
  v0 = iconst.i32 0x9876_5432
  v1 = uextend.i64 v0
  return v1
  ; check: v2 = iconst.i64 0x9876_5432
  ; check: return v2  ; v2 = 0x9876_5432
}


function %extend_always_above_zero(i32) -> i8 {
block0(v1: i32):
    v2 = uextend.i64 v1
    v3 = iconst.i64 0
    v4 = icmp slt v2, v3
    return v4
}

; check: v5 = iconst.i8 0
; check: return v5

function %extend_always_above_zero2(i32) -> i8 {
block0(v1: i32):
    v2 = uextend.i64 v1
    v3 = iconst.i64 0
    v4 = icmp sge v2, v3
    return v4
}

; check: v5 = iconst.i8 1
; check: return v5

function %double_uextend(i16) -> i64 {
block0(v1: i16):
    v2 = uextend.i32 v1
    v3 = uextend.i64 v2
    return v3
}

; check: v4 = uextend.i64 v1
; check: return v4

function %double_sextend(i16) -> i64 {
block0(v1: i16):
    v2 = sextend.i32 v1
    v3 = sextend.i64 v2
    return v3
}

; check: v4 = sextend.i64 v1
; check: return v4

function %suextend_icmp(i16, i16) -> i64 {
block0(v0: i16, v1: i16):
    v2 = icmp slt v0, v1
    v3 = uextend.i32 v2
    v4 = sextend.i64 v3
    return v4
}

; check: v5 = uextend.i64 v2
; check: return v5

function %usextend_icmp(i16, i16) -> i64 {
block0(v0: i16, v1: i16):
    v2 = icmp uge v0, v1
    v3 = sextend.i32 v2
    v4 = uextend.i64 v3
    return v4
}

; check: v7 = uextend.i64 v2
; check: return v7

function %sextend_then_reduce(i16) -> i16 {
block0(v1: i16):
    v2 = sextend.i32 v1
    v3 = ireduce.i16 v2
    return v3
}

; check: return v1

function %uextend_then_reduce(i32) -> i32 {
block0(v1: i32):
    v2 = uextend.i64 v1
    v3 = ireduce.i32 v2
    return v3
}

; check: return v1

function %sextend_then_reduce_smaller(i32) -> i16 {
block0(v1: i32):
    v2 = sextend.i64 v1
    v3 = ireduce.i16 v2
    return v3
}

; check: v4 = ireduce.i16 v1
; check: return v4

function %uextend_then_reduce_smaller(i32) -> i16 {
block0(v1: i32):
    v2 = uextend.i64 v1
    v3 = ireduce.i16 v2
    return v3
}

; check: v4 = ireduce.i16 v1
; check: return v4

function %sextend_then_reduce_partially(i16) -> i32 {
block0(v1: i16):
    v2 = sextend.i64 v1
    v3 = ireduce.i32 v2
    return v3
}

; check: v4 = sextend.i32 v1
; check: return v4

function %uextend_then_reduce_partially(i16) -> i32 {
block0(v1: i16):
    v2 = uextend.i64 v1
    v3 = ireduce.i32 v2
    return v3
}

; check: v4 = uextend.i32 v1
; check: return v4

function %sextend_then_slt_zero(i8) -> i8 {
block0(v0: i8):
    v1 = sextend.i16 v0
    v2 = iconst.i16 0
    v3 = icmp slt v1, v2
    return v3
}

; check: v4 = iconst.i8 0
; check: v5 = icmp slt v0, v4
; check: return v5

function %sextend_then_ne_zero(i8) -> i8 {
block0(v0: i8):
    v1 = sextend.i16 v0
    v2 = iconst.i16 0
    v3 = icmp ne v1, v2
    return v3
}

; check: v4 = iconst.i8 0
; check: v5 = icmp ne v0, v4
; check: return v5

function %extend_imul_reduce(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = imul v2, v3
    v5 = ireduce.i64 v4
    return v5
}

; check: v8 = imul v0, v1
; check: return v8

function %extend_iadd_reduce(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
    v2 = sextend.i32 v0
    v3 = sextend.i32 v1
    v4 = iadd v2, v3
    v5 = ireduce.i16 v4
    return v5
}

; check: v8 = iadd v0, v1
; check: return v8

function %extend_bxor_reduce(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = uextend.i128 v0
    v3 = uextend.i128 v1
    v4 = bxor v2, v3
    v5 = ireduce.i64 v4
    return v5
}

; check: v6 = bxor v0, v1
; check: return v6

function %extend_band_reduce(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
    v2 = sextend.i32 v0
    v3 = sextend.i32 v1
    v4 = band v2, v3
    v5 = ireduce.i16 v4
    return v5
}

; check: v8 = band v0, v1
; check: return v8

function %extend_ineg_reduce(i64) -> i64 {
block0(v0: i64):
    v1 = sextend.i128 v0
    v2 = ineg v1
    v3 = ireduce.i64 v2
    return v3
}

; check: v5 = ineg v0
; check: return v5

function %extend_bnot_reduce(i16) -> i16 {
block0(v0: i16):
    v1 = uextend.i32 v0
    v2 = bnot v1
    v3 = ireduce.i16 v2
    return v3
}

; check: v5 = bnot v0
; check: return v5

function %concat_zero(i64) -> i128 {
block0(v0: i64):
    v1 = iconst.i64 0
    v2 = iconcat v0, v1
    return v2
}

; check: v3 = uextend.i128 v0
; check: return v3

function %sext128(i64) -> i128 {
block0(v0: i64):
    v1 = sshr_imm v0, 63
    v2 = iconcat v0, v1
    return v2
}

; check: v4 = sextend.i128 v0
; check: return v4
