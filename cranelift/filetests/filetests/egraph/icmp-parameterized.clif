test optimize precise-output
set opt_level=speed
target x86_64

;; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
;; !!! GENERATED BY 'make-icmp-parameterized-tests.sh' DO NOT EDIT !!!
;; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
;; run with the 'CRANELIFT_TEST_BLESS=1' env var set to update this file

function %icmp_eq_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp eq v0, v0
    return v1
}

; function %icmp_eq_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 1
;     return v2  ; v2 = 1
; }

function %icmp_ne_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp ne v0, v0
    return v1
}

; function %icmp_ne_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 0
;     return v2  ; v2 = 0
; }

function %icmp_ult_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp ult v0, v0
    return v1
}

; function %icmp_ult_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 0
;     return v2  ; v2 = 0
; }

function %icmp_ule_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp ule v0, v0
    return v1
}

; function %icmp_ule_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 1
;     return v2  ; v2 = 1
; }

function %icmp_ugt_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp ugt v0, v0
    return v1
}

; function %icmp_ugt_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 0
;     return v2  ; v2 = 0
; }

function %icmp_uge_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp uge v0, v0
    return v1
}

; function %icmp_uge_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 1
;     return v2  ; v2 = 1
; }

function %icmp_slt_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp slt v0, v0
    return v1
}

; function %icmp_slt_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 0
;     return v2  ; v2 = 0
; }

function %icmp_sle_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp sle v0, v0
    return v1
}

; function %icmp_sle_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 1
;     return v2  ; v2 = 1
; }

function %icmp_sgt_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp sgt v0, v0
    return v1
}

; function %icmp_sgt_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 0
;     return v2  ; v2 = 0
; }

function %icmp_sge_self(i32) -> i8 {
block0(v0: i32):
    v1 = icmp sge v0, v0
    return v1
}

; function %icmp_sge_self(i32) -> i8 fast {
; block0(v0: i32):
;     v2 = iconst.i8 1
;     return v2  ; v2 = 1
; }

function %icmp_eq_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp eq v0, v1
    return v2
}

; function %icmp_eq_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0
;     v2 = icmp eq v0, v1  ; v1 = 0
;     return v2
; }

function %icmp_eq_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp eq v0, v1
    return v2
}

; function %icmp_eq_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 1
;     v2 = icmp eq v0, v1  ; v1 = 1
;     return v2
; }

function %icmp_eq_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp eq v0, v1
    return v2
}

; function %icmp_eq_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -1
;     v2 = icmp eq v0, v1  ; v1 = -1
;     return v2
; }

function %icmp_eq_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp eq v0, v1
    return v2
}

; function %icmp_eq_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2
;     v2 = icmp eq v0, v1  ; v1 = -2
;     return v2
; }

function %icmp_eq_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp eq v0, v1
    return v2
}

; function %icmp_eq_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483648
;     v2 = icmp eq v0, v1  ; v1 = -2147483648
;     return v2
; }

function %icmp_eq_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp eq v0, v1
    return v2
}

; function %icmp_eq_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483647
;     v2 = icmp eq v0, v1  ; v1 = -2147483647
;     return v2
; }

function %icmp_eq_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp eq v0, v1
    return v2
}

; function %icmp_eq_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_ffff
;     v2 = icmp eq v0, v1  ; v1 = 0x7fff_ffff
;     return v2
; }

function %icmp_eq_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp eq v0, v1
    return v2
}

; function %icmp_eq_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_fffe
;     v2 = icmp eq v0, v1  ; v1 = 0x7fff_fffe
;     return v2
; }

function %icmp_ne_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp ne v0, v1
    return v2
}

; function %icmp_ne_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0
;     v2 = icmp ne v0, v1  ; v1 = 0
;     return v2
; }

function %icmp_ne_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp ne v0, v1
    return v2
}

; function %icmp_ne_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 1
;     v2 = icmp ne v0, v1  ; v1 = 1
;     return v2
; }

function %icmp_ne_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp ne v0, v1
    return v2
}

; function %icmp_ne_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -1
;     v2 = icmp ne v0, v1  ; v1 = -1
;     return v2
; }

function %icmp_ne_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp ne v0, v1
    return v2
}

; function %icmp_ne_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2
;     v2 = icmp ne v0, v1  ; v1 = -2
;     return v2
; }

function %icmp_ne_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp ne v0, v1
    return v2
}

; function %icmp_ne_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483648
;     v2 = icmp ne v0, v1  ; v1 = -2147483648
;     return v2
; }

function %icmp_ne_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp ne v0, v1
    return v2
}

; function %icmp_ne_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483647
;     v2 = icmp ne v0, v1  ; v1 = -2147483647
;     return v2
; }

function %icmp_ne_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp ne v0, v1
    return v2
}

; function %icmp_ne_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_ffff
;     v2 = icmp ne v0, v1  ; v1 = 0x7fff_ffff
;     return v2
; }

function %icmp_ne_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp ne v0, v1
    return v2
}

; function %icmp_ne_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_fffe
;     v2 = icmp ne v0, v1  ; v1 = 0x7fff_fffe
;     return v2
; }

function %icmp_ult_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp ult v0, v1
    return v2
}

; function %icmp_ult_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i8 0
;     return v3  ; v3 = 0
; }

function %icmp_ult_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp ult v0, v1
    return v2
}

; function %icmp_ult_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0
;     v4 = icmp eq v0, v3  ; v3 = 0
;     return v4
; }

function %icmp_ult_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp ult v0, v1
    return v2
}

; function %icmp_ult_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -1
;     v3 = icmp ne v0, v1  ; v1 = -1
;     return v3
; }

function %icmp_ult_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp ult v0, v1
    return v2
}

; function %icmp_ult_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2
;     v2 = icmp ult v0, v1  ; v1 = -2
;     return v2
; }

function %icmp_ult_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp ult v0, v1
    return v2
}

; function %icmp_ult_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483648
;     v2 = icmp ult v0, v1  ; v1 = -2147483648
;     return v2
; }

function %icmp_ult_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp ult v0, v1
    return v2
}

; function %icmp_ult_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483647
;     v2 = icmp ult v0, v1  ; v1 = -2147483647
;     return v2
; }

function %icmp_ult_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp ult v0, v1
    return v2
}

; function %icmp_ult_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_ffff
;     v2 = icmp ult v0, v1  ; v1 = 0x7fff_ffff
;     return v2
; }

function %icmp_ult_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp ult v0, v1
    return v2
}

; function %icmp_ult_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_fffe
;     v2 = icmp ult v0, v1  ; v1 = 0x7fff_fffe
;     return v2
; }

function %icmp_ule_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp ule v0, v1
    return v2
}

; function %icmp_ule_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0
;     v5 = icmp eq v0, v1  ; v1 = 0
;     return v5
; }

function %icmp_ule_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp ule v0, v1
    return v2
}

; function %icmp_ule_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 2
;     v4 = icmp ult v0, v3  ; v3 = 2
;     return v4
; }

function %icmp_ule_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp ule v0, v1
    return v2
}

; function %icmp_ule_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i8 1
;     return v3  ; v3 = 1
; }

function %icmp_ule_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp ule v0, v1
    return v2
}

; function %icmp_ule_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -1
;     v5 = icmp ne v0, v3  ; v3 = -1
;     return v5
; }

function %icmp_ule_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp ule v0, v1
    return v2
}

; function %icmp_ule_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -2147483647
;     v4 = icmp ult v0, v3  ; v3 = -2147483647
;     return v4
; }

function %icmp_ule_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp ule v0, v1
    return v2
}

; function %icmp_ule_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -2147483646
;     v4 = icmp ult v0, v3  ; v3 = -2147483646
;     return v4
; }

function %icmp_ule_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp ule v0, v1
    return v2
}

; function %icmp_ule_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -2147483648
;     v4 = icmp ult v0, v3  ; v3 = -2147483648
;     return v4
; }

function %icmp_ule_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp ule v0, v1
    return v2
}

; function %icmp_ule_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0x7fff_ffff
;     v4 = icmp ult v0, v3  ; v3 = 0x7fff_ffff
;     return v4
; }

function %icmp_ugt_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp ugt v0, v1
    return v2
}

; function %icmp_ugt_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0
;     v3 = icmp ne v0, v1  ; v1 = 0
;     return v3
; }

function %icmp_ugt_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp ugt v0, v1
    return v2
}

; function %icmp_ugt_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 1
;     v2 = icmp ugt v0, v1  ; v1 = 1
;     return v2
; }

function %icmp_ugt_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp ugt v0, v1
    return v2
}

; function %icmp_ugt_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i8 0
;     return v3  ; v3 = 0
; }

function %icmp_ugt_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp ugt v0, v1
    return v2
}

; function %icmp_ugt_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -1
;     v4 = icmp eq v0, v3  ; v3 = -1
;     return v4
; }

function %icmp_ugt_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp ugt v0, v1
    return v2
}

; function %icmp_ugt_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483648
;     v2 = icmp ugt v0, v1  ; v1 = -2147483648
;     return v2
; }

function %icmp_ugt_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp ugt v0, v1
    return v2
}

; function %icmp_ugt_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483647
;     v2 = icmp ugt v0, v1  ; v1 = -2147483647
;     return v2
; }

function %icmp_ugt_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp ugt v0, v1
    return v2
}

; function %icmp_ugt_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_ffff
;     v2 = icmp ugt v0, v1  ; v1 = 0x7fff_ffff
;     return v2
; }

function %icmp_ugt_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp ugt v0, v1
    return v2
}

; function %icmp_ugt_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_fffe
;     v2 = icmp ugt v0, v1  ; v1 = 0x7fff_fffe
;     return v2
; }

function %icmp_uge_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp uge v0, v1
    return v2
}

; function %icmp_uge_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i8 1
;     return v3  ; v3 = 1
; }

function %icmp_uge_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp uge v0, v1
    return v2
}

; function %icmp_uge_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0
;     v5 = icmp ne v0, v3  ; v3 = 0
;     return v5
; }

function %icmp_uge_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp uge v0, v1
    return v2
}

; function %icmp_uge_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v4 = iconst.i32 -2
;     v5 = icmp ugt v0, v4  ; v4 = -2
;     return v5
; }

function %icmp_uge_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp uge v0, v1
    return v2
}

; function %icmp_uge_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -3
;     v4 = icmp ugt v0, v3  ; v3 = -3
;     return v4
; }

function %icmp_uge_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp uge v0, v1
    return v2
}

; function %icmp_uge_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0x7fff_ffff
;     v4 = icmp ugt v0, v3  ; v3 = 0x7fff_ffff
;     return v4
; }

function %icmp_uge_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp uge v0, v1
    return v2
}

; function %icmp_uge_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -2147483648
;     v4 = icmp ugt v0, v3  ; v3 = -2147483648
;     return v4
; }

function %icmp_uge_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp uge v0, v1
    return v2
}

; function %icmp_uge_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0x7fff_fffe
;     v4 = icmp ugt v0, v3  ; v3 = 0x7fff_fffe
;     return v4
; }

function %icmp_uge_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp uge v0, v1
    return v2
}

; function %icmp_uge_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0x7fff_fffd
;     v4 = icmp ugt v0, v3  ; v3 = 0x7fff_fffd
;     return v4
; }

function %icmp_slt_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp slt v0, v1
    return v2
}

; function %icmp_slt_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0
;     v2 = icmp slt v0, v1  ; v1 = 0
;     return v2
; }

function %icmp_slt_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp slt v0, v1
    return v2
}

; function %icmp_slt_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 1
;     v9 = icmp slt v0, v1  ; v1 = 1
;     return v9
; }

function %icmp_slt_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp slt v0, v1
    return v2
}

; function %icmp_slt_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -1
;     v2 = icmp slt v0, v1  ; v1 = -1
;     return v2
; }

function %icmp_slt_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp slt v0, v1
    return v2
}

; function %icmp_slt_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2
;     v2 = icmp slt v0, v1  ; v1 = -2
;     return v2
; }

function %icmp_slt_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp slt v0, v1
    return v2
}

; function %icmp_slt_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i8 0
;     return v3  ; v3 = 0
; }

function %icmp_slt_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp slt v0, v1
    return v2
}

; function %icmp_slt_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -2147483648
;     v4 = icmp eq v0, v3  ; v3 = -2147483648
;     return v4
; }

function %icmp_slt_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp slt v0, v1
    return v2
}

; function %icmp_slt_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_ffff
;     v3 = icmp ne v0, v1  ; v1 = 0x7fff_ffff
;     return v3
; }

function %icmp_slt_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp slt v0, v1
    return v2
}

; function %icmp_slt_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_fffe
;     v2 = icmp slt v0, v1  ; v1 = 0x7fff_fffe
;     return v2
; }

function %icmp_sle_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp sle v0, v1
    return v2
}

; function %icmp_sle_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0
;     v9 = icmp sle v0, v1  ; v1 = 0
;     return v9
; }

function %icmp_sle_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp sle v0, v1
    return v2
}

; function %icmp_sle_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 2
;     v4 = icmp slt v0, v3  ; v3 = 2
;     return v4
; }

function %icmp_sle_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp sle v0, v1
    return v2
}

; function %icmp_sle_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v5 = iconst.i32 0
;     v6 = icmp slt v0, v5  ; v5 = 0
;     return v6
; }

function %icmp_sle_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp sle v0, v1
    return v2
}

; function %icmp_sle_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -1
;     v4 = icmp slt v0, v3  ; v3 = -1
;     return v4
; }

function %icmp_sle_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp sle v0, v1
    return v2
}

; function %icmp_sle_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483648
;     v5 = icmp eq v0, v1  ; v1 = -2147483648
;     return v5
; }

function %icmp_sle_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp sle v0, v1
    return v2
}

; function %icmp_sle_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 -2147483646
;     v4 = icmp slt v0, v3  ; v3 = -2147483646
;     return v4
; }

function %icmp_sle_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp sle v0, v1
    return v2
}

; function %icmp_sle_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i8 1
;     return v3  ; v3 = 1
; }

function %icmp_sle_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp sle v0, v1
    return v2
}

; function %icmp_sle_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0x7fff_ffff
;     v5 = icmp ne v0, v3  ; v3 = 0x7fff_ffff
;     return v5
; }

function %icmp_sgt_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp sgt v0, v1
    return v2
}

; function %icmp_sgt_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0
;     v2 = icmp sgt v0, v1  ; v1 = 0
;     return v2
; }

function %icmp_sgt_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp sgt v0, v1
    return v2
}

; function %icmp_sgt_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 1
;     v2 = icmp sgt v0, v1  ; v1 = 1
;     return v2
; }

function %icmp_sgt_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp sgt v0, v1
    return v2
}

; function %icmp_sgt_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0
;     v4 = icmp sge v0, v3  ; v3 = 0
;     return v4
; }

function %icmp_sgt_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp sgt v0, v1
    return v2
}

; function %icmp_sgt_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2
;     v2 = icmp sgt v0, v1  ; v1 = -2
;     return v2
; }

function %icmp_sgt_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp sgt v0, v1
    return v2
}

; function %icmp_sgt_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483648
;     v3 = icmp ne v0, v1  ; v1 = -2147483648
;     return v3
; }

function %icmp_sgt_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp sgt v0, v1
    return v2
}

; function %icmp_sgt_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483647
;     v2 = icmp sgt v0, v1  ; v1 = -2147483647
;     return v2
; }

function %icmp_sgt_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp sgt v0, v1
    return v2
}

; function %icmp_sgt_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i8 0
;     return v3  ; v3 = 0
; }

function %icmp_sgt_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp sgt v0, v1
    return v2
}

; function %icmp_sgt_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0x7fff_ffff
;     v4 = icmp eq v0, v3  ; v3 = 0x7fff_ffff
;     return v4
; }

function %icmp_sge_umin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0
    v2 = icmp sge v0, v1
    return v2
}

; function %icmp_sge_umin(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0
;     v2 = icmp sge v0, v1  ; v1 = 0
;     return v2
; }

function %icmp_sge_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 1
    v2 = icmp sge v0, v1
    return v2
}

; function %icmp_sge_1(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i32 0
;     v4 = icmp sgt v0, v3  ; v3 = 0
;     return v4
; }

function %icmp_sge_umax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFF
    v2 = icmp sge v0, v1
    return v2
}

; function %icmp_sge_umax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -1
;     v2 = icmp sge v0, v1  ; v1 = -1
;     return v2
; }

function %icmp_sge_umax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0xFFFF_FFFE
    v2 = icmp sge v0, v1
    return v2
}

; function %icmp_sge_umax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2
;     v2 = icmp sge v0, v1  ; v1 = -2
;     return v2
; }

function %icmp_sge_smin(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0000
    v2 = icmp sge v0, v1
    return v2
}

; function %icmp_sge_smin(i32) -> i8 fast {
; block0(v0: i32):
;     v3 = iconst.i8 1
;     return v3  ; v3 = 1
; }

function %icmp_sge_smin_plus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x8000_0001
    v2 = icmp sge v0, v1
    return v2
}

; function %icmp_sge_smin_plus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 -2147483647
;     v2 = icmp sge v0, v1  ; v1 = -2147483647
;     return v2
; }

function %icmp_sge_smax(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFF
    v2 = icmp sge v0, v1
    return v2
}

; function %icmp_sge_smax(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_ffff
;     v3 = icmp eq v0, v1  ; v1 = 0x7fff_ffff
;     return v3
; }

function %icmp_sge_smax_minus_1(i32) -> i8 {
block0(v0: i32):
    v1 = iconst.i32 0x7FFF_FFFE
    v2 = icmp sge v0, v1
    return v2
}

; function %icmp_sge_smax_minus_1(i32) -> i8 fast {
; block0(v0: i32):
;     v1 = iconst.i32 0x7fff_fffe
;     v2 = icmp sge v0, v1  ; v1 = 0x7fff_fffe
;     return v2
; }

function %icmp_and_eq_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp eq v0, v1
;     return v2
; }

function %icmp_and_eq_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_eq_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_eq_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_eq_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_eq_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_eq_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_eq_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_eq_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_eq_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_eq_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_ne_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_ne_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ne v0, v1
;     return v2
; }

function %icmp_and_ne_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ult v0, v1
;     return v5
; }

function %icmp_and_ne_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ult v0, v1
;     return v5
; }

function %icmp_and_ne_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ugt v0, v1
;     return v5
; }

function %icmp_and_ne_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ugt v0, v1
;     return v5
; }

function %icmp_and_ne_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp slt v0, v1
;     return v5
; }

function %icmp_and_ne_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp slt v0, v1
;     return v5
; }

function %icmp_and_ne_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sgt v0, v1
;     return v5
; }

function %icmp_and_ne_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ne_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sgt v0, v1
;     return v5
; }

function %icmp_and_ult_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_ult_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ult v0, v1
;     return v5
; }

function %icmp_and_ult_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     return v2
; }

function %icmp_and_ult_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ult v0, v1
;     return v5
; }

function %icmp_and_ult_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_ult_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_ult_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     v3 = icmp slt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ult_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     v3 = icmp sle v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ult_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     v3 = icmp sgt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ult_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ult_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     v3 = icmp sge v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ule_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_ule_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ult v0, v1
;     return v5
; }

function %icmp_and_ule_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ult v0, v1
;     return v5
; }

function %icmp_and_ule_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     return v2
; }

function %icmp_and_ule_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_ule_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_ule_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     v3 = icmp slt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ule_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     v3 = icmp sle v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ule_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     v3 = icmp sgt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ule_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ule_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     v3 = icmp sge v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ugt_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_ugt_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ugt v0, v1
;     return v5
; }

function %icmp_and_ugt_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_ugt_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_ugt_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     return v2
; }

function %icmp_and_ugt_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ugt v0, v1
;     return v5
; }

function %icmp_and_ugt_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     v3 = icmp slt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ugt_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     v3 = icmp sle v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ugt_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     v3 = icmp sgt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_ugt_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_ugt_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     v3 = icmp sge v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_uge_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_uge_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ugt v0, v1
;     return v5
; }

function %icmp_and_uge_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_uge_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_uge_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ugt v0, v1
;     return v5
; }

function %icmp_and_uge_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     return v2
; }

function %icmp_and_uge_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     v3 = icmp slt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_uge_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     v3 = icmp sle v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_uge_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     v3 = icmp sgt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_uge_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_uge_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     v3 = icmp sge v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_slt_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_slt_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp slt v0, v1
;     return v5
; }

function %icmp_and_slt_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     v3 = icmp ult v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_slt_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     v3 = icmp ule v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_slt_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     v3 = icmp ugt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_slt_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     v3 = icmp uge v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_slt_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     return v2
; }

function %icmp_and_slt_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp slt v0, v1
;     return v5
; }

function %icmp_and_slt_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_slt_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_slt_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_sle_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_sle_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp slt v0, v1
;     return v5
; }

function %icmp_and_sle_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     v3 = icmp ult v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sle_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     v3 = icmp ule v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sle_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     v3 = icmp ugt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sle_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     v3 = icmp uge v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sle_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp slt v0, v1
;     return v5
; }

function %icmp_and_sle_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     return v2
; }

function %icmp_and_sle_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_sle_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sle_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_sgt_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_sgt_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sgt v0, v1
;     return v5
; }

function %icmp_and_sgt_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     v3 = icmp ult v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sgt_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     v3 = icmp ule v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sgt_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     v3 = icmp ugt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sgt_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     v3 = icmp uge v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sgt_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_sgt_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_sgt_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     return v2
; }

function %icmp_and_sgt_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sgt_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sgt v0, v1
;     return v5
; }

function %icmp_and_sge_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp eq v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_sge_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp ne v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sgt v0, v1
;     return v5
; }

function %icmp_and_sge_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp ult v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     v3 = icmp ult v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sge_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp ule v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     v3 = icmp ule v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sge_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp ugt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     v3 = icmp ugt v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sge_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp uge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     v3 = icmp uge v0, v1
;     v4 = band v2, v3
;     return v4
; }

function %icmp_and_sge_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp slt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 0
;     return v5  ; v5 = 0
; }

function %icmp_and_sge_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp sle v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp eq v0, v1
;     return v5
; }

function %icmp_and_sge_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp sgt v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sgt v0, v1
;     return v5
; }

function %icmp_and_sge_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp sge v0, v1
    v4 = band v2, v3
    return v4
}

; function %icmp_and_sge_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     return v2
; }

function %icmp_or_eq_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp eq v0, v1
;     return v2
; }

function %icmp_or_eq_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_eq_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ule v0, v1
;     return v5
; }

function %icmp_or_eq_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ule v0, v1
;     return v5
; }

function %icmp_or_eq_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp uge v0, v1
;     return v5
; }

function %icmp_or_eq_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp uge v0, v1
;     return v5
; }

function %icmp_or_eq_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sle v0, v1
;     return v5
; }

function %icmp_or_eq_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sle v0, v1
;     return v5
; }

function %icmp_or_eq_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sge v0, v1
;     return v5
; }

function %icmp_or_eq_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_eq_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sge v0, v1
;     return v5
; }

function %icmp_or_ne_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ne_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ne v0, v1
;     return v2
; }

function %icmp_or_ne_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_ne_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ne_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_ne_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ne_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_ne_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ne_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_ne_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ne_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ult_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ule v0, v1
;     return v5
; }

function %icmp_or_ult_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_ult_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     return v2
; }

function %icmp_or_ult_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ule v0, v1
;     return v5
; }

function %icmp_or_ult_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_ult_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ult_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     v3 = icmp slt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ult_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     v3 = icmp sle v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ult_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     v3 = icmp sgt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ult_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ult_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ult v0, v1
;     v3 = icmp sge v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ule_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ule v0, v1
;     return v5
; }

function %icmp_or_ule_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ule_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ule v0, v1
;     return v5
; }

function %icmp_or_ule_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     return v2
; }

function %icmp_or_ule_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ule_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ule_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     v3 = icmp slt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ule_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     v3 = icmp sle v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ule_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     v3 = icmp sgt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ule_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ule_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ule v0, v1
;     v3 = icmp sge v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ugt_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp uge v0, v1
;     return v5
; }

function %icmp_or_ugt_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_ugt_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_ugt_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_ugt_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     return v2
; }

function %icmp_or_ugt_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp uge v0, v1
;     return v5
; }

function %icmp_or_ugt_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     v3 = icmp slt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ugt_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     v3 = icmp sle v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ugt_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     v3 = icmp sgt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_ugt_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_ugt_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp ugt v0, v1
;     v3 = icmp sge v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_uge_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp uge v0, v1
;     return v5
; }

function %icmp_or_uge_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_uge_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_uge_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_uge_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp uge v0, v1
;     return v5
; }

function %icmp_or_uge_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     return v2
; }

function %icmp_or_uge_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     v3 = icmp slt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_uge_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     v3 = icmp sle v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_uge_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     v3 = icmp sgt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_uge_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_uge_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp uge v0, v1
;     v3 = icmp sge v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_slt_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sle v0, v1
;     return v5
; }

function %icmp_or_slt_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_slt_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     v3 = icmp ult v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_slt_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     v3 = icmp ule v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_slt_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     v3 = icmp ugt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_slt_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     v3 = icmp uge v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_slt_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp slt v0, v1
;     return v2
; }

function %icmp_or_slt_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sle v0, v1
;     return v5
; }

function %icmp_or_slt_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_slt_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_slt_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_sle_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sle v0, v1
;     return v5
; }

function %icmp_or_sle_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_sle_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     v3 = icmp ult v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sle_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     v3 = icmp ule v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sle_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     v3 = icmp ugt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sle_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     v3 = icmp uge v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sle_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sle v0, v1
;     return v5
; }

function %icmp_or_sle_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sle v0, v1
;     return v2
; }

function %icmp_or_sle_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_sle_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sle_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_sgt_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sge v0, v1
;     return v5
; }

function %icmp_or_sgt_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_sgt_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     v3 = icmp ult v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sgt_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     v3 = icmp ule v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sgt_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     v3 = icmp ugt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sgt_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     v3 = icmp uge v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sgt_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp ne v0, v1
;     return v5
; }

function %icmp_or_sgt_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_sgt_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sgt v0, v1
;     return v2
; }

function %icmp_or_sgt_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sgt_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sge v0, v1
;     return v5
; }

function %icmp_or_sge_eq(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp eq v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_eq(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sge v0, v1
;     return v5
; }

function %icmp_or_sge_ne(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp ne v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_ne(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_sge_ult(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp ult v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_ult(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     v3 = icmp ult v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sge_ule(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp ule v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_ule(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     v3 = icmp ule v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sge_ugt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp ugt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_ugt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     v3 = icmp ugt v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sge_uge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp uge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_uge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     v3 = icmp uge v0, v1
;     v4 = bor v2, v3
;     return v4
; }

function %icmp_or_sge_slt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp slt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_slt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_sge_sle(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp sle v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_sle(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = iconst.i8 1
;     return v5  ; v5 = 1
; }

function %icmp_or_sge_sgt(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp sgt v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_sgt(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v5 = icmp sge v0, v1
;     return v5
; }

function %icmp_or_sge_sge(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    v3 = icmp sge v0, v1
    v4 = bor v2, v3
    return v4
}

; function %icmp_or_sge_sge(i32, i32) -> i8 fast {
; block0(v0: i32, v1: i32):
;     v2 = icmp sge v0, v1
;     return v2
; }
