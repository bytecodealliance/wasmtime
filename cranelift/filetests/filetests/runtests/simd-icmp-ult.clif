test interpret
test run
set enable_simd
target aarch64
target s390x
target x86_64
target x86_64 has_avx

function %simd_icmp_ult_i8(i8x16, i8x16) -> i8x16 {
block0(v0: i8x16, v1: i8x16):
    v2 = icmp ult v0, v1
    return v2
}
; run: %simd_icmp_ult_i8([0 1 -1 0 -5 1 0 0 0 0 0 0 0 0 0 0], [0 0 -1 1 -1 -1 0 0 0 0 0 0 0 0 0 0]) == [0 0 0 -1 -1 -1 0 0 0 0 0 0 0 0 0 0]

function %simd_icmp_ult_i16(i16x8, i16x8) -> i16x8 {
block0(v0: i16x8, v1: i16x8):
    v2 = icmp ult v0, v1
    return v2
}
; run: %simd_icmp_ult_i16([0 1 -1 0 -5 1 0 0], [0 0 -1 1 -1 -1 0 0]) == [0 0 0 -1 -1 -1 0 0]

function %simd_icmp_ult_i32(i32x4, i32x4) -> i32x4 {
block0(v0: i32x4, v1: i32x4):
    v2 = icmp ult v0, v1
    return v2
}
; run: %simd_icmp_ult_i32([0 1 -1 0], [0 0 -1 1]) == [0 0 0 -1]
; run: %simd_icmp_ult_i32([-5 1 0 0], [-1 -1 0 0]) == [-1 -1 0 0]



function %icmp_ult_const_i32x4() -> i8 {
block0:
    v0 = vconst.i32x4 [1 1 1 1]
    v1 = vconst.i32x4 [-1 2 3 4] ; -1 = 0xffff... will be greater than 1 when unsigned
    v2 = icmp ult v0, v1
    v8 = vall_true v2
    return v8
}
; run: %icmp_ult_const_i32x4() == 1


function %icmp_ult_const_i16x8() -> i8 {
block0:
    v0 = vconst.i16x8 [-1 -1 -1 -1 -1 -1 -1 -1]
    v1 = vconst.i16x8 [-1 -1 -1 -1 -1 -1 -1 -1]
    v2 = icmp ult v0, v1
    v3 = vconst.i16x8 0x00
    v4 = bitcast.i16x8 v2
    v5 = icmp eq v3, v4
    v8 = vall_true v5
    return v8
}
; run: %icmp_ult_const_i16x8() == 1
