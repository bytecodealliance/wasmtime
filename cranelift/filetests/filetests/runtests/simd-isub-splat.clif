test interpret
test run
target aarch64
target s390x
target x86_64
target x86_64 sse42
target x86_64 sse42 has_avx
set enable_multi_ret_implicit_sret
target riscv64 has_v
target riscv64 has_v has_c has_zcb


function %isub_splat_reverse_i8x16(i8x16, i8) -> i8x16 {
block0(v0: i8x16, v1: i8):
    v2 = splat.i8x16 v1
    v3 = isub v2, v0
    return v3
}
; run: %isub_splat_reverse_i8x16([1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16], 22) == [21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6]

function %isub_splat_reverse_i16x8(i16x8, i16) -> i16x8 {
block0(v0: i16x8, v1: i16):
    v2 = splat.i16x8 v1
    v3 = isub v2, v0
    return v3
}
; run: %isub_splat_reverse_i16x8([1 2 3 4 5 6 7 8], 22) == [21 20 19 18 17 16 15 14]

function %isub_splat_reverse_i32x4(i32x4, i32) -> i32x4 {
block0(v0: i32x4, v1: i32):
    v2 = splat.i32x4 v1
    v3 = isub v2, v0
    return v3
}
; run: %isub_splat_reverse_i32x4([1 2 3 4], 22) == [21 20 19 18]

function %isub_splat_reverse_i64x2(i64x2, i64) -> i64x2 {
block0(v0: i64x2, v1: i64):
    v2 = splat.i64x2 v1
    v3 = isub v2, v0
    return v3
}
; run: %isub_splat_reverse_i64x2([1 2], 22) == [21 20]



function %isub_splat_i8x16(i8x16, i8) -> i8x16 {
block0(v0: i8x16, v1: i8):
    v2 = splat.i8x16 v1
    v3 = isub v0, v2
    return v3
}
; run: %isub_splat_i8x16([1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16], 22) == [-21 -20 -19 -18 -17 -16 -15 -14 -13 -12 -11 -10 -9 -8 -7 -6]

function %isub_splat_i16x8(i16x8, i16) -> i16x8 {
block0(v0: i16x8, v1: i16):
    v2 = splat.i16x8 v1
    v3 = isub v0, v2
    return v3
}
; run: %isub_splat_i16x8([1 2 3 4 5 6 7 8], 22) == [-21 -20 -19 -18 -17 -16 -15 -14]

function %isub_splat_i32x4(i32x4, i32) -> i32x4 {
block0(v0: i32x4, v1: i32):
    v2 = splat.i32x4 v1
    v3 = isub v0, v2
    return v3
}
; run: %isub_splat_i32x4([1 2 3 4], 22) == [-21 -20 -19 -18]

function %isub_splat_i64x2(i64x2, i64) -> i64x2 {
block0(v0: i64x2, v1: i64):
    v2 = splat.i64x2 v1
    v3 = isub v0, v2
    return v3
}
; run: %isub_splat_i64x2([1 2], 22) == [-21 -20]



function %isub_splat_const_i8x16(i8x16) -> i8x16 {
block0(v0: i8x16):
    v1 = iconst.i8 5
    v2 = splat.i8x16 v1
    v3 = isub v0, v2
    return v3
}
; run: %isub_splat_const_i8x16([1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16]) == [-4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10 11]

function %isub_splat_const_i16x8(i16x8) -> i16x8 {
block0(v0: i16x8):
    v1 = iconst.i16 -16
    v2 = splat.i16x8 v1
    v3 = isub v0, v2
    return v3
}
; run: %isub_splat_const_i16x8([1 2 3 4 5 6 7 8]) == [17 18 19 20 21 22 23 24]

function %isub_splat_const_i32x4(i32x4) -> i32x4 {
block0(v0: i32x4):
    v1 = iconst.i32 15
    v2 = splat.i32x4 v1
    v3 = isub v0, v2
    return v3
}
; run: %isub_splat_const_i32x4([1 2 3 4]) == [-14 -13 -12 -11]

function %isub_splat_const_i64x2(i64x2) -> i64x2 {
block0(v0: i64x2):
    v1 = iconst.i64 -5
    v2 = splat.i64x2 v1
    v3 = isub v0, v2
    return v3
}
; run: %isub_splat_const_i64x2([1 2]) == [6 7]



function %isub_splat_const_reverse_i8x16(i8x16) -> i8x16 {
block0(v0: i8x16):
    v1 = iconst.i8 5
    v2 = splat.i8x16 v1
    v3 = isub v2, v0
    return v3
}
; run: %isub_splat_const_reverse_i8x16([1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16]) == [4 3 2 1 0 -1 -2 -3 -4 -5 -6 -7 -8 -9 -10 -11]

function %isub_splat_const_reverse_i16x8(i16x8) -> i16x8 {
block0(v0: i16x8):
    v1 = iconst.i16 -16
    v2 = splat.i16x8 v1
    v3 = isub v2, v0
    return v3
}
; run: %isub_splat_const_reverse_i16x8([1 2 3 4 5 6 7 8]) == [-17 -18 -19 -20 -21 -22 -23 -24]

function %isub_splat_const_reverse_i32x4(i32x4) -> i32x4 {
block0(v0: i32x4):
    v1 = iconst.i32 15
    v2 = splat.i32x4 v1
    v3 = isub v2, v0
    return v3
}
; run: %isub_splat_const_reverse_i32x4([1 2 3 4]) == [14 13 12 11]

function %isub_splat_const_reverse_i64x2(i64x2) -> i64x2 {
block0(v0: i64x2):
    v1 = iconst.i64 -5
    v2 = splat.i64x2 v1
    v3 = isub v2, v0
    return v3
}
; run: %isub_splat_const_reverse_i64x2([1 2]) == [-6 -7]


function %isub_splat_sextend_i16x8(i16x8, i8) -> i16x8 {
block0(v0: i16x8, v1: i8):
    v2 = sextend.i16 v1
    v3 = splat.i16x8 v2
    v4 = isub v0, v3
    return v4
}
; run: %isub_splat_sextend_i16x8([1 -2 3 4 5 6 7 8], -10) == [11 8 13 14 15 16 17 18]

function %isub_splat_sextend_i32x4(i32x4, i16) -> i32x4 {
block0(v0: i32x4, v1: i16):
    v2 = sextend.i32 v1
    v3 = splat.i32x4 v2
    v4 = isub v0, v3
    return v4
}
; run: %isub_splat_sextend_i32x4([1 -2 3 4], -10) == [11 8 13 14]

function %isub_splat_sextend_i64x2(i64x2, i32) -> i64x2 {
block0(v0: i64x2, v1: i32):
    v2 = sextend.i64 v1
    v3 = splat.i64x2 v2
    v4 = isub v0, v3
    return v4
}
; run: %isub_splat_sextend_i64x2([1 -2], 10) == [-9 -12]


function %isub_splat_uextend_i16x8(i16x8, i8) -> i16x8 {
block0(v0: i16x8, v1: i8):
    v2 = uextend.i16 v1
    v3 = splat.i16x8 v2
    v4 = isub v0, v3
    return v4
}
; run: %isub_splat_uextend_i16x8([1 -2 3 4 5 6 7 8], 10) == [0xfff7 0xfff4 0xfff9 0xfffa 0xfffb 0xfffc 0xfffd 0xfffe]
; run: %isub_splat_uextend_i16x8([1 -2 3 4 5 6 7 8], -10) == [0xff0b 0xff08 0xff0d 0xff0e 0xff0f 0xff10 0xff11 0xff12]

function %isub_splat_uextend_i32x4(i32x4, i16) -> i32x4 {
block0(v0: i32x4, v1: i16):
    v2 = uextend.i32 v1
    v3 = splat.i32x4 v2
    v4 = isub v0, v3
    return v4
}
; run: %isub_splat_uextend_i32x4([1 -2 3 4], 10) == [0xfffffff7 0xfffffff4 0xfffffff9 0xfffffffa]
; run: %isub_splat_uextend_i32x4([1 -2 3 4], -10) == [0xffff000b 0xffff0008 0xffff000d 0xffff000e]

function %isub_splat_uextend_i64x2(i64x2, i32) -> i64x2 {
block0(v0: i64x2, v1: i32):
    v2 = uextend.i64 v1
    v3 = splat.i64x2 v2
    v4 = isub v0, v3
    return v4
}
; run: %isub_splat_uextend_i64x2([1 -2], 10) == [0xfffffffffffffff7 0xfffffffffffffff4]
; run: %isub_splat_uextend_i64x2([1 -2], -10) == [0xffffffff0000000b 0xffffffff00000008]
