test run
target aarch64
target s390x
target x86_64 has_sse3 has_ssse3 has_sse41
target x86_64 has_sse3 has_ssse3 has_sse41 has_avx
set enable_multi_ret_implicit_sret
target riscv64 has_v
target riscv64 has_v has_c has_zcb

function %simd_fcmp_gt_f32(f32x4, f32x4) -> i32x4 {
block0(v0: f32x4, v1: f32x4):
    v2 = fcmp gt v0, v1
    return v2
}
; run: %simd_fcmp_gt_f32([0x0.5 0x1.5 0x1.1p10 0x1.4cccccp0], [0x0.5 0x2.9 0x1.400000p1 0x1.800000p0]) == [0 0 -1 0]
; run: %simd_fcmp_gt_f32([0x0.0 -0x0.0 -0x0.0 0x0.0], [-0x0.0 0x0.0 +Inf -Inf]) == [0 0 0 -1]
; run: %simd_fcmp_gt_f32([-0x0.0 0x0.0 +Inf +Inf], [-0x0.0 0x0.0 -Inf +Inf]) == [0 0 -1 0]
; run: %simd_fcmp_gt_f32([-NaN NaN -NaN NaN], [NaN NaN -NaN NaN]) == [0 0 0 0]
; run: %simd_fcmp_gt_f32([NaN -0x0.0 -Inf 0x1.0], [-NaN 0x0.0 +Inf -0x1.0]) == [0 0 0 -1]

function %simd_fcmp_splat_rhs_gt_f32(f32x4, f32) -> i32x4 {
block0(v0: f32x4, v1: f32):
    v2 = splat.f32x4 v1
    v3 = fcmp gt v0, v2
    return v3
}
; run: %simd_fcmp_splat_rhs_gt_f32([0x0.5 0x1.5 0x1.1p10 0x1.4cccccp0], 0x0.5) == [0 -1 -1 -1]
; run: %simd_fcmp_splat_rhs_gt_f32([0x0.0 -0x0.0 -0x0.0 0x0.0], -0x0.0) == [0 0 0 0]
; run: %simd_fcmp_splat_rhs_gt_f32([-0x0.0 0x0.0 +Inf +Inf], -Inf) == [-1 -1 -1 -1]
; run: %simd_fcmp_splat_rhs_gt_f32([-NaN NaN -NaN NaN], NaN) == [0 0 0 0]
; run: %simd_fcmp_splat_rhs_gt_f32([NaN -0x0.0 -Inf 0x1.0], -NaN) == [0 0 0 0]

function %simd_fcmp_splat_lhs_gt_f32(f32x4, f32) -> i32x4 {
block0(v0: f32x4, v1: f32):
    v2 = splat.f32x4 v1
    v3 = fcmp gt v2, v0
    return v3
}
; run: %simd_fcmp_splat_lhs_gt_f32([0x0.5 0x1.5 0x1.1p10 0x1.4cccccp0], 0x0.5) == [0 0 0 0]
; run: %simd_fcmp_splat_lhs_gt_f32([0x0.0 -0x0.0 -0x0.0 0x0.0], -0x0.0) == [0 0 0 0]
; run: %simd_fcmp_splat_lhs_gt_f32([-0x0.0 0x0.0 +Inf +Inf], -Inf) == [0 0 0 0]
; run: %simd_fcmp_splat_lhs_gt_f32([-NaN NaN -NaN NaN], NaN) == [0 0 0 0]
; run: %simd_fcmp_splat_lhs_gt_f32([NaN -0x0.0 -Inf 0x1.0], -NaN) == [0 0 0 0]

function %simd_fcmp_gt_f64(f64x2, f64x2) -> i64x2 {
block0(v0: f64x2, v1: f64x2):
    v2 = fcmp gt v0, v1
    return v2
}
; run: %simd_fcmp_gt_f64([0x0.5 0x1.5], [0x0.5 0x2.9]) == [0 0]
; run: %simd_fcmp_gt_f64([0x0.0 -0x0.0], [-0x0.0 0x0.0]) == [0 0]
; run: %simd_fcmp_gt_f64([+Inf +Inf], [-Inf +Inf]) == [-1 0]
; run: %simd_fcmp_gt_f64([-NaN NaN], [NaN NaN]) == [0 0]
; run: %simd_fcmp_gt_f64([NaN -0x0.0], [-NaN 0x0.0]) == [0 0]

function %simd_fcmp_splat_rhs_gt_f64(f64x2, f64) -> i64x2 {
block0(v0: f64x2, v1: f64):
    v2 = splat.f64x2 v1
    v3 = fcmp gt v0, v2
    return v3
}
; run: %simd_fcmp_splat_rhs_gt_f64([0x0.5 0x1.5], 0x0.5) == [0 -1]
; run: %simd_fcmp_splat_rhs_gt_f64([0x0.0 -0x0.0], -0x0.0) == [0 0]
; run: %simd_fcmp_splat_rhs_gt_f64([+Inf +Inf], -Inf) == [-1 -1]
; run: %simd_fcmp_splat_rhs_gt_f64([-NaN NaN], NaN) == [0 0]
; run: %simd_fcmp_splat_rhs_gt_f64([NaN -0x0.0], -NaN) == [0 0]

function %simd_fcmp_splat_lhs_gt_f64(f64x2, f64) -> i64x2 {
block0(v0: f64x2, v1: f64):
    v2 = splat.f64x2 v1
    v3 = fcmp gt v2, v0
    return v3
}
; run: %simd_fcmp_splat_lhs_gt_f64([0x0.5 0x1.5], 0x0.5) == [0 0]
; run: %simd_fcmp_splat_lhs_gt_f64([0x0.0 -0x0.0], -0x0.0) == [0 0]
; run: %simd_fcmp_splat_lhs_gt_f64([+Inf +Inf], -Inf) == [0 0]
; run: %simd_fcmp_splat_lhs_gt_f64([-NaN NaN], NaN) == [0 0]
; run: %simd_fcmp_splat_lhs_gt_f64([NaN -0x0.0], -NaN) == [0 0]

function %fcmp_gt_nans_f32x4() -> i8 {
block0:
    v0 = vconst.f32x4 [NaN 0x42.0 -NaN NaN]
    v1 = vconst.f32x4 [NaN NaN 0x42.0 Inf]
    v2 = fcmp gt v0, v1
    ; now check that the result v2 is all zeroes
    v3 = vconst.i32x4 0x00
    v4 = bitcast.i32x4 v2
    v5 = icmp eq v3, v4
    v8 = vall_true v5
    return v8
}
; run: %fcmp_gt_nans_f32x4() == 1
